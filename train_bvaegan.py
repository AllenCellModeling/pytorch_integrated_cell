import argparse

import importlib
import numpy as np

import os
import pickle

import math

import torch
import torch.nn as nn
import torch.optim as optim
from torch.autograd import Variable
import torchvision.utils

import time
import datetime

import warnings
import json

import integrated_cell as ic
from integrated_cell import model_utils

import shutil
import socket

# import torch.backends.cudnn as cudnn
# cudnn.benchmark = True

import pdb

def str2bool(v):
    if v.lower() in ('yes', 'true', 't', 'y', '1'):
        return True
    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
        return False
    else:
        raise argparse.ArgumentTypeError('Boolean value expected.')

parser = argparse.ArgumentParser()

parser.add_argument('--gpu_ids', nargs='+', type=int, default=0, help='gpu id')
parser.add_argument('--myseed', type=int, default=0, help='random seed')
parser.add_argument('--nlatentdim', type=int, default=16, help='number of latent dimensions')
parser.add_argument('--lrEnc', type=float, default=0.0005, help='learning rate for encoder')
parser.add_argument('--lrDec', type=float, default=0.0005, help='learning rate for decoder')
parser.add_argument('--lrDecD', type=float, default=0.00005, help='learning rate for decD')

parser.add_argument('--kwargs_enc_optim', type=json.loads, default='{"betas": [0.5, 0.999]}', help='kwargs for encoder optimizer')
parser.add_argument('--kwargs_dec_optim', type=json.loads, default='{"betas": [0.5, 0.999]}', help='kwargs for decoder optimizer')
parser.add_argument('--kwargs_decD_optim', type=json.loads, default='{"betas": [0.5, 0.999]}', help='kwargs for decoder descriminator optimizer')

parser.add_argument('--kwargs_model', type=json.loads, default={}, help='kwargs for the model')

parser.add_argument('--kwargs_enc', type=json.loads, default={}, help='kwargs for the enc')
parser.add_argument('--kwargs_dec', type=json.loads, default={}, help='kwargs for the dec')
parser.add_argument('--kwargs_decD', type=json.loads, default={}, help='kwargs for the decD')

parser.add_argument('--kwargs_dp', type=json.loads, default={}, help='kwargs for the data provider')

parser.add_argument('--critRecon', default='BCELoss', help='Loss function for image reconstruction')
parser.add_argument('--critAdv', default='nn.BCEWithLogitsLoss', help='Loss function for advarsaries')

parser.add_argument('--batch_size', type=int, default=64, help='batch size')
parser.add_argument('--nepochs', type=int, default=250, help='total number of epochs')
parser.add_argument('--nepochs_pt2', type=int, default=-1, help='total number of epochs')

parser.add_argument('--model_name', default='waaegan', help='name of the model module')
parser.add_argument('--save_dir', type=str, default=None, help='save dir')
parser.add_argument('--save_parent', type=str, default=None, help='parent save directory to save with autogenerated working directory (mutually exclusive to "--save_dir")')
parser.add_argument('--saveProgressIter', type=int, default=1, help='number of iterations between saving progress')
parser.add_argument('--saveStateIter', type=int, default=1, help='number of iterations between saving progress')
parser.add_argument('--data_save_path', default=None, help='save path of data file')
parser.add_argument('--imdir', default='/root/data/release_4_1_17/results_v2/aligned/2D', help='location of images')

parser.add_argument('--latentDistribution', default='gaussian', help='Distribution of latent space, can be {gaussian, uniform}')

parser.add_argument('--ndat', type=int, default=-1, help='Number of data points to use')
parser.add_argument('--optimizer', default='Adam', help='type of optimizer, can be {Adam, RMSprop}')

parser.add_argument('--train_module', default=None, help='training module')
parser.add_argument('--train_module_pt1', default=None, help='training module')
parser.add_argument('--train_module_pt2', default=None, help='training module')

parser.add_argument('--dataProvider', default='DataProvider', help='Dataprovider object')

parser.add_argument('--channels_pt1', nargs='+', type=int, default=[0,2], help='channels to use for part 1')
parser.add_argument('--channels_pt2', nargs='+', type=int, default=[0,1,2], help='channels to use for part 2')

parser.add_argument('--dtype', default='float', help='data type that the dataprovider uses. Only \'float\' supported.')

parser.add_argument('--overwrite_opts', default=False, type=str2bool, help='Overwrite options file')
parser.add_argument('--skip_pt1', default=False, type=str2bool, help='Skip pt 1')

parser.add_argument('--ref_dir', default='ref_model', type=str, help='Directory name for reference model')
parser.add_argument('--struct_dir', default='struct_model', type=str, help='Directory name for structure model')

opt = parser.parse_args()


def load_opts(kwargs_model, opt, save_path):
    opt.opt_save_path = '{0}/opt.pkl'.format(opt.save_dir)

    if os.path.exists(save_path) and not opt.overwrite_opts:
        warnings.warn('Options file exists and overwrite is not set to True. Using existing options file.')

        #load options file
        kwargs_model = pickle.load( open( save_path, 'rb' ) )
    else:

        #make a copy if the opts file exists
        if os.path.exists(save_path):
            shutil.copyfile(save_path, '{0}_{1}'.format(save_path, the_time))

        pickle.dump(kwargs_model, open(save_path, 'wb'))
    
    print(kwargs_model)
    return kwargs_model

def setup_kwargs_model(opt):
    kwargs_model = opt.kwargs_model
    
    kwargs_model['n_channels'] = len(opt.channels_pt1)
    kwargs_model['n_classes'] = 0
    kwargs_model['n_ref'] = 0
    
    kwargs_model['n_epochs'] = opt.nepochs
    kwargs_model['n_latent_dim'] = opt.nlatentdim
    
    kwargs_model['gpu_ids'] = opt.gpu_ids
    kwargs_model['save_dir'] = opt.save_dir
    kwargs_model['save_state_iter'] = opt.saveStateIter
    kwargs_model['save_progress_iter'] = opt.saveProgressIter
    
    kwargs_model['model_name'] = opt.model_name
    kwargs_model['kwargs_enc'] = opt.kwargs_enc
    kwargs_model['kwargs_enc_optim'] = opt.kwargs_enc_optim
    kwargs_model['kwargs_dec'] = opt.kwargs_dec
    kwargs_model['kwargs_dec_optim'] = opt.kwargs_dec_optim    
    kwargs_model['kwargs_decD'] = opt.kwargs_decD
    kwargs_model['kwargs_decD_optim'] = opt.kwargs_decD_optim    
    
    kwargs_model['critRecon'] = opt.critRecon
    kwargs_model['critAdv'] = opt.critAdv
    kwargs_model['optimizer'] = opt.optimizer
    
    kwargs_model['lrEnc'] = opt.lrEnc
    kwargs_model['lrDec'] = opt.lrDec
    kwargs_model['lrDecD'] = opt.lrDecD
    
    kwargs_model['latent_distribution'] = opt.latentDistribution

    kwargs_model['hostname'] = opt.hostname
    
    return kwargs_model


if (opt.save_parent is not None) and (opt.save_dir is not None):
    raise ValueError('--save_dir and --save_parent are both set. Please choose one or the other.')
    
if ((opt.train_module is not None) and (opt.train_module_pt1 is not None)) or ((opt.train_module is not None) and (opt.train_module_pt2 is not None)):
    raise ValueError('--train_module and --train_model_pt1 or --train_model_pt2 are both set. Please choose a global train module or specify partial models.')

the_time = datetime.datetime.now().strftime("%Y-%m-%d-%H:%M:%S")
if opt.save_parent is not None:
    opt.save_dir = os.path.join(opt.save_parent, the_time)

opt.the_time = the_time
opt.save_parent = opt.save_dir

opt.hostname = socket.gethostname()

if opt.data_save_path is None:
    opt.data_save_path = opt.save_dir + os.sep + 'data.pyt'

if not os.path.exists(opt.save_parent):
    os.makedirs(opt.save_parent)

if opt.train_module is not None:
    opt.train_module_pt1 = opt.train_module
    opt.train_module_pt2 = opt.train_module
    
os.environ['CUDA_VISIBLE_DEVICES'] = ','.join([str(ID) for ID in opt.gpu_ids])
opt.gpu_ids = list(range(0, len(opt.gpu_ids)))

torch.manual_seed(opt.myseed)
torch.cuda.manual_seed(opt.myseed)
np.random.seed(opt.myseed)


if opt.nepochs_pt2 == -1:
    opt.nepochs_pt2 = opt.nepochs 

dp = model_utils.load_data_provider(data_path = opt.data_save_path, batch_size = opt.batch_size, im_dir = opt.imdir, dp_module = opt.dataProvider, n_dat = opt.ndat, **opt.kwargs_dp)
dp.channelInds = opt.channels_pt1

#######
### TRAIN REFERENCE MODEL
#######

opt.save_dir = os.path.join(opt.save_parent, opt.ref_dir)
if not os.path.exists(opt.save_dir):
    os.makedirs(opt.save_dir)

if not opt.skip_pt1:
    kwargs_model = setup_kwargs_model(opt)

    kwargs_model = load_opts(kwargs_model, opt, save_path = '{0}/opt.pkl'.format(opt.save_dir))
    
    model_module = importlib.import_module("integrated_cell.models." + opt.train_module_pt1)

    print(kwargs_model)
    model = model_module.Model(data_provider = dp, **kwargs_model)

    model.load(opt.save_dir)
    model.train()
    
#######
### DONE TRAINING REFERENCE MODEL
#######

#######
### TRAIN STRUCTURE MODEL
#######

embeddings_path = opt.save_dir + os.sep + 'embeddings.pkl'

if opt.skip_pt1:
    embeddings = model_utils.load_embeddings(embeddings_path, None, dp, opt)
else:
    embeddings = model_utils.load_embeddings(embeddings_path, model.enc, dp, opt)

models = None
optimizers = None

dp.embeddings = embeddings
dp.channelInds = opt.channels_pt2

opt.save_dir = os.path.join(opt.save_parent, opt.struct_dir)
if not os.path.exists(opt.save_dir):
    os.makedirs(opt.save_dir)

kwargs_model = setup_kwargs_model(opt)    

kwargs_model['n_channels'] = len(opt.channels_pt2)
kwargs_model['n_classes'] = dp.get_n_classes()
kwargs_model['n_ref'] = opt.nlatentdim
kwargs_model['n_epochs'] = opt.nepochs_pt2

kwargs_model = load_opts(kwargs_model, opt, save_path = '{0}/opt.pkl'.format(opt.save_dir))

model_module = importlib.import_module("integrated_cell.models." + opt.train_module_pt2)

print(kwargs_model)
model = model_module.Model(data_provider = dp, **kwargs_model)

model.load(opt.save_dir)
model.train()

print('Finished Training')

embeddings_path = opt.save_dir + os.sep + 'embeddings.pkl'
embeddings = model_utils.load_embeddings(embeddings_path, model.enc, dp, opt)

#######
### DONE TRAINING STRUCTURE MODEL
#######
