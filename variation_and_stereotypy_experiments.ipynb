{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(Diters=5, DitersAlt=100, batch_size=32, channelInds=[0, 1, 2], channels_pt1=[0, 2], channels_pt2=[0, 1, 2], clamp_lower=-0.01, clamp_upper=0.01, dataProvider='DataProvider3Dh5', decDRatio=1e-05, dragan=False, dtype='float', encDRatio=0.001, gpu_ids=[0, 1, 2], imdir='/root/results/ipp_dataset_cellnuc_seg_curated_7_24_17', improved=False, improved_penalty=0.1, imsize=8, iter=133499, latentDistribution='gaussian', latentSample=<function sampleGaussian at 0x7f4828de59d8>, lrDec=5e-05, lrDecD=5e-05, lrEnc=5e-05, lrEncD=5e-05, model_name='aaegan3Dv4-relu', myseed=0, nClasses=10, nRef=32, nch=3, nclasses=1, ndat=14235, nepochs=300, nepochs_pt2=500, nlatentdim=32, noise=0.01, noise_std=0, optimizer='adam', saveProgressIter=1, saveStateIter=1, save_dir='./test_aaegan/aaegan3Dv4_32D-relu_v3//struct_model', save_parent='./test_aaegan/aaegan3Dv4_32D-relu_v3/', train_module='aaegan_trainv2')\n",
      "Loading from ./test_aaegan/aaegan3Dv4_32D-relu_v3//struct_model\n",
      "Done loading model.\n",
      "Done loading embeddings.\n"
     ]
    }
   ],
   "source": [
    "#######    \n",
    "### This function prints off the most likely predicted \n",
    "### channels for each of the cells in our dataset\n",
    "#######\n",
    "\n",
    "#######    \n",
    "### Load the Model Parts\n",
    "#######\n",
    "\n",
    "import argparse\n",
    "import SimpleLogger as SimpleLogger\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils\n",
    "\n",
    "#have to do this import to be able to use pyplot in the docker image\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "from model_utils import set_gpu_recursive, load_model, save_state, save_progress, get_latent_embeddings, maybe_save\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "import pdb\n",
    "\n",
    "parent_dir = './test_aaegan/aaegan3Dv4_32D-relu_v3'\n",
    "\n",
    "model_dir = parent_dir + os.sep + 'struct_model' \n",
    "\n",
    "# logger_file = '{0}/logger_tmp.pkl'.format(model_dir)\n",
    "opt = pickle.load( open( '{0}/opt.pkl'.format(model_dir), \"rb\" ) )\n",
    "\n",
    "print(opt)\n",
    "\n",
    "DP = importlib.import_module(\"data_providers.\" + opt.dataProvider)\n",
    "model_provider = importlib.import_module(\"models.\" + opt.model_name)\n",
    "train_module = importlib.import_module(\"train_modules.\" + opt.train_module)\n",
    "\n",
    "torch.manual_seed(opt.myseed)\n",
    "torch.cuda.manual_seed(opt.myseed)\n",
    "np.random.seed(opt.myseed)\n",
    "\n",
    "if not os.path.exists(opt.save_dir):\n",
    "    os.makedirs(opt.save_dir)\n",
    "    \n",
    "if opt.nepochs_pt2 == -1:\n",
    "    opt.nepochs_pt2 = opt.nepochs\n",
    "\n",
    "opts = {}\n",
    "opts['verbose'] = True\n",
    "opts['pattern'] = '*.tif_flat.png'\n",
    "opts['out_size'] = [opt.imsize, opt.imsize]\n",
    "\n",
    "data_path = './data_{0}x{1}.pyt'.format(str(opts['out_size'][0]), str(opts['out_size'][1]))\n",
    "if os.path.exists(data_path):\n",
    "    dp = torch.load(data_path)\n",
    "else:\n",
    "    dp = DP.DataProvider(opt.imdir, opts)\n",
    "    torch.save(dp, data_path)\n",
    "    \n",
    "dp.opts['dtype'] = 'float'\n",
    "    \n",
    "if opt.ndat == -1:\n",
    "    opt.ndat = dp.get_n_dat('train')    \n",
    "\n",
    "iters_per_epoch = np.ceil(opt.ndat/opt.batch_size)    \n",
    "            \n",
    "#######    \n",
    "### Load REFERENCE MODEL\n",
    "#######\n",
    "\n",
    "embeddings_path = opt.save_parent + os.sep + 'ref_model' + os.sep + 'embeddings.pkl'\n",
    "if os.path.exists(embeddings_path):\n",
    "    embeddings = torch.load(embeddings_path)\n",
    "else:\n",
    "    embeddings = get_latent_embeddings(models['enc'], dp, opt)\n",
    "    torch.save(embeddings, embeddings_path)\n",
    "\n",
    "models = None\n",
    "optimizers = None\n",
    "    \n",
    "def get_ref(self, inds, train_or_test='train'):\n",
    "    inds = torch.LongTensor(inds)\n",
    "    return self.embeddings[train_or_test][inds]\n",
    "\n",
    "dp.embeddings = embeddings\n",
    "\n",
    "# do this thing to bind the get_ref method to the dataprovider object\n",
    "import types  \n",
    "dp.get_ref = types.MethodType(get_ref, dp)\n",
    "            \n",
    "\n",
    "opt.channelInds = [0, 1, 2]\n",
    "dp.opts['channelInds'] = opt.channelInds\n",
    "opt.nch = len(opt.channelInds)\n",
    "        \n",
    "opt.nClasses = dp.get_n_classes()\n",
    "opt.nRef = opt.nlatentdim\n",
    "\n",
    "try:\n",
    "    train_module = None\n",
    "    train_module = importlib.import_module(\"train_modules.\" + opt.train_module)\n",
    "    train_module = train_module.trainer(dp, opt)\n",
    "except:\n",
    "    pass    \n",
    "\n",
    "if not hasattr(opt, 'critRecon'):\n",
    "    opt.critRecon = 'BCELoss'\n",
    "    \n",
    "if not hasattr(opt, 'dtype'):\n",
    "    opt.dtype = 'float'\n",
    "\n",
    "# pdb.set_trace()\n",
    "opt.gpu_ids = [1,2,3]\n",
    "models, optimizers, criterions, logger, opt = load_model(model_provider, opt)\n",
    "\n",
    "enc = models['enc']\n",
    "dec = models['dec']\n",
    "enc.train(False)\n",
    "dec.train(False)\n",
    "\n",
    "models = None\n",
    "optimizers = None\n",
    "\n",
    "\n",
    "print('Done loading model.')\n",
    "\n",
    "# Get the embeddings for the structure localization\n",
    "\n",
    "opt.batch_size = 200\n",
    "# opt.gpu_ids = [0,1,3]\n",
    "enc.gpu_ids = opt.gpu_ids\n",
    "dec.gpu_ids = opt.gpu_ids\n",
    "\n",
    "embeddings_path = opt.save_dir + os.sep + 'embeddings_struct.pkl'\n",
    "if os.path.exists(embeddings_path):\n",
    "    embeddings = torch.load(embeddings_path)\n",
    "else:\n",
    "    embeddings = get_latent_embeddings(enc, dp, opt, 1)\n",
    "    torch.save(embeddings, embeddings_path)\n",
    "\n",
    "print('Done loading embeddings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15372/15827\n",
      "15373/15827\n",
      "15374/15827\n",
      "15375/15827\n",
      "15376/15827\n",
      "15377/15827\n",
      "15378/15827\n",
      "15379/15827\n",
      "15380/15827\n",
      "15381/15827\n",
      "15382/15827\n",
      "15383/15827\n",
      "15384/15827\n",
      "15385/15827\n",
      "15386/15827\n",
      "15387/15827\n",
      "15388/15827\n",
      "15389/15827\n",
      "15390/15827\n",
      "15391/15827\n",
      "15392/15827\n",
      "15393/15827\n",
      "15394/15827\n",
      "15395/15827\n",
      "15396/15827\n",
      "15397/15827\n",
      "15398/15827\n",
      "15399/15827\n",
      "15400/15827\n",
      "15401/15827\n",
      "15402/15827\n",
      "15403/15827\n",
      "15404/15827\n",
      "15405/15827\n",
      "15406/15827\n",
      "15407/15827\n",
      "15408/15827\n",
      "15409/15827\n",
      "15410/15827\n",
      "15411/15827\n",
      "15412/15827\n",
      "15413/15827\n",
      "15414/15827\n",
      "15415/15827\n",
      "15416/15827\n",
      "15417/15827\n",
      "15418/15827\n",
      "15419/15827\n",
      "15420/15827\n",
      "15421/15827\n",
      "15422/15827\n",
      "15423/15827\n",
      "15424/15827\n",
      "15425/15827\n",
      "15426/15827\n",
      "15427/15827\n",
      "15428/15827\n",
      "15429/15827\n",
      "15430/15827\n",
      "15431/15827\n",
      "15432/15827\n",
      "15433/15827\n",
      "15434/15827\n",
      "15435/15827\n",
      "15436/15827\n",
      "15437/15827\n",
      "15438/15827\n",
      "15439/15827\n",
      "15440/15827\n",
      "15441/15827\n",
      "15442/15827\n",
      "15443/15827\n",
      "15444/15827\n",
      "15445/15827\n",
      "15446/15827\n",
      "15447/15827\n",
      "15448/15827\n",
      "15449/15827\n",
      "15450/15827\n",
      "15451/15827\n",
      "15452/15827\n",
      "15453/15827\n",
      "15454/15827\n",
      "15455/15827\n",
      "15456/15827\n",
      "15457/15827\n",
      "15458/15827\n",
      "15459/15827\n",
      "15460/15827\n",
      "15461/15827\n",
      "15462/15827\n",
      "15463/15827\n",
      "15464/15827\n",
      "15465/15827\n",
      "15466/15827\n",
      "15467/15827\n",
      "15468/15827\n",
      "15469/15827\n",
      "15470/15827\n",
      "15471/15827\n",
      "15472/15827\n",
      "15473/15827\n",
      "15474/15827\n",
      "15475/15827\n",
      "15476/15827\n",
      "15477/15827\n",
      "15478/15827\n",
      "15479/15827\n",
      "15480/15827\n",
      "15481/15827\n",
      "15482/15827\n",
      "15483/15827\n",
      "15484/15827\n",
      "15485/15827\n",
      "15486/15827\n",
      "15487/15827\n",
      "15488/15827\n",
      "15489/15827\n",
      "15490/15827\n",
      "15491/15827\n",
      "15492/15827\n",
      "15493/15827\n",
      "15494/15827\n",
      "15495/15827\n",
      "15496/15827\n",
      "15497/15827\n",
      "15498/15827\n",
      "15499/15827\n",
      "15500/15827\n",
      "15501/15827\n",
      "15502/15827\n",
      "15503/15827\n",
      "15504/15827\n",
      "15505/15827\n",
      "15506/15827\n",
      "15507/15827\n",
      "15508/15827\n",
      "15509/15827\n",
      "15510/15827\n",
      "15511/15827\n",
      "15512/15827\n",
      "15513/15827\n",
      "15514/15827\n",
      "15515/15827\n",
      "15516/15827\n",
      "15517/15827\n",
      "15518/15827\n",
      "15519/15827\n",
      "15520/15827\n",
      "15521/15827\n",
      "15522/15827\n",
      "15523/15827\n",
      "15524/15827\n",
      "15525/15827\n",
      "15526/15827\n",
      "15527/15827\n",
      "15528/15827\n",
      "15529/15827\n",
      "15530/15827\n",
      "15531/15827\n",
      "15532/15827\n",
      "15533/15827\n",
      "15534/15827\n",
      "15535/15827\n",
      "15536/15827\n",
      "15537/15827\n",
      "15538/15827\n",
      "15539/15827\n",
      "15540/15827\n",
      "15541/15827\n",
      "15542/15827\n",
      "15543/15827\n",
      "15544/15827\n",
      "15545/15827\n",
      "15546/15827\n",
      "15547/15827\n",
      "15548/15827\n",
      "15549/15827\n",
      "15550/15827\n",
      "15551/15827\n",
      "15552/15827\n",
      "15553/15827\n",
      "15554/15827\n",
      "15555/15827\n",
      "15556/15827\n",
      "15557/15827\n",
      "15558/15827\n",
      "15559/15827\n",
      "15560/15827\n",
      "15561/15827\n",
      "15562/15827\n",
      "15563/15827\n",
      "15564/15827\n",
      "15565/15827\n",
      "15566/15827\n",
      "15567/15827\n",
      "15568/15827\n",
      "15569/15827\n",
      "15570/15827\n",
      "15571/15827\n",
      "15572/15827\n",
      "15573/15827\n",
      "15574/15827\n",
      "15575/15827\n",
      "15576/15827\n",
      "15577/15827\n",
      "15578/15827\n",
      "15579/15827\n",
      "15580/15827\n",
      "15581/15827\n",
      "15582/15827\n",
      "15583/15827\n",
      "15584/15827\n",
      "15585/15827\n",
      "15586/15827\n",
      "15587/15827\n",
      "15588/15827\n",
      "15589/15827\n",
      "15590/15827\n",
      "15591/15827\n",
      "15592/15827\n",
      "15593/15827\n",
      "15594/15827\n",
      "15595/15827\n",
      "15596/15827\n",
      "15597/15827\n",
      "15598/15827\n",
      "15599/15827\n",
      "15600/15827\n",
      "15601/15827\n",
      "15602/15827\n",
      "15603/15827\n",
      "15604/15827\n",
      "15605/15827\n",
      "15606/15827\n",
      "15607/15827\n",
      "15608/15827\n",
      "15609/15827\n",
      "15610/15827\n",
      "15611/15827\n",
      "15612/15827\n",
      "15613/15827\n",
      "15614/15827\n",
      "15615/15827\n",
      "15616/15827\n",
      "15617/15827\n",
      "15618/15827\n",
      "15619/15827\n",
      "15620/15827\n",
      "15621/15827\n",
      "15622/15827\n",
      "15623/15827\n",
      "15624/15827\n",
      "15625/15827\n",
      "15626/15827\n",
      "15627/15827\n",
      "15628/15827\n",
      "15629/15827\n",
      "15630/15827\n",
      "15631/15827\n",
      "15632/15827\n",
      "15633/15827\n",
      "15634/15827\n",
      "15635/15827\n"
     ]
    }
   ],
   "source": [
    "#######    \n",
    "### Main Loop\n",
    "#######\n",
    "\n",
    "import pdb\n",
    "from aicsimage.io import omeTifWriter\n",
    "from imgToProjection import imgtoprojection\n",
    "from IPython.core.display import display\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "enc = None\n",
    "\n",
    "opt.batch_size = 300\n",
    "gpu_id = opt.gpu_ids[0]\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "embeddings_all = torch.cat([embeddings['train'], embeddings['test']], 0);\n",
    "\n",
    "dat_train_test = ['train'] * len(embeddings['train']) + ['test'] * len(embeddings['test'])\n",
    "dat_dp_inds = np.concatenate([np.arange(0, len(embeddings['train'])), np.arange(0, len(embeddings['test']))], axis=0).astype('int')\n",
    "dat_inds = np.concatenate([dp.data['train']['inds'], dp.data['test']['inds']])\n",
    "\n",
    "err_cols = ['err_' + train_or_test + '_' + str(i) + '_' + str(img_index) for train_or_test, i, img_index in zip(dat_train_test, dat_dp_inds, dat_inds)]\n",
    "\n",
    "colormap = 'hsv'\n",
    "colors = plt.get_cmap(colormap)(np.linspace(0, 1, 4))\n",
    "\n",
    "px_size = [0.3873, 0.3873, 0.3873]\n",
    "\n",
    "train_or_test_split = ['test', 'train']\n",
    "\n",
    "img_paths_all = list()\n",
    "\n",
    "save_parent = opt.save_dir + os.sep + 'var_test' + os.sep\n",
    "if not os.path.exists(save_parent):\n",
    "    os.makedirs(save_parent)\n",
    "\n",
    "def convert_image(img):\n",
    "    img = img.data[0].cpu().numpy()\n",
    "    img = np.transpose(img, (3, 0, 1, 2))\n",
    "    \n",
    "    return img\n",
    "\n",
    "# For train or test\n",
    "# pdb.set_trace()\n",
    "\n",
    "for train_or_test, i, img_index, c in zip(dat_train_test, dat_dp_inds, dat_inds, range(0, len(dat_dp_inds))):\n",
    "    \n",
    "    \n",
    "    img_class = dp.image_classes[img_index]    \n",
    "    img_class_onehot = dp.get_classes([i], train_or_test, 'onehot')\n",
    "    \n",
    "    img_name = dp.get_image_paths([i], train_or_test)[0]    \n",
    "    img_name = os.path.basename(img_name)\n",
    "    img_name = img_name[0:img_name.rfind('.')]\n",
    "    \n",
    "    save_dir = save_parent + os.sep + train_or_test + os.sep + img_name\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    err_save_path = save_dir + os.sep + img_name + '.csv'\n",
    "    if os.path.exists(err_save_path):\n",
    "        continue\n",
    "\n",
    "    print(str(c) + os.sep + str(len(dat_dp_inds)))\n",
    "    #Load the image\n",
    "    img_in = dp.get_images([i], train_or_test)\n",
    "    img_in = Variable(img_in.cuda(gpu_id), volatile=True)\n",
    "\n",
    "    img_in_struct = torch.index_select(img_in, 1, torch.LongTensor([1]).cuda(gpu_id))\n",
    "\n",
    "    \n",
    "    \n",
    "    #pass forward through the model\n",
    "#     enc.gpu_ids = [gpu_id]\n",
    "#     z = enc(img_in)\n",
    "\n",
    "    shape_embedding = embeddings[train_or_test][i]\n",
    "    \n",
    "    #set the class label so it is correct\n",
    "    img_class_onehot_log = (img_class_onehot - 1) * 25\n",
    "\n",
    "    #go through embeddings\n",
    "    nembeddings = embeddings_all.size()[0]\n",
    "    inds = list(range(0,nembeddings))\n",
    "    data_iter = [inds[j:j+opt.batch_size] for j in range(0, len(inds), opt.batch_size)]        \n",
    "\n",
    "    errors = list()\n",
    "    z = [None] * 3\n",
    "\n",
    "    for j in range(0, len(data_iter)):\n",
    "#         print('cell: ' + str(i) + ', ' + str(j) + '/' + str(len(data_iter)))\n",
    "\n",
    "        batch_inds = data_iter[j]\n",
    "        batch_size = len(data_iter[j])\n",
    "\n",
    "        z[0] = Variable(img_class_onehot_log.repeat(batch_size, 1).float(), volatile=True).cuda(gpu_id)\n",
    "        z[1] = Variable(shape_embedding.repeat(batch_size,1), volatile=True).cuda(gpu_id)\n",
    "\n",
    "        struct_embeddings = embeddings_all.index(torch.Tensor(batch_inds).long())\n",
    "        z[2] = Variable(struct_embeddings, volatile=True).cuda(gpu_id)\n",
    "\n",
    "#             try:\n",
    "        imgs_out = dec(z)\n",
    "#             except:\n",
    "#                 pdb.set_trace()\n",
    "\n",
    "        imgs_out = torch.index_select(imgs_out, 1, torch.LongTensor([1]).cuda(gpu_id))\n",
    "\n",
    "        for img in imgs_out:\n",
    "            errors.append(loss(img, img_in_struct).data[0])\n",
    "\n",
    "    tot_inten = torch.sum(img_in_struct).data[0]\n",
    "\n",
    "    df = pd.DataFrame([[img_index, i, img_class, img_name, tot_inten, train_or_test] + errors], columns=['img_index', 'data_provider_index', 'label', 'path', 'tot_inten', 'train_or_test'] + err_cols)\n",
    "    df.to_csv(err_save_path)\n",
    "        \n",
    "print('Done computing errors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(dat_dp_inds[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_all_path = save_parent + os.sep + 'all_dat.csv'\n",
    "\n",
    "if not os.path.exists(save_all_path):\n",
    "    csv_list = list()\n",
    "\n",
    "    # For train or test\n",
    "    for train_or_test in train_or_test_split:\n",
    "        ndat = dp.get_n_dat(train_or_test)\n",
    "        # For each cell in the data split\n",
    "        for i in range(0, ndat):\n",
    "            print(str(i) + os.sep + str(ndat))\n",
    "\n",
    "            img_index = dp.data[train_or_test]['inds'][i]\n",
    "            img_class = dp.image_classes[img_index]\n",
    "\n",
    "            img_class_onehot = dp.get_classes([i], train_or_test, 'onehot')\n",
    "            img_name = os.path.basename(dp.image_paths[img_index])[0:-3]\n",
    "\n",
    "            save_dir = save_parent + os.sep + train_or_test + os.sep + img_name\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "\n",
    "            err_save_path = save_dir + os.sep + img_name + '.csv'\n",
    "            if os.path.exists(err_save_path):\n",
    "                csv_errors = pd.read_csv(err_save_path)\n",
    "#                 csv_errors['train_or_test'] = train_or_test\n",
    "                csv_list.append(csv_errors)\n",
    "            else:\n",
    "                print('Missing ' +  err_save_path)\n",
    "\n",
    "    errors_all = pd.DataFrame(csv_list)\n",
    "\n",
    "    errors_all.to_csv(save_all_path)\n",
    "else:\n",
    "    errors_all = pd.read_csv(save_all_path)\n",
    "\n",
    "    \n",
    "ulabels = np.unique(errors_all['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(num=None, figsize=(10, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "errors = errors_all.filter(regex='recon_err')\n",
    "errors_mean = errors.median(axis=1)\n",
    "\n",
    "errors_mean = np.divide(errors_mean, errors_all['tot_inten'])\n",
    "\n",
    "min_bin = np.min(errors_mean)\n",
    "max_bin = np.max(errors_mean)\n",
    "\n",
    "bins = np.linspace(min_bin, max_bin, 250)\n",
    "\n",
    "c = 0\n",
    "\n",
    "for train_or_test in train_or_test_split:\n",
    "    c+=1\n",
    "    plt.subplot(len(train_or_test_split), 1, c)\n",
    "    \n",
    "    train_inds = errors_all['train_or_test'] == train_or_test\n",
    "    \n",
    "    for label in ulabels:\n",
    "        label_inds = errors_all['label'] == label\n",
    "        \n",
    "        inds = np.logical_and(train_inds, label_inds)\n",
    "        \n",
    "        legend_key = label\n",
    "        plt.hist(errors_mean[inds], bins, alpha=0.5, label=legend_key, normed=True)\n",
    "        \n",
    "    \n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from data_providers.DataProvider3D import load_h5 \n",
    "from model_utils import tensor2img\n",
    "from IPython.core.display import display\n",
    "import PIL.Image\n",
    "\n",
    "def get_images(dp, paths):\n",
    "    dims = list(dp.imsize)\n",
    "    dims[0] = len(dp.opts['channelInds'])\n",
    "\n",
    "    dims.insert(0, len(paths))\n",
    "\n",
    "    images = torch.zeros(tuple(dims))\n",
    "\n",
    "    if dp.opts['dtype'] == 'half':\n",
    "        images = images.type(torch.HalfTensor)\n",
    "\n",
    "    c = 0\n",
    "    for h5_path in paths:\n",
    "        image = load_h5(h5_path)\n",
    "        image = torch.from_numpy(image)\n",
    "        images[c] = image.index_select(0, torch.LongTensor(dp.opts['channelInds'])).clone()\n",
    "        c += 1\n",
    "\n",
    "    # images *= 2\n",
    "    # images -= 1\n",
    "    return images\n",
    "\n",
    "\n",
    "\n",
    "for label in ulabels:\n",
    "    print(label)\n",
    "    label_inds = errors_all['label'] == label\n",
    "\n",
    "    imgs_flat = list()\n",
    "#         label_inds = errors_all['label'] == 'Alpha tubulin'\n",
    "    for train_or_test in train_or_test_split:\n",
    "#         print(train_or_test)\n",
    "        train_inds = errors_all['train_or_test'] == train_or_test\n",
    "        inds = np.where(np.logical_and(train_inds, label_inds))\n",
    "\n",
    "        inds_sorted = np.argsort(errors_mean[inds[0]])\n",
    "\n",
    "        errors_sub = errors_all.loc[inds[0][inds_sorted]]\n",
    "\n",
    "        im_paths = [dp.image_paths[i] for i in errors_sub.iloc[0:10]['img_index']]\n",
    "        img_out = get_images(dp, im_paths)\n",
    "        img_flat_low_err = tensor2img(img_out)\n",
    "        \n",
    "        im_paths = [dp.image_paths[i] for i in errors_sub.iloc[-10:]['img_index']]\n",
    "        img_out = get_images(dp, im_paths)\n",
    "        img_flat_hi_err = tensor2img(img_out)\n",
    "    \n",
    "        imsize = img_flat_low_err.shape\n",
    "        border = np.ones([imsize[0], 10, 3])\n",
    "    \n",
    "        img_flat = np.concatenate([img_flat_low_err, border, img_flat_hi_err], axis=1)\n",
    "        imgs_flat.append(img_flat)\n",
    "    \n",
    "    display(PIL.Image.fromarray(np.uint8(np.concatenate(imgs_flat)*255)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(imgs)flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_or_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors_mean[inds[0]].iloc[inds_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor2img(img_out)[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
