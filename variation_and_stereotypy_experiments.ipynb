{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DONT USE THIS. USE VARIATION_AND_STEREOTYPY_EXPERIMENTS.PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######    \n",
    "### This function prints off the most likely predicted \n",
    "### channels for each of the cells in our dataset\n",
    "#######\n",
    "\n",
    "#######    \n",
    "### Load the Model Parts\n",
    "#######\n",
    "\n",
    "import argparse\n",
    "import SimpleLogger as SimpleLogger\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils\n",
    "\n",
    "#have to do this import to be able to use pyplot in the docker image\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "from model_utils import set_gpu_recursive, load_model, save_state, save_progress, get_latent_embeddings, maybe_save\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "import pdb\n",
    "\n",
    "parent_dir = './test_aaegan/aaegan3Dv5_128D'\n",
    "\n",
    "model_dir = parent_dir + os.sep + 'struct_model' \n",
    "\n",
    "# logger_file = '{0}/logger_tmp.pkl'.format(model_dir)\n",
    "opt = pickle.load( open( '{0}/opt.pkl'.format(model_dir), \"rb\" ) )\n",
    "\n",
    "print(opt)\n",
    "\n",
    "DP = importlib.import_module(\"data_providers.\" + opt.dataProvider)\n",
    "model_provider = importlib.import_module(\"models.\" + opt.model_name)\n",
    "train_module = importlib.import_module(\"train_modules.\" + opt.train_module)\n",
    "\n",
    "torch.manual_seed(opt.myseed)\n",
    "torch.cuda.manual_seed(opt.myseed)\n",
    "np.random.seed(opt.myseed)\n",
    "\n",
    "if not os.path.exists(opt.save_dir):\n",
    "    os.makedirs(opt.save_dir)\n",
    "    \n",
    "if opt.nepochs_pt2 == -1:\n",
    "    opt.nepochs_pt2 = opt.nepochs\n",
    "\n",
    "opts = {}\n",
    "opts['verbose'] = True\n",
    "opts['pattern'] = '*.tif_flat.png'\n",
    "opts['out_size'] = [opt.imsize, opt.imsize]\n",
    "\n",
    "data_path = './data_{0}x{1}.pyt'.format(str(opts['out_size'][0]), str(opts['out_size'][1]))\n",
    "if os.path.exists(data_path):\n",
    "    dp = torch.load(data_path)\n",
    "else:\n",
    "    dp = DP.DataProvider(opt.imdir, opts)\n",
    "    torch.save(dp, data_path)\n",
    "    \n",
    "dp.opts['dtype'] = 'float'\n",
    "    \n",
    "if opt.ndat == -1:\n",
    "    opt.ndat = dp.get_n_dat('train')    \n",
    "\n",
    "iters_per_epoch = np.ceil(opt.ndat/opt.batch_size)    \n",
    "            \n",
    "#######    \n",
    "### Load REFERENCE MODEL\n",
    "#######\n",
    "\n",
    "embeddings_path = opt.save_parent + os.sep + 'ref_model' + os.sep + 'embeddings.pkl'\n",
    "if os.path.exists(embeddings_path):\n",
    "    embeddings = torch.load(embeddings_path)\n",
    "else:\n",
    "    embeddings = get_latent_embeddings(models['enc'], dp, opt)\n",
    "    torch.save(embeddings, embeddings_path)\n",
    "\n",
    "models = None\n",
    "optimizers = None\n",
    "    \n",
    "def get_ref(self, inds, train_or_test='train'):\n",
    "    inds = torch.LongTensor(inds)\n",
    "    return self.embeddings[train_or_test][inds]\n",
    "\n",
    "dp.embeddings = embeddings\n",
    "\n",
    "# do this thing to bind the get_ref method to the dataprovider object\n",
    "import types  \n",
    "dp.get_ref = types.MethodType(get_ref, dp)\n",
    "            \n",
    "\n",
    "opt.channelInds = [0, 1, 2]\n",
    "dp.opts['channelInds'] = opt.channelInds\n",
    "opt.nch = len(opt.channelInds)\n",
    "        \n",
    "opt.nClasses = dp.get_n_classes()\n",
    "opt.nRef = opt.nlatentdim\n",
    "\n",
    "try:\n",
    "    train_module = None\n",
    "    train_module = importlib.import_module(\"train_modules.\" + opt.train_module)\n",
    "    train_module = train_module.trainer(dp, opt)\n",
    "except:\n",
    "    pass    \n",
    "\n",
    "if not hasattr(opt, 'critRecon'):\n",
    "    opt.critRecon = 'BCELoss'\n",
    "    \n",
    "if not hasattr(opt, 'dtype'):\n",
    "    opt.dtype = 'float'\n",
    "\n",
    "# pdb.set_trace()\n",
    "opt.gpu_ids = [0, 1]\n",
    "models, optimizers, criterions, logger, opt = load_model(model_provider, opt)\n",
    "\n",
    "enc = models['enc']\n",
    "dec = models['dec']\n",
    "enc.train(False)\n",
    "dec.train(False)\n",
    "\n",
    "models = None\n",
    "optimizers = None\n",
    "\n",
    "\n",
    "print('Done loading model.')\n",
    "\n",
    "# Get the embeddings for the structure localization\n",
    "\n",
    "opt.batch_size = 100\n",
    "# opt.gpu_ids = [0,1,3]\n",
    "enc.gpu_ids = opt.gpu_ids\n",
    "dec.gpu_ids = opt.gpu_ids\n",
    "\n",
    "embeddings_path = opt.save_dir + os.sep + 'embeddings_struct.pkl'\n",
    "if os.path.exists(embeddings_path):\n",
    "    embeddings = torch.load(embeddings_path)\n",
    "else:\n",
    "    embeddings = get_latent_embeddings(enc, dp, opt)\n",
    "    torch.save(embeddings, embeddings_path)\n",
    "\n",
    "enc = None    \n",
    "    \n",
    "print('Done loading embeddings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######    \n",
    "### Main Loop\n",
    "#######\n",
    "\n",
    "import pdb\n",
    "from aicsimage.io import omeTifWriter\n",
    "from imgToProjection import imgtoprojection\n",
    "from IPython.core.display import display\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "opt.batch_size = 400\n",
    "gpu_id = opt.gpu_ids[0]\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "embeddings_all = torch.cat([embeddings['train'], embeddings['test']], 0);\n",
    "\n",
    "dat_train_test = ['train'] * len(embeddings['train']) + ['test'] * len(embeddings['test'])\n",
    "dat_dp_inds = np.concatenate([np.arange(0, len(embeddings['train'])), np.arange(0, len(embeddings['test']))], axis=0).astype('int')\n",
    "dat_inds = np.concatenate([dp.data['train']['inds'], dp.data['test']['inds']])\n",
    "\n",
    "err_cols = ['err_' + train_or_test + '_' + str(i) + '_' + str(img_index) for train_or_test, i, img_index in zip(dat_train_test, dat_dp_inds, dat_inds)]\n",
    "\n",
    "colormap = 'hsv'\n",
    "colors = plt.get_cmap(colormap)(np.linspace(0, 1, 4))\n",
    "\n",
    "px_size = [0.3873, 0.3873, 0.3873]\n",
    "\n",
    "train_or_test_split = ['test', 'train']\n",
    "\n",
    "img_paths_all = list()\n",
    "\n",
    "save_parent = opt.save_dir + os.sep + 'var_test' + os.sep\n",
    "if not os.path.exists(save_parent):\n",
    "    os.makedirs(save_parent)\n",
    "\n",
    "def convert_image(img):\n",
    "    img = img.data[0].cpu().numpy()\n",
    "    img = np.transpose(img, (3, 0, 1, 2))\n",
    "    \n",
    "    return img\n",
    "\n",
    "# For train or test\n",
    "# pdb.set_trace()\n",
    "\n",
    "for train_or_test, i, img_index, c in zip(dat_train_test, dat_dp_inds, dat_inds, range(0, len(dat_dp_inds))):\n",
    "    \n",
    "    \n",
    "    img_class = dp.image_classes[img_index]    \n",
    "    img_class_onehot = dp.get_classes([i], train_or_test, 'onehot')\n",
    "    \n",
    "    img_name = dp.get_image_paths([i], train_or_test)[0]    \n",
    "    img_name = os.path.basename(img_name)\n",
    "    img_name = img_name[0:img_name.rfind('.')]\n",
    "    \n",
    "    save_dir = save_parent + os.sep + train_or_test + os.sep + img_name\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    err_save_path = save_dir + os.sep + img_name + '.csv'\n",
    "    if os.path.exists(err_save_path):\n",
    "        continue\n",
    "\n",
    "    print(str(c) + os.sep + str(len(dat_dp_inds)))\n",
    "    #Load the image\n",
    "    img_in = dp.get_images([i], train_or_test)\n",
    "    img_in = Variable(img_in.cuda(gpu_id), volatile=True)\n",
    "\n",
    "    img_in_struct = torch.index_select(img_in, 1, torch.LongTensor([1]).cuda(gpu_id))\n",
    "\n",
    "    \n",
    "    \n",
    "    #pass forward through the model\n",
    "#     enc.gpu_ids = [gpu_id]\n",
    "#     z = enc(img_in)\n",
    "\n",
    "    shape_embedding = embeddings[train_or_test][i]\n",
    "    \n",
    "    #set the class label so it is correct\n",
    "    img_class_onehot_log = (img_class_onehot - 1) * 25\n",
    "\n",
    "    #go through embeddings\n",
    "    nembeddings = embeddings_all.size()[0]\n",
    "    inds = list(range(0,nembeddings))\n",
    "    data_iter = [inds[j:j+opt.batch_size] for j in range(0, len(inds), opt.batch_size)]        \n",
    "\n",
    "    errors = list()\n",
    "    z = [None] * 3\n",
    "\n",
    "    for j in range(0, len(data_iter)):\n",
    "#         print('cell: ' + str(i) + ', ' + str(j) + '/' + str(len(data_iter)))\n",
    "\n",
    "        batch_inds = data_iter[j]\n",
    "        batch_size = len(data_iter[j])\n",
    "\n",
    "        z[0] = Variable(img_class_onehot_log.repeat(batch_size, 1).float(), volatile=True).cuda(gpu_id)\n",
    "        z[1] = Variable(shape_embedding.repeat(batch_size,1), volatile=True).cuda(gpu_id)\n",
    "\n",
    "        struct_embeddings = embeddings_all.index(torch.Tensor(batch_inds).long())\n",
    "        z[2] = Variable(struct_embeddings, volatile=True).cuda(gpu_id)\n",
    "\n",
    "#             try:\n",
    "        imgs_out = dec(z)\n",
    "#             except:\n",
    "#                 pdb.set_trace()\n",
    "\n",
    "        imgs_out = torch.index_select(imgs_out, 1, torch.LongTensor([1]).cuda(gpu_id))\n",
    "\n",
    "        for img in imgs_out:\n",
    "            errors.append(loss(img, img_in_struct).data[0])\n",
    "\n",
    "    tot_inten = torch.sum(img_in_struct).data[0]\n",
    "\n",
    "    df = pd.DataFrame([[img_index, i, img_class, img_name, tot_inten, train_or_test] + errors], columns=['img_index', 'data_provider_index', 'label', 'path', 'tot_inten', 'train_or_test'] + err_cols)\n",
    "    df.to_csv(err_save_path)\n",
    "        \n",
    "print('Done computing errors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(dat_dp_inds[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_all_path = save_parent + os.sep + 'all_dat.csv'\n",
    "\n",
    "if not os.path.exists(save_all_path):\n",
    "    csv_list = list()\n",
    "\n",
    "    # For train or test\n",
    "    for train_or_test in train_or_test_split:\n",
    "        ndat = dp.get_n_dat(train_or_test)\n",
    "        # For each cell in the data split\n",
    "        for i in range(0, ndat):\n",
    "            print(str(i) + os.sep + str(ndat))\n",
    "\n",
    "            img_index = dp.data[train_or_test]['inds'][i]\n",
    "            img_class = dp.image_classes[img_index]\n",
    "\n",
    "            img_class_onehot = dp.get_classes([i], train_or_test, 'onehot')\n",
    "            img_name = os.path.basename(dp.image_paths[img_index])[0:-3]\n",
    "\n",
    "            save_dir = save_parent + os.sep + train_or_test + os.sep + img_name\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "\n",
    "            err_save_path = save_dir + os.sep + img_name + '.csv'\n",
    "            if os.path.exists(err_save_path):\n",
    "                csv_errors = pd.read_csv(err_save_path)\n",
    "#                 csv_errors['train_or_test'] = train_or_test\n",
    "                csv_list.append(csv_errors)\n",
    "            else:\n",
    "                print('Missing ' +  err_save_path)\n",
    "\n",
    "    errors_all = pd.DataFrame(csv_list)\n",
    "\n",
    "    errors_all.to_csv(save_all_path)\n",
    "else:\n",
    "    errors_all = pd.read_csv(save_all_path)\n",
    "\n",
    "    \n",
    "ulabels = np.unique(errors_all['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(num=None, figsize=(10, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "errors = errors_all.filter(regex='recon_err')\n",
    "errors_mean = errors.median(axis=1)\n",
    "\n",
    "errors_mean[np.isnan(errors_mean)] = math.huge\n",
    "\n",
    "errors_mean = np.divide(errors_mean, errors_all['tot_inten'])\n",
    "\n",
    "min_bin = np.prctile(errors_mean, 2)\n",
    "max_bin = np.prctile(errors_mean, 98)\n",
    "\n",
    "bins = np.linspace(min_bin, max_bin, 250)\n",
    "\n",
    "c = 0\n",
    "\n",
    "for train_or_test in train_or_test_split:\n",
    "    c+=1\n",
    "    plt.subplot(len(train_or_test_split), 1, c)\n",
    "    \n",
    "    train_inds = errors_all['train_or_test'] == train_or_test\n",
    "    \n",
    "    for label in ulabels:\n",
    "        label_inds = errors_all['label'] == label\n",
    "        \n",
    "        inds = np.logical_and(train_inds, label_inds)\n",
    "        \n",
    "        legend_key = label\n",
    "        plt.hist(errors_mean[inds], bins, alpha=0.5, label=legend_key, normed=True)\n",
    "        \n",
    "    \n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from data_providers.DataProvider3D import load_h5 \n",
    "from model_utils import tensor2img\n",
    "from IPython.core.display import display\n",
    "import PIL.Image\n",
    "\n",
    "def get_images(dp, paths):\n",
    "    dims = list(dp.imsize)\n",
    "    dims[0] = len(dp.opts['channelInds'])\n",
    "\n",
    "    dims.insert(0, len(paths))\n",
    "\n",
    "    images = torch.zeros(tuple(dims))\n",
    "\n",
    "    if dp.opts['dtype'] == 'half':\n",
    "        images = images.type(torch.HalfTensor)\n",
    "\n",
    "    c = 0\n",
    "    for h5_path in paths:\n",
    "        image = load_h5(h5_path)\n",
    "        image = torch.from_numpy(image)\n",
    "        images[c] = image.index_select(0, torch.LongTensor(dp.opts['channelInds'])).clone()\n",
    "        c += 1\n",
    "\n",
    "    # images *= 2\n",
    "    # images -= 1\n",
    "    return images\n",
    "\n",
    "\n",
    "\n",
    "for label in ulabels:\n",
    "    print(label)\n",
    "    label_inds = errors_all['label'] == label\n",
    "\n",
    "    imgs_flat = list()\n",
    "#         label_inds = errors_all['label'] == 'Alpha tubulin'\n",
    "    for train_or_test in train_or_test_split:\n",
    "#         print(train_or_test)\n",
    "        train_inds = errors_all['train_or_test'] == train_or_test\n",
    "        inds = np.where(np.logical_and(train_inds, label_inds))\n",
    "\n",
    "        inds_sorted = np.argsort(errors_mean[inds[0]])\n",
    "\n",
    "        errors_sub = errors_all.loc[inds[0][inds_sorted]]\n",
    "\n",
    "        im_paths = [dp.image_paths[i] for i in errors_sub.iloc[0:10]['img_index']]\n",
    "        img_out = get_images(dp, im_paths)\n",
    "        img_flat_low_err = tensor2img(img_out)\n",
    "        \n",
    "        im_paths = [dp.image_paths[i] for i in errors_sub.iloc[-10:]['img_index']]\n",
    "        img_out = get_images(dp, im_paths)\n",
    "        img_flat_hi_err = tensor2img(img_out)\n",
    "    \n",
    "        imsize = img_flat_low_err.shape\n",
    "        border = np.ones([imsize[0], 10, 3])\n",
    "    \n",
    "        img_flat = np.concatenate([img_flat_low_err, border, img_flat_hi_err], axis=1)\n",
    "        imgs_flat.append(img_flat)\n",
    "    \n",
    "    display(PIL.Image.fromarray(np.uint8(np.concatenate(imgs_flat)*255)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "classes = dp.get_classes(np.arange(0, dp.get_n_dat('train')), 'train').numpy()\n",
    "embeddings_tmp = embeddings['train'].numpy()\n",
    "\n",
    "uclasses = np.unique(classes)\n",
    "\n",
    "ndims = embeddings['train'].shape[1]\n",
    "nrows = ndims/2\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 2*nrows))\n",
    "\n",
    "counter = 1\n",
    "           \n",
    "for dim in np.arange(0, ndims, 2):\n",
    "\n",
    "    for uclass in uclasses:\n",
    "\n",
    "        \n",
    "        class_inds = classes == uclass;\n",
    "\n",
    "\n",
    "        plt.subplot(nrows, len(uclasses), counter)\n",
    "        plt.scatter(embeddings_tmp[class_inds,dim], embeddings_tmp[class_inds,dim+1], c=classes[class_inds], s=0.1)\n",
    "        plt.axis('equal')\n",
    "        plt.axis([-4, 4, -4, 4])\n",
    "        \n",
    "        \n",
    "        if uclass == 0:\n",
    "            plt.xlabel('x ' + str(dim))\n",
    "            plt.ylabel('x ' + str(dim+1))\n",
    "\n",
    "        if dim == 0: plt.title(dp.label_names[uclass])\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "plt.savefig('{0}/latent_space.png'.format(model_dir), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
