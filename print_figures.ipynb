{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(Diters=5, DitersAlt=100, batch_size=30, channelInds=[0, 2], channels_pt1=[0, 2], channels_pt2=[0, 1, 2], critRecon='BCELoss', dataProvider='DataProvider3Dh5', data_save_path='./test_aaegan/aaegan3Dv6_128D_latent_v4/data.pyt', decDRatio=0.0001, dtype='float', encDRatio=0.0001, gpu_ids=[0, 1], imdir='/root/results/ipp_dataset_cellnuc_seg_curated_8_24_17', latentDistribution='gaussian', lrDec=5e-05, lrDecD=5e-05, lrEnc=5e-05, lrEncD=0.01, model_name='aaegan3Dv6', myseed=0, nClasses=0, nRef=0, nch=2, ndat=14302, nepochs=250, nepochs_pt2=300, nlatentdim=128, noise=1e-05, optimizer='adam', saveProgressIter=1, saveStateIter=1, save_dir='./test_aaegan/aaegan3Dv6_128D_latent_v4//ref_model', save_parent='./test_aaegan/aaegan3Dv6_128D_latent_v4/', train_module='aaegan_trainv3')\n",
      "Loading from /root/projects/pytorch_integrated_cell/test_aaegan/aaegan3Dv6_128D_latent_v4/ref_model\n",
      "Namespace(Diters=5, DitersAlt=100, batch_size=30, channelInds=[0, 1, 2], channels_pt1=[0, 2], channels_pt2=[0, 1, 2], critRecon='BCELoss', dataProvider='DataProvider3Dh5', data_save_path='./test_aaegan/aaegan3Dv6_128D_latent_v4/data.pyt', decDRatio=0.0001, dtype='float', encDRatio=0.0001, gpu_ids=[0, 1], imdir='/root/results/ipp_dataset_cellnuc_seg_curated_8_24_17', latentDistribution='gaussian', latentSample=<function sampleGaussian at 0x7fdd8d46d378>, lrDec=5e-05, lrDecD=5e-05, lrEnc=5e-05, lrEncD=0.01, model_name='aaegan3Dv6', myseed=0, nClasses=10, nRef=128, nch=3, nclasses=1, ndat=14302, nepochs=250, nepochs_pt2=300, nlatentdim=128, noise=1e-05, noise_std=0, optimizer='adam', saveProgressIter=1, saveStateIter=1, save_dir='./test_aaegan/aaegan3Dv6_128D_latent_v4//struct_model', save_parent='./test_aaegan/aaegan3Dv6_128D_latent_v4/', train_module='aaegan_trainv3')\n",
      "Loading from /root/projects/pytorch_integrated_cell/test_aaegan/aaegan3Dv6_128D_latent_v4/struct_model\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import model_utils\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pdb\n",
    "\n",
    "parent_dir = '/root/projects/pytorch_integrated_cell/test_aaegan/aaegan3Dv6_128D_latent_v4'\n",
    "gpu_ids = [0, 1]\n",
    "batch_size = 100\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--parent_dir', help='save dir')\n",
    "# parser.add_argument('--gpu_ids', nargs='+', type=int, default=0, help='gpu id')\n",
    "# parser.add_argument('--batch_size', type=int, default=400, help='batch_size')\n",
    "# parser.add_argument('--overwrite', type=bool, default=False, help='overwrite existing results')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# model_dir = args.parent_dir + os.sep + 'struct_model' \n",
    "\n",
    "\n",
    "figure_dir = parent_dir + os.sep + 'figures'\n",
    "\n",
    "if not os.path.exists(figure_dir):\n",
    "    os.makedirs(figure_dir)\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(2)\n",
    "torch.cuda.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_dir = parent_dir + os.sep + 'ref_model'\n",
    "opt_ref = pickle.load(open( '{0}/opt.pkl'.format(model_dir), \"rb\" ))\n",
    "print(opt_ref)\n",
    "opt_ref.gpu_ids = gpu_ids\n",
    "\n",
    "opt_ref.save_dir = model_dir\n",
    "models, _, _, logger_ref, _ = model_utils.load_model(opt_ref.model_name, opt_ref)\n",
    "enc_ref = models['enc']\n",
    "dec_ref = models['dec']\n",
    "\n",
    "enc_ref.train(False)\n",
    "dec_ref.train(False)\n",
    "models = None\n",
    "\n",
    "dp_ref = model_utils.load_data_provider(opt_ref.data_save_path, opt_ref.imdir, opt_ref.dataProvider)\n",
    "dp_ref.opts['channelInds'] = opt_ref.channelInds\n",
    "\n",
    "model_dir = parent_dir + os.sep + 'struct_model'\n",
    "opt = pickle.load(open( '{0}/opt.pkl'.format(model_dir), \"rb\" ))\n",
    "print(opt)\n",
    "opt.gpu_ids = gpu_ids\n",
    "\n",
    "opt.save_dir = model_dir\n",
    "models, _, _, logger, _ = model_utils.load_model(opt.model_name, opt)\n",
    "enc = models['enc']\n",
    "dec = models['dec']\n",
    "\n",
    "enc.train(False)\n",
    "dec.train(False)\n",
    "models = None\n",
    "\n",
    "dp = model_utils.load_data_provider(opt.data_save_path, opt.imdir, opt.dataProvider)\n",
    "\n",
    "\n",
    "print('done loading models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parent_dir + os.sep + 'ref_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from imgToProjection import imgtoprojection\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "def tensor2img(imgs, colors=None):\n",
    "\n",
    "    \n",
    "    if colors is None:\n",
    "            colormap = 'hsv'\n",
    "            colors = plt.get_cmap(colormap)(np.linspace(0, 1, imgs.shape[1]+1))\n",
    "    \n",
    "    imgs = imgs.numpy()\n",
    "    im_out = list()\n",
    "    \n",
    "    #for every image\n",
    "    for i in range(0, imgs.shape[0]):\n",
    "        img = imgs[i]\n",
    "        \n",
    "        #contrast adjust each channel\n",
    "        for j in range(0, img.shape[0]):\n",
    "            maxval = np.max(img[j])\n",
    "            if maxval > 0:\n",
    "                img[j] = img[j]/maxval\n",
    "            \n",
    "        \n",
    "        img = imgtoprojection(np.swapaxes(img, 1, 3), proj_all=True, colors = colors, global_adjust=True)\n",
    "        img = np.swapaxes(img, 0, 2)\n",
    "        \n",
    "        img = np.flip(np.flip(img,0), 1)\n",
    "        \n",
    "        #very light border between each projection\n",
    "        img[:,-2:,:] = .25\n",
    "        img[-2:,:,:] = .25\n",
    "        \n",
    "        im_out.append(img)\n",
    "\n",
    "    img = np.concatenate(im_out, 1)\n",
    "\n",
    "    return img\n",
    "\n",
    "def print_fig1(dp, save_path, save_path_struct, n_per_row = 6, colors=[[1,0,1], [1,1,0], [0,1,1]]):\n",
    "    #this figure is #classes by n_per_row max project image of cells. \n",
    "\n",
    "    ntrain = dp.get_n_dat('train')\n",
    "    \n",
    "    train_classes = dp.get_classes(np.arange(0, ntrain), 'train').numpy()\n",
    "    class_names = dp.label_names\n",
    "    \n",
    "    image_list = list()\n",
    "    image_list_struct = list()\n",
    "    \n",
    "    for i in range(0, len(class_names)):\n",
    "        inds = np.where(train_classes == i)[0]\n",
    "        np.random.shuffle(inds)\n",
    "        \n",
    "        #make the CMY image\n",
    "        images = dp.get_images(inds[0:n_per_row], 'train')\n",
    "        images_flat = tensor2img(images, colors)\n",
    "        image_list.append(images_flat)\n",
    "        \n",
    "        #make the struct-only Yellow image\n",
    "        images[:, [0,2], :, :,:] = images[:, [0,2], :, :,:].fill_(0) #not sure why i have to do it this way, but it doesn't work without the assigment\n",
    "        \n",
    "        images_flat_struct = tensor2img(images, colors)\n",
    "        image_list_struct.append(images_flat_struct)\n",
    "        \n",
    "        \n",
    "    images = np.concatenate(image_list, axis=0)\n",
    "    scipy.misc.imsave(save_path, images)\n",
    "    \n",
    "    images_struct = np.concatenate(image_list_struct, axis=0)\n",
    "    scipy.misc.imsave(save_path_struct, images_struct)\n",
    "                                   \n",
    "def print_fig2(enc, dec, dp, save_path, save_path_struct, n_per_row = 6, colors=[[1,0,1], [1,1,0], [0,1,1]], required_test_inds=None):\n",
    "    ntrain = dp.get_n_dat('train')\n",
    "    train_classes = dp.get_classes(np.arange(0, ntrain), 'train').numpy()\n",
    "    \n",
    "    class_names = dp.label_names\n",
    "    \n",
    "    nclasses = len(class_names)\n",
    "    train_inds = np.int_(np.zeros(nclasses))\n",
    "    for i in range(0, len(class_names)):\n",
    "        images_w = list()\n",
    "        class_inds = np.where(train_classes == i)[0]\n",
    "        np.random.shuffle(class_inds)\n",
    "        train_inds[i] = class_inds[0]\n",
    "        \n",
    "    train_images = dp.get_images(train_inds, 'train')\n",
    "    train_images_struct = train_images.clone()\n",
    "    train_images_struct[:, [0,2], :, :,:] = train_images_struct[:, [0,2], :, :,:].fill_(0)\n",
    "    \n",
    "    \n",
    "    n_per_row_tmp = n_per_row - len(required_test_inds)\n",
    "    \n",
    "    ntest = dp.get_n_dat('test')\n",
    "    test_inds= np.arange(0, ntest)\n",
    "    np.random.shuffle(test_inds)\n",
    "    test_inds = test_inds[np.arange(0, n_per_row_tmp-1)]\n",
    "    \n",
    "    test_inds = np.concatenate([test_inds, required_test_inds])\n",
    "    \n",
    "    test_images = dp.get_images(test_inds, 'test')\n",
    "    \n",
    "    images_h = list()\n",
    "    images_h_struct = list()   \n",
    "    \n",
    "    for i in range(0, len(class_names)):\n",
    "        images_w = list()\n",
    "        images_w_struct = list()\n",
    "        \n",
    "        train_inds = np.where(train_classes == i)[0]\n",
    "        np.random.shuffle(train_inds)\n",
    "        \n",
    "        for j in range(0, n_per_row-1):\n",
    "            image = Variable(torch.unsqueeze(test_images[j], 0))\n",
    "            z = enc(image)\n",
    "            \n",
    "            z[0].data.fill_(-100)\n",
    "            z[0].data[0,i] = 0\n",
    "\n",
    "            z[-1].data.fill_(0)\n",
    "    \n",
    "            image = dec(z)\n",
    "        \n",
    "            image = image.data.cpu()\n",
    "        \n",
    "            image[:, [0,2], :, :,:] = test_images[j][[0,2],:,:,:]\n",
    "        \n",
    "            images_w.append(tensor2img(image, colors))\n",
    "            \n",
    "            image[:, [0,2], :, :,:] = image[:, [0,2], :, :,:].fill_(0)\n",
    "            images_w_struct.append(tensor2img(image, colors))\n",
    "        \n",
    "        #CMY version\n",
    "        images_w = np.concatenate(images_w, axis=1)\n",
    "        images_w[:,-2:,:] = 0.5\n",
    "        image_flat = tensor2img(torch.unsqueeze(train_images[i], 0), colors)\n",
    "        images_w = np.concatenate([images_w, image_flat], axis=1)        \n",
    "        images_h.append(images_w)\n",
    "        \n",
    "        #Struct-only Yellow version\n",
    "        images_w_struct = np.concatenate(images_w_struct, axis=1)\n",
    "        images_w_struct[:,-2:,:] = 0.5\n",
    "        image_flat = tensor2img(torch.unsqueeze(train_images_struct[i], 0), colors)\n",
    "        images_w_struct = np.concatenate([images_w_struct, image_flat], axis=1)        \n",
    "        images_h_struct.append(images_w_struct)\n",
    "        \n",
    "    images = np.concatenate(images_h, axis=0)\n",
    "    scipy.misc.imsave(save_path, images)\n",
    "    \n",
    "    images_struct = np.concatenate(images_h_struct, axis=0)\n",
    "    scipy.misc.imsave(save_path_struct, images_struct)\n",
    "    \n",
    "def print_conf_mat(enc, dp, figure_dir, batch_size, default_gpu_id):\n",
    "\n",
    "\n",
    "    train_or_test_groups = ['test', 'train']\n",
    "\n",
    "    cf_out = dict()\n",
    "\n",
    "    for train_or_test in train_or_test_groups:\n",
    "        save_path = figure_dir + os.sep + 'conf_mat_' + train_or_test + '.csv'\n",
    "        \n",
    "        \n",
    "        y_hat = list()\n",
    "        y = list()\n",
    "\n",
    "        ndat = dp.get_n_dat(train_or_test)\n",
    "\n",
    "        intervals = np.arange(0, ndat, batch_size)\n",
    "\n",
    "        for i in tqdm(intervals):\n",
    "            batch_range = i + batch_size\n",
    "            if batch_range > ndat:\n",
    "                batch_range = ndat\n",
    "\n",
    "\n",
    "            dat_inds = np.arange(i, batch_range)\n",
    "\n",
    "            images = Variable(dp.get_images(dat_inds,train_or_test)).cuda(default_gpu_id)\n",
    "            labels = dp.get_classes(dat_inds,train_or_test).numpy()\n",
    "\n",
    "            z = enc(images)\n",
    "\n",
    "            y_hat.append(np.argmax(z[0].data.cpu().numpy(), axis=1))\n",
    "            y.append(labels)\n",
    "\n",
    "            del images, labels, z\n",
    "\n",
    "\n",
    "        y = np.concatenate(y, axis=0)\n",
    "        y_hat = np.concatenate(y_hat, axis=0)\n",
    "\n",
    "        cf = confusion_matrix(y, y_hat)\n",
    "        pd.DataFrame(cf, columns=dp.label_names).to_csv(save_path, index=False)\n",
    "\n",
    "        cf_out[train_or_test] = cf \n",
    "        \n",
    "    return cf_out\n",
    "\n",
    "def print_recon(enc, dec, dp, save_path, default_gpu_id, colors=[[1,0,1], [1,1,0], [0,1,1]]):\n",
    "    \n",
    "    train_or_test_groups = ['train', 'test'] \n",
    "\n",
    "    class_names = dp.label_names\n",
    "    \n",
    "\n",
    "    images_train_test = list()\n",
    "    \n",
    "    for train_or_test in train_or_test_groups:\n",
    "        \n",
    "        ntrain = dp.get_n_dat(train_or_test)\n",
    "        train_classes = dp.get_classes(np.arange(0, ntrain), train_or_test).numpy()\n",
    "        \n",
    "        image_in = list()\n",
    "        image_out = list()\n",
    "        \n",
    "        for i in range(0, len(class_names)):\n",
    "            inds = np.where(train_classes == i)[0]\n",
    "#             np.random.shuffle(inds)\n",
    "\n",
    "            #make the CMY image\n",
    "            images = dp.get_images([inds[0]], train_or_test)\n",
    "\n",
    "            image_in_flat = tensor2img(images, colors)\n",
    "            image_in.append(image_in_flat)\n",
    "            \n",
    "            image_recon = dec(enc(Variable(images).cuda(default_gpu_id)))\n",
    "            image_out_flat = tensor2img(image_recon.data.cpu(), colors)\n",
    "            image_out.append(image_out_flat)\n",
    "\n",
    "#             #make the struct-only Yellow image\n",
    "#             images[:, [0,2], :, :,:] = images[:, [0,2], :, :,:].fill_(0) #not sure why i have to do it this way, but it doesn't work without the assigment\n",
    "\n",
    "#             images_flat_struct = tensor2img(images, colors)\n",
    "#             image_list_struct.append(images_flat_struct)\n",
    "        \n",
    "        \n",
    "        image_in = np.concatenate(image_in, axis=1)\n",
    "        image_out = np.concatenate(image_out, axis=1)\n",
    "        \n",
    "        images = np.concatenate([image_in, image_out], axis=0)\n",
    "        images_train_test.append(images)\n",
    "        \n",
    "    images_train_test = np.concatenate(images_train_test, axis=0)\n",
    "    scipy.misc.imsave(save_path, images_train_test)\n",
    "    \n",
    "#     images_struct = np.concatenate(image_list_struct, axis=0)\n",
    "#     scipy.misc.imsave(save_path_struct, images_struct)\n",
    "\n",
    "\n",
    "def print_history(logger, save_path, r_or_s):\n",
    "    field_order = ['reconLoss',\n",
    "#                      'minimaxEncDLoss',\n",
    "                     'encDLoss',\n",
    "#                      'minimaxDecDLoss',\n",
    "                     'decDLoss',\n",
    "                     'classLoss',\n",
    "                     'refLoss']\n",
    "    \n",
    "    \n",
    "    field_dict = {'reconLoss': '$\\mathcal{L}_{X_{' + r_or_s + '}}$',\n",
    "                  'minimaxEncDLoss': '$\\mathcal{L}_{mmEncD^{' + r_or_s + '}}$',\n",
    "                  'encDLoss': '$\\mathcal{L}_{EncD^{' + r_or_s + '}}$',\n",
    "                  'minimaxDecDLoss': '$\\mathcal{L}_{mmDecD^{' + r_or_s + '}}$',\n",
    "                  'decDLoss': '$\\mathcal{L}_{DecD^{' + r_or_s + '}}$',\n",
    "                  'classLoss': '$\\mathcal{L}_{\\hat{' + r_or_s + '}}$',\n",
    "                  'refLoss': '$\\mathcal{L}_{\\hat{x}^{' + r_or_s + '}}$'}\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "    for i in range(0, len(field_order)):\n",
    "        field = field_order[i]\n",
    "        if field in logger.fields:\n",
    "            plt.plot(logger.log['iter'], logger.log[field], label=field_dict[field])\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title('History')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "def print_latent_plot(embeddings, save_path, r_or_s, dims=[0,1]):\n",
    "    \n",
    "    train_or_test_groups = ['train', 'test'] \n",
    "    \n",
    "    plt.figure(num=None, figsize=(4, 4), dpi=120, facecolor='w', edgecolor='k')\n",
    "    \n",
    "    handles = list()\n",
    "    for train_or_test in train_or_test_groups:\n",
    "        embed_points = embeddings[train_or_test].numpy()\n",
    "        h = plt.scatter(embed_points[:,dims[0]], embed_points[:,dims[1]], s=1, alpha=0.5)\n",
    "        \n",
    "        h = mpatches.Patch(color=h.get_facecolor()[0], label=train_or_test)\n",
    "        handles.append(h)\n",
    "        \n",
    "    plt.xlabel('$z^{' + r_or_s + '}_{' + str(dims[0]+1) + '}$')\n",
    "    plt.ylabel('$z^{' + r_or_s + '}_{' + str(dims[1]+1) + '}$')    \n",
    "            \n",
    "    plt.legend(handles, train_or_test_groups, loc=1)\n",
    "        \n",
    "    ax_range = 4\n",
    "#     plt.axis([-ax_range, ax_range, -ax_range, ax_range])\n",
    "#     plt.axis('equal')\n",
    "    \n",
    "    plt.xlim(-ax_range, ax_range)\n",
    "    plt.ylim(-ax_range, ax_range)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    \n",
    "    plt.close('all')\n",
    "    \n",
    "    pass\n",
    "    \n",
    "def print_latent_grid(dec, ref_or_class_num, save_path, default_gpu_id, dims=[0,1], std=1.5, nsamples=5, colors=[[1,0,1], [1,1,0], [0,1,1]]):\n",
    "    \n",
    "    z = list()\n",
    "    \n",
    "    if ref_or_class_num is not 'ref':\n",
    "        label = Variable(torch.Tensor(1, 10).fill_(-50).cuda(default_gpu_id))\n",
    "        label.data[0][ref_or_class_num] = 0\n",
    "\n",
    "        z.append(label)\n",
    "        \n",
    "        z.append(Variable(torch.Tensor(1, 128).fill_(0).cuda(default_gpu_id)))\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    z.append(Variable(torch.Tensor(1, 128).fill_(0).cuda(default_gpu_id)))\n",
    "    \n",
    "    samples = np.linspace(-std, std, nsamples)\n",
    "    \n",
    "    images_w = list()\n",
    "    for i in samples:\n",
    "        images_h = list()\n",
    "        for j in samples:\n",
    "            z[-1].data[0][dims[0]] = i\n",
    "            z[-1].data[0][dims[1]] = j\n",
    "    \n",
    "            im_out = dec(z)\n",
    "            image_out_flat = tensor2img(im_out.data.cpu(), colors)\n",
    "            images_h.append(image_out_flat)\n",
    "            \n",
    "        images_w.append(np.concatenate(images_h, axis=0))\n",
    "        \n",
    "    image_out = np.concatenate(images_w, axis=1)\n",
    "    \n",
    "    scipy.misc.imsave(save_path, image_out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig1_path = figure_dir + os.sep + 'fig1.png'\n",
    "fig1_s1_path = figure_dir + os.sep + 'fig1_s1.png'\n",
    "print_fig1(dp, fig1_path, fig1_s1_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig2_path = figure_dir + os.sep + 'fig2.png'\n",
    "fig2_s2_path = figure_dir + os.sep + 'fig2_s2.png'\n",
    "print_fig2(enc, dec, dp, fig2_path, fig2_s2_path, n_per_row=6, required_test_inds=[975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ref_path = figure_dir + os.sep + 'ref_history.png'\n",
    "print_history(logger_ref, history_ref_path)\n",
    "\n",
    "history_struct_path = figure_dir + os.sep + 'struct_history.png'\n",
    "print_history(logger, history_struct_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recon_path = figure_dir + os.sep + 'struct_recon.png'\n",
    "print_recon(enc, dec, dp, recon_path, gpu_ids[0])\n",
    "\n",
    "\n",
    "recon_path = figure_dir + os.sep + 'ref_recon.png'\n",
    "print_recon(enc_ref, dec_ref, dp_ref, recon_path, gpu_ids[0], colors=[[1,0,1], [0,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf_mat_path = figure_dir + os.sep + 'conf_mat'\n",
    "print_conf_mat(enc, dp, figure_dir, 200, gpu_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_recon_path = figure_dir + os.sep + 'ref_latent.png'\n",
    "embeddings_path = parent_dir + os.sep + 'ref_model' + os.sep + 'embeddings.pkl'\n",
    "embeddings = model_utils.load_embeddings(embeddings_path)\n",
    "\n",
    "print_latent_plot(embeddings, latent_recon_path, 'r')\n",
    "\n",
    "\n",
    "latent_recon_path = figure_dir + os.sep + 'struct_latent.png'\n",
    "embeddings_path = parent_dir + os.sep + 'struct_model' + os.sep + 'embeddings.pkl'\n",
    "embeddings = model_utils.load_embeddings(embeddings_path)\n",
    "\n",
    "print_latent_plot(embeddings, latent_recon_path, 's')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std = 3\n",
    "\n",
    "latent_grid_path = figure_dir + os.sep + 'grid_ref.png'\n",
    "print_latent_grid(dec_ref, 'ref', latent_grid_path, gpu_ids[0], std=std, colors=[[1,0,1], [0,1,1]])\n",
    "\n",
    "latent_grid_path = figure_dir + os.sep + 'grid_struct.png'\n",
    "\n",
    "for i in range(0, dp.get_n_classes()):\n",
    "    latent_grid_path = figure_dir + os.sep + 'grid_struct_' + dp.label_names[i] + '.png'\n",
    "    print_latent_grid(dec, i, latent_grid_path, gpu_ids[0], std=std, colors=[[0,0,0], [1,1,0], [0,0,0]])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(np.where(dp.data['test']['inds']==8824))\n",
    "\n",
    "print(np.where(dp.data['test']['inds']==9238))\n",
    "\n",
    "print(np.where(dp.data['test']['inds']==9538))\n",
    "\n",
    "print(np.where(dp.data['test']['inds']==9695))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      "  0.0000 -24.6505 -23.4934 -35.1414 -23.4414 -34.4089 -25.4520 -27.4133\n",
      "\n",
      "Columns 8 to 9 \n",
      "-21.8785 -22.0951\n",
      "[torch.cuda.FloatTensor of size 1x10 (GPU 0)]\n",
      ", Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 26 to 38 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 39 to 51 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 52 to 64 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 65 to 77 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 78 to 90 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 91 to 103 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 104 to 116 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 117 to 127 \n",
      "    0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.cuda.FloatTensor of size 1x128 (GPU 0)]\n",
      ", Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      " 1.0130  0.9116  1.0380  1.5989  0.9068 -0.2264 -0.0662 -0.4907  1.1442 -0.7094\n",
      "\n",
      "Columns 10 to 19 \n",
      "-1.4374 -1.0477 -0.3925 -1.4888  0.7822  1.2323  1.9612 -0.5681 -0.1466  2.6679\n",
      "\n",
      "Columns 20 to 29 \n",
      "-0.7825  1.1176  0.3584 -0.4953 -0.1089 -0.9697 -0.8749  0.5050  0.2008  1.4740\n",
      "\n",
      "Columns 30 to 39 \n",
      " 1.5939 -1.2743  0.9715 -0.4403  0.3614  0.2263 -1.8202 -2.3640 -1.0624 -0.0377\n",
      "\n",
      "Columns 40 to 49 \n",
      " 2.7705 -2.5767  1.4841 -1.6104  0.3037 -1.2428 -0.3619 -0.5847 -1.3346  0.4639\n",
      "\n",
      "Columns 50 to 59 \n",
      "-0.0425  0.4125 -0.3612 -0.8302  0.1929  0.6947 -1.1164  0.4388 -1.3475 -0.6831\n",
      "\n",
      "Columns 60 to 69 \n",
      " 2.2565  0.1287  0.9248 -0.7463  0.0527 -0.4125 -0.2266 -0.0440 -1.4214 -1.7418\n",
      "\n",
      "Columns 70 to 79 \n",
      " 1.1788  0.2410  0.6055  0.2945  1.5337  1.9638  1.3162 -1.1081 -0.0447  0.3746\n",
      "\n",
      "Columns 80 to 89 \n",
      " 0.2831  0.4438  0.5409  0.1166  0.8959 -0.9287  0.1328  0.0191  0.8221 -1.6332\n",
      "\n",
      "Columns 90 to 99 \n",
      "-0.5024 -0.6153  0.9403 -0.5680  0.2359 -1.4841  1.4351  0.3231 -1.4869  0.1165\n",
      "\n",
      "Columns 100 to 109 \n",
      "-0.3183  0.4726  0.0522  0.9110  0.2179  0.5253 -0.7256  0.9543 -0.2050  0.3517\n",
      "\n",
      "Columns 110 to 119 \n",
      "-1.6706 -1.4414  2.1306 -0.6298 -0.8780 -1.0490  0.5481 -0.6466 -0.3267  0.7089\n",
      "\n",
      "Columns 120 to 127 \n",
      "-0.4440 -0.6879 -0.5443 -0.7399  0.1890  0.2965  0.0090 -0.0994\n",
      "[torch.cuda.FloatTensor of size 1x128 (GPU 0)]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "save_path = figure_dir + os.sep + 'tmp.png'\n",
    "colors=[[1,0,1], [1,1,0], [0,1,1]]\n",
    "\n",
    "images = Variable(dp.get_images([1], 'train')).cuda(gpu_ids[0])\n",
    "z = enc(images)\n",
    "z[1].data[0].fill_(0)\n",
    "img_out = dec(z)\n",
    "img_out = img_out.data.cpu()\n",
    "\n",
    "\n",
    "scipy.misc.imsave(save_path, tensor2img(img_out, colors))\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   2,   4,   6,   8,  10,  12,  14,  16,  18,  20,  22,  24,\n",
       "        26,  28,  30,  32,  34,  36,  38,  40,  42,  44,  46,  48,  50,\n",
       "        52,  54,  56,  58,  60,  62,  64,  66,  68,  70,  72,  74,  76,\n",
       "        78,  80,  82,  84,  86,  88,  90,  92,  94,  96,  98, 100, 102,\n",
       "       104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,128,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15901"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.get_n_dat('train')+dp.get_n_dat('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alpha actinin', 'Alpha tubulin', 'Beta actin', 'Desmoplakin',\n",
       "       'Fibrillarin', 'Lamin B1', 'Myosin IIB', 'Sec61 beta', 'Tom20',\n",
       "       'ZO1'],\n",
       "      dtype='<U13')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
