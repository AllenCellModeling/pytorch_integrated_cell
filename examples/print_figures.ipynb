{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(Diters=5, DitersAlt=100, batch_size=30, channelInds=[0, 2], channels_pt1=[0, 2], channels_pt2=[0, 1, 2], critRecon='BCELoss', dataProvider='DataProvider3Dh5', data_save_path='/root//results/integrated_cell/test_aaegan/dgx_test_v4_1/data.pyt', decDRatio=1e-05, dtype='float', encDRatio=0.0001, gpu_ids=[0, 1], imdir='/root/data/ipp/ipp_17_10_25', latentDistribution='gaussian', lrDec=0.0002, lrDecD=0.0002, lrEnc=0.0002, lrEncD=0.01, model_name='aaegan3Dv6-exp', myseed=0, nClasses=0, nRef=0, nch=2, ndat=19755, nepochs=150, nepochs_pt2=150, nlatentdim=128, noise=0.01, optimizer='adam', saveProgressIter=1, saveStateIter=1, save_dir='/root//results/integrated_cell/test_aaegan/dgx_test_v4_1/ref_model', save_parent='/root//results/integrated_cell/test_aaegan/dgx_test_v4_1', train_module='aaegan_trainv6')\n",
      "Loading from /root/results/integrated_cell/test_aaegan/dgx_test_v4_1/ref_model\n",
      "Namespace(Diters=5, DitersAlt=100, batch_size=30, channelInds=[0, 1, 2], channels_pt1=[0, 2], channels_pt2=[0, 1, 2], critRecon='BCELoss', dataProvider='DataProvider3Dh5', data_save_path='/root//results/integrated_cell/test_aaegan/dgx_test_v4_1/data.pyt', decDRatio=1e-05, dtype='float', encDRatio=0.0001, gpu_ids=[0, 1], imdir='/root/data/ipp/ipp_17_10_25', latentDistribution='gaussian', latentSample=<function sampleGaussian at 0x7f51a4e090d0>, lrDec=0.0002, lrDecD=0.0002, lrEnc=0.0002, lrEncD=0.01, model_name='aaegan3Dv6-exp', myseed=0, nClasses=11, nRef=128, nch=3, nclasses=1, ndat=19755, nepochs=150, nepochs_pt2=150, nlatentdim=128, noise=0.01, noise_std=0, optimizer='adam', saveProgressIter=1, saveStateIter=1, save_dir='/root//results/integrated_cell/test_aaegan/dgx_test_v4_1/struct_model', save_parent='/root//results/integrated_cell/test_aaegan/dgx_test_v4_1', train_module='aaegan_trainv6')\n",
      "Loading from /root/results/integrated_cell/test_aaegan/dgx_test_v4_1/struct_model\n",
      "done loading models\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import model_utils\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pdb\n",
    "\n",
    "parent_dir = '/root/results/integrated_cell/test_aaegan/dgx_test_v4_1'\n",
    "gpu_ids = [0, 1]\n",
    "batch_size = 100\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--parent_dir', help='save dir')\n",
    "# parser.add_argument('--gpu_ids', nargs='+', type=int, default=0, help='gpu id')\n",
    "# parser.add_argument('--batch_size', type=int, default=400, help='batch_size')\n",
    "# parser.add_argument('--overwrite', type=bool, default=False, help='overwrite existing results')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# model_dir = args.parent_dir + os.sep + 'struct_model' \n",
    "\n",
    "\n",
    "figure_dir = parent_dir + os.sep + 'figures'\n",
    "\n",
    "if not os.path.exists(figure_dir):\n",
    "    os.makedirs(figure_dir)\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(2)\n",
    "torch.cuda.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_dir = parent_dir + os.sep + 'ref_model'\n",
    "opt_ref = pickle.load(open( '{0}/opt.pkl'.format(model_dir), \"rb\" ))\n",
    "print(opt_ref)\n",
    "opt_ref.gpu_ids = gpu_ids\n",
    "\n",
    "opt_ref.save_dir = model_dir\n",
    "models, _, _, logger_ref, _ = model_utils.load_model(opt_ref.model_name, opt_ref)\n",
    "enc_ref = models['enc']\n",
    "dec_ref = models['dec']\n",
    "\n",
    "enc_ref.train(False)\n",
    "dec_ref.train(False)\n",
    "models = None\n",
    "\n",
    "dp_ref = model_utils.load_data_provider(opt_ref.data_save_path, opt_ref.imdir, opt_ref.dataProvider)\n",
    "dp_ref.opts['channelInds'] = opt_ref.channelInds\n",
    "\n",
    "model_dir = parent_dir + os.sep + 'struct_model'\n",
    "opt = pickle.load(open( '{0}/opt.pkl'.format(model_dir), \"rb\" ))\n",
    "print(opt)\n",
    "opt.gpu_ids = gpu_ids\n",
    "\n",
    "opt.save_dir = model_dir\n",
    "models, _, _, logger, _ = model_utils.load_model(opt.model_name, opt)\n",
    "enc = models['enc']\n",
    "dec = models['dec']\n",
    "\n",
    "enc.train(False)\n",
    "dec.train(False)\n",
    "models = None\n",
    "\n",
    "dp = model_utils.load_data_provider(opt.data_save_path, opt.imdir, opt.dataProvider)\n",
    "\n",
    "\n",
    "print('done loading models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from imgToProjection import imgtoprojection\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "def tensor2img(imgs, colors=None):\n",
    "\n",
    "    \n",
    "    if colors is None:\n",
    "            colormap = 'hsv'\n",
    "            colors = plt.get_cmap(colormap)(np.linspace(0, 1, imgs.shape[1]+1))\n",
    "    \n",
    "    imgs = imgs.numpy()\n",
    "    im_out = list()\n",
    "    \n",
    "    #for every image\n",
    "    for i in range(0, imgs.shape[0]):\n",
    "        img = imgs[i]\n",
    "        \n",
    "        #contrast adjust each channel\n",
    "        for j in range(0, img.shape[0]):\n",
    "            maxval = np.max(img[j])\n",
    "            if maxval > 0:\n",
    "                img[j] = img[j]/maxval\n",
    "            \n",
    "        \n",
    "        img = imgtoprojection(np.swapaxes(img, 1, 3), proj_all=True, colors = colors, global_adjust=True)\n",
    "        img = np.swapaxes(img, 0, 2)\n",
    "        \n",
    "        img = np.flip(np.flip(img,0), 1)\n",
    "        \n",
    "        #very light border between each projection\n",
    "        img[:,-2:,:] = .25\n",
    "        img[-2:,:,:] = .25\n",
    "        \n",
    "        im_out.append(img)\n",
    "\n",
    "    img = np.concatenate(im_out, 1)\n",
    "\n",
    "    return img\n",
    "\n",
    "def print_fig1(dp, save_path, save_path_struct, n_per_row = 6, colors=[[1,0,1], [1,1,0], [0,1,1]]):\n",
    "    #this figure is #classes by n_per_row max project image of cells. \n",
    "\n",
    "    ntrain = dp.get_n_dat('train')\n",
    "    \n",
    "    train_classes = dp.get_classes(np.arange(0, ntrain), 'train').numpy()\n",
    "    class_names = dp.label_names\n",
    "    \n",
    "    image_list = list()\n",
    "    image_list_struct = list()\n",
    "    \n",
    "    for i in range(0, len(class_names)):\n",
    "        inds = np.where(train_classes == i)[0]\n",
    "        np.random.shuffle(inds)\n",
    "        \n",
    "        #make the CMY image\n",
    "        images = dp.get_images(inds[0:n_per_row], 'train')\n",
    "        images_flat = tensor2img(images, colors)\n",
    "        image_list.append(images_flat)\n",
    "        \n",
    "        #make the struct-only Yellow image\n",
    "        images[:, [0,2], :, :,:] = images[:, [0,2], :, :,:].fill_(0) #not sure why i have to do it this way, but it doesn't work without the assigment\n",
    "        \n",
    "        images_flat_struct = tensor2img(images, colors)\n",
    "        image_list_struct.append(images_flat_struct)\n",
    "        \n",
    "        \n",
    "    images = np.concatenate(image_list, axis=0)\n",
    "    scipy.misc.imsave(save_path, images)\n",
    "    \n",
    "    images_struct = np.concatenate(image_list_struct, axis=0)\n",
    "    scipy.misc.imsave(save_path_struct, images_struct)\n",
    "                                   \n",
    "def print_fig2(enc, dec, dp, save_path, save_path_struct, n_per_row = 6, colors=[[1,0,1], [1,1,0], [0,1,1]], required_test_inds=None):\n",
    "    ntrain = dp.get_n_dat('train')\n",
    "    train_classes = dp.get_classes(np.arange(0, ntrain), 'train').numpy()\n",
    "    \n",
    "    class_names = dp.label_names\n",
    "    \n",
    "    nclasses = len(class_names)\n",
    "    train_inds = np.int_(np.zeros(nclasses))\n",
    "    for i in range(0, len(class_names)):\n",
    "        images_w = list()\n",
    "        class_inds = np.where(train_classes == i)[0]\n",
    "        np.random.shuffle(class_inds)\n",
    "        train_inds[i] = class_inds[0]\n",
    "        \n",
    "    train_images = dp.get_images(train_inds, 'train')\n",
    "    train_images_struct = train_images.clone()\n",
    "    train_images_struct[:, [0,2], :, :,:] = train_images_struct[:, [0,2], :, :,:].fill_(0)\n",
    "    \n",
    "    \n",
    "    n_per_row_tmp = n_per_row - len(required_test_inds)\n",
    "    \n",
    "    ntest = dp.get_n_dat('test')\n",
    "    test_inds= np.arange(0, ntest)\n",
    "    np.random.shuffle(test_inds)\n",
    "    test_inds = test_inds[np.arange(0, n_per_row_tmp-1)]\n",
    "    \n",
    "    test_inds = np.concatenate([test_inds, required_test_inds])\n",
    "    \n",
    "    test_images = dp.get_images(test_inds, 'test')\n",
    "    \n",
    "    images_h = list()\n",
    "    images_h_struct = list()   \n",
    "    \n",
    "    for i in range(0, len(class_names)):\n",
    "        images_w = list()\n",
    "        images_w_struct = list()\n",
    "        \n",
    "        train_inds = np.where(train_classes == i)[0]\n",
    "        np.random.shuffle(train_inds)\n",
    "        \n",
    "        for j in range(0, n_per_row-1):\n",
    "            image = Variable(torch.unsqueeze(test_images[j], 0))\n",
    "            z = enc(image)\n",
    "            \n",
    "            z[0].data.fill_(-100)\n",
    "            z[0].data[0,i] = 0\n",
    "\n",
    "            z[-1].data.fill_(0)\n",
    "    \n",
    "            image = dec(z)\n",
    "        \n",
    "            image = image.data.cpu()\n",
    "        \n",
    "            image[:, [0,2], :, :,:] = test_images[j][[0,2],:,:,:]\n",
    "        \n",
    "            images_w.append(tensor2img(image, colors))\n",
    "            \n",
    "            image[:, [0,2], :, :,:] = image[:, [0,2], :, :,:].fill_(0)\n",
    "            images_w_struct.append(tensor2img(image, colors))\n",
    "        \n",
    "        #CMY version\n",
    "        images_w = np.concatenate(images_w, axis=1)\n",
    "        images_w[:,-2:,:] = 0.5\n",
    "        image_flat = tensor2img(torch.unsqueeze(train_images[i], 0), colors)\n",
    "        images_w = np.concatenate([images_w, image_flat], axis=1)        \n",
    "        images_h.append(images_w)\n",
    "        \n",
    "        #Struct-only Yellow version\n",
    "        images_w_struct = np.concatenate(images_w_struct, axis=1)\n",
    "        images_w_struct[:,-2:,:] = 0.5\n",
    "        image_flat = tensor2img(torch.unsqueeze(train_images_struct[i], 0), colors)\n",
    "        images_w_struct = np.concatenate([images_w_struct, image_flat], axis=1)        \n",
    "        images_h_struct.append(images_w_struct)\n",
    "        \n",
    "    images = np.concatenate(images_h, axis=0)\n",
    "    scipy.misc.imsave(save_path, images)\n",
    "    \n",
    "    images_struct = np.concatenate(images_h_struct, axis=0)\n",
    "    scipy.misc.imsave(save_path_struct, images_struct)\n",
    "    \n",
    "def print_conf_mat(enc, dp, figure_dir, batch_size, default_gpu_id):\n",
    "\n",
    "\n",
    "    train_or_test_groups = ['test', 'train']\n",
    "\n",
    "    cf_out = dict()\n",
    "\n",
    "    for train_or_test in train_or_test_groups:\n",
    "        save_path = figure_dir + os.sep + 'conf_mat_' + train_or_test + '.csv'\n",
    "        \n",
    "        \n",
    "        y_hat = list()\n",
    "        y = list()\n",
    "\n",
    "        ndat = dp.get_n_dat(train_or_test)\n",
    "\n",
    "        intervals = np.arange(0, ndat, batch_size)\n",
    "\n",
    "        for i in tqdm(intervals):\n",
    "            batch_range = i + batch_size\n",
    "            if batch_range > ndat:\n",
    "                batch_range = ndat\n",
    "\n",
    "\n",
    "            dat_inds = np.arange(i, batch_range)\n",
    "\n",
    "            images = Variable(dp.get_images(dat_inds,train_or_test)).cuda(default_gpu_id)\n",
    "            labels = dp.get_classes(dat_inds,train_or_test).numpy()\n",
    "\n",
    "            z = enc(images)\n",
    "\n",
    "            y_hat.append(np.argmax(z[0].data.cpu().numpy(), axis=1))\n",
    "            y.append(labels)\n",
    "\n",
    "            del images, labels, z\n",
    "\n",
    "\n",
    "        y = np.concatenate(y, axis=0)\n",
    "        y_hat = np.concatenate(y_hat, axis=0)\n",
    "\n",
    "        cf = confusion_matrix(y, y_hat)\n",
    "        pd.DataFrame(cf, columns=dp.label_names).to_csv(save_path, index=False)\n",
    "\n",
    "        cf_out[train_or_test] = cf \n",
    "        \n",
    "    return cf_out\n",
    "\n",
    "def print_recon(enc, dec, dp, save_path, default_gpu_id, colors=[[1,0,1], [1,1,0], [0,1,1]]):\n",
    "    \n",
    "    train_or_test_groups = ['train', 'test'] \n",
    "\n",
    "    class_names = dp.label_names\n",
    "    \n",
    "\n",
    "    images_train_test = list()\n",
    "    \n",
    "    for train_or_test in train_or_test_groups:\n",
    "        \n",
    "        ntrain = dp.get_n_dat(train_or_test)\n",
    "        train_classes = dp.get_classes(np.arange(0, ntrain), train_or_test).numpy()\n",
    "        \n",
    "        image_in = list()\n",
    "        image_out = list()\n",
    "        \n",
    "        for i in range(0, len(class_names)):\n",
    "            inds = np.where(train_classes == i)[0]\n",
    "#             np.random.shuffle(inds)\n",
    "\n",
    "            #make the CMY image\n",
    "            images = dp.get_images([inds[0]], train_or_test)\n",
    "\n",
    "            image_in_flat = tensor2img(images, colors)\n",
    "            image_in.append(image_in_flat)\n",
    "            \n",
    "            image_recon = dec(enc(Variable(images).cuda(default_gpu_id)))\n",
    "            image_out_flat = tensor2img(image_recon.data.cpu(), colors)\n",
    "            image_out.append(image_out_flat)\n",
    "\n",
    "#             #make the struct-only Yellow image\n",
    "#             images[:, [0,2], :, :,:] = images[:, [0,2], :, :,:].fill_(0) #not sure why i have to do it this way, but it doesn't work without the assigment\n",
    "\n",
    "#             images_flat_struct = tensor2img(images, colors)\n",
    "#             image_list_struct.append(images_flat_struct)\n",
    "        \n",
    "        \n",
    "        image_in = np.concatenate(image_in, axis=1)\n",
    "        image_out = np.concatenate(image_out, axis=1)\n",
    "        \n",
    "        images = np.concatenate([image_in, image_out], axis=0)\n",
    "        images_train_test.append(images)\n",
    "        \n",
    "    images_train_test = np.concatenate(images_train_test, axis=0)\n",
    "    scipy.misc.imsave(save_path, images_train_test)\n",
    "    \n",
    "#     images_struct = np.concatenate(image_list_struct, axis=0)\n",
    "#     scipy.misc.imsave(save_path_struct, images_struct)\n",
    "\n",
    "\n",
    "def print_history(logger, save_path, r_or_s):\n",
    "    field_order = [\n",
    "                     'decDLoss',\n",
    "                     'minimaxDecDLoss',\n",
    "                     'encDLoss',\n",
    "                     'minimaxEncDLoss',\n",
    "                     'reconLoss',\n",
    "                     'classLoss',\n",
    "                     'refLoss']\n",
    "    \n",
    "    \n",
    "    field_dict = {'reconLoss': '$\\mathcal{L}_{X_{' + r_or_s + '}}$',\n",
    "                  'minimaxEncDLoss': '$\\mathcal{L}_{mmEncD^{' + r_or_s + '}}$',\n",
    "                  'encDLoss': '$\\mathcal{L}_{EncD^{' + r_or_s + '}}$',\n",
    "                  'minimaxDecDLoss': '$\\mathcal{L}_{mmDecD^{' + r_or_s + '}}$',\n",
    "                  'decDLoss': '$\\mathcal{L}_{DecD^{' + r_or_s + '}}$',\n",
    "                  'classLoss': '$\\mathcal{L}_{y}$',\n",
    "                  'refLoss': '$\\mathcal{L}_{\\hat{x}^{' + r_or_s + '}}$'}\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "    for i in range(0, len(field_order)):\n",
    "        field = field_order[i]\n",
    "        if field in logger.fields:\n",
    "            plt.plot(logger.log['iter'], logger.log[field], label=field_dict[field])\n",
    "    \n",
    "    plt.legend()\n",
    "#     plt.title('History')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('loss')\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "def print_latent_plot(embeddings, save_path, r_or_s, dims=[0,1]):\n",
    "    \n",
    "    train_or_test_groups = ['train', 'test'] \n",
    "    \n",
    "    plt.figure(num=None, figsize=(4, 4), dpi=120, facecolor='w', edgecolor='k')\n",
    "    \n",
    "    handles = list()\n",
    "    for train_or_test in train_or_test_groups:\n",
    "        embed_points = embeddings[train_or_test].numpy()\n",
    "        h = plt.scatter(embed_points[:,dims[0]], embed_points[:,dims[1]], s=1, alpha=0.5)\n",
    "        \n",
    "        h = mpatches.Patch(color=h.get_facecolor()[0], label=train_or_test)\n",
    "        handles.append(h)\n",
    "        \n",
    "    plt.xlabel('$z^{' + r_or_s + '}_{' + str(dims[0]+1) + '}$')\n",
    "    plt.ylabel('$z^{' + r_or_s + '}_{' + str(dims[1]+1) + '}$')    \n",
    "            \n",
    "    plt.legend(handles, train_or_test_groups, loc=1)\n",
    "        \n",
    "    ax_range = 4\n",
    "#     plt.axis([-ax_range, ax_range, -ax_range, ax_range])\n",
    "#     plt.axis('equal')\n",
    "    \n",
    "    plt.xlim(-ax_range, ax_range)\n",
    "    plt.ylim(-ax_range, ax_range)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    \n",
    "    plt.close('all')\n",
    "    \n",
    "    pass\n",
    "    \n",
    "def print_latent_grid(dec, ref_or_class_num, save_path, default_gpu_id, ndims = 128, nclasses = 10, dims=[0,1], std=1.5, nsamples=5, colors=[[1,0,1], [1,1,0], [0,1,1]]):\n",
    "    \n",
    "    z = list()\n",
    "    \n",
    "    if ref_or_class_num is not 'ref':\n",
    "        label = Variable(torch.Tensor(1, nclasses).fill_(-50).cuda(default_gpu_id))\n",
    "        label.data[0][ref_or_class_num] = 0\n",
    "\n",
    "        z.append(label)\n",
    "        \n",
    "        z.append(Variable(torch.Tensor(1, ndims).fill_(0).cuda(default_gpu_id)))\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    z.append(Variable(torch.Tensor(1, ndims).fill_(0).cuda(default_gpu_id)))\n",
    "    \n",
    "    samples = np.linspace(-std, std, nsamples)\n",
    "    \n",
    "    images_w = list()\n",
    "    for i in samples:\n",
    "        images_h = list()\n",
    "        for j in samples:\n",
    "            z[-1].data[0][dims[0]] = i\n",
    "            z[-1].data[0][dims[1]] = j\n",
    "    \n",
    "#             pdb.set_trace()\n",
    "            im_out = dec(z)\n",
    "            image_out_flat = tensor2img(im_out.data.cpu(), colors)\n",
    "            images_h.append(image_out_flat)\n",
    "            \n",
    "        images_w.append(np.concatenate(images_h, axis=0))\n",
    "        \n",
    "    image_out = np.concatenate(images_w, axis=1)\n",
    "    \n",
    "    return image_out\n",
    "    \n",
    "def print_image_counts(dp, save_path):\n",
    "    n_train = dp.get_n_dat('train')\n",
    "    n_test = dp.get_n_dat('test')\n",
    "    labels_train = dp.get_classes(np.arange(0,n_train), 'train').numpy()\n",
    "    labels_test = dp.get_classes(np.arange(0,n_test), 'test').numpy()\n",
    "    ulabels = np.unique(labels_train)\n",
    "    \n",
    "    image_counts = list()\n",
    "    for label in ulabels:\n",
    "        label_name = dp.label_names[label]\n",
    "        n_train_class = len(np.where(labels_train == label)[0])\n",
    "        n_test_class = len(np.where(labels_test == label)[0])\n",
    "        \n",
    "        image_counts.append([label_name, n_train_class+n_test_class, n_train_class, n_test_class])\n",
    "    \n",
    "    df = pd.DataFrame(image_counts, columns={'Label name', '#total', '#train', '#test'})\n",
    "    df.to_csv(save_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_image_counts(dp, figure_dir + os.sep + 'label_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1_path = figure_dir + os.sep + 'fig1.png'\n",
    "fig1_s1_path = figure_dir + os.sep + 'fig1_s1.png'\n",
    "print_fig1(dp, fig1_path, fig1_s1_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2_path = figure_dir + os.sep + 'fig2.png'\n",
    "fig2_s2_path = figure_dir + os.sep + 'fig2_s2.png'\n",
    "print_fig2(enc, dec, dp, fig2_path, fig2_s2_path, n_per_row=6, required_test_inds=[898])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ref_path = figure_dir + os.sep + 'ref_history.png'\n",
    "print_history(logger_ref, history_ref_path, 'r')\n",
    "\n",
    "history_struct_path = figure_dir + os.sep + 'struct_history.png'\n",
    "print_history(logger, history_struct_path, 's')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_path = figure_dir + os.sep + 'struct_recon.png'\n",
    "print_recon(enc, dec, dp, recon_path, gpu_ids[0])\n",
    "\n",
    "\n",
    "recon_path = figure_dir + os.sep + 'ref_recon.png'\n",
    "print_recon(enc_ref, dec_ref, dp_ref, recon_path, gpu_ids[0], colors=[[1,0,1], [0,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/modules/container.py:67: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      " 19%|█▉        | 3/16 [00:34<02:27, 11.34s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9ab037b376e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconf_mat_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfigure_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'conf_mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcf_out\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mprint_conf_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigure_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-3787cfd2901a>\u001b[0m in \u001b[0;36mprint_conf_mat\u001b[0;34m(enc, dp, figure_dir, batch_size, default_gpu_id)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mdat_inds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat_inds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_gpu_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat_inds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/pytorch_integrated_cell/data_providers/DataProvider3Dh5.py\u001b[0m in \u001b[0;36mget_images\u001b[0;34m(self, inds_tt, train_or_test)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrownum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds_master\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mh5_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_parent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_h5_reg_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_h5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/pytorch_integrated_cell/data_providers/DataProvider3Dh5.py\u001b[0m in \u001b[0;36mload_h5\u001b[0;34m(self, h5_path)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchInds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'double'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mvalue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         DeprecationWarning(\"dataset.value has been deprecated. \"\n\u001b[1;32m    249\u001b[0m             \"Use dataset[()] instead.\")\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conf_mat_path = figure_dir + os.sep + 'conf_mat'\n",
    "cf_out  = print_conf_mat(enc, dp, figure_dir, 100, gpu_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 36   0   4   1   0   0   5   1   0   0   0]\n",
      " [  1 330   5   1   2   2   1   0   2   1   0]\n",
      " [  3   9 160   1   0   0   1   0   0   0   0]\n",
      " [  0   0   0 229   0   0   0   4   0   0   3]\n",
      " [  0   0   0   0 104   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 434   0   1   0   2   0]\n",
      " [  4   0   0   5   0   0   7   0   0   0   3]\n",
      " [  0   0   0   6   0   0   0 156   0   0   0]\n",
      " [  0   2   0   0   0   0   0   0 218   1   0]\n",
      " [  0   0   0   0   0   0   0   0   1 449   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  17]]\n",
      "n correct: 2140\n",
      "n total: 2212\n",
      "Accuracy: 0.9674502712477396\n"
     ]
    }
   ],
   "source": [
    "save_path = figure_dir + os.sep + 'conf_mat_' + 'test' + '.csv'\n",
    "os.path.exists(save_path)\n",
    "\n",
    "cm = pd.read_csv(save_path).as_matrix()\n",
    "\n",
    "eye = np.identity(cm.shape[0]).astype(bool)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "n_correct = np.sum(cm[eye])\n",
    "n = np.sum(cm)\n",
    "\n",
    "acc = n_correct / n\n",
    "\n",
    "print('n correct: {0}'.format(n_correct))\n",
    "print('n total: {0}'.format(n))\n",
    "print('Accuracy: {0}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[eye] = 0\n",
    "\n",
    "np.sum(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[107, np.random.choice(embeddings['test'].shape[1],1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_recon_path = figure_dir + os.sep + 'ref_latent.png'\n",
    "embeddings_path = parent_dir + os.sep + 'ref_model' + os.sep + 'embeddings.pkl'\n",
    "embeddings = model_utils.load_embeddings(embeddings_path)\n",
    "\n",
    "print_latent_plot(embeddings, latent_recon_path, 'r', [23,44])\n",
    "\n",
    "\n",
    "latent_recon_path = figure_dir + os.sep + 'struct_latent.png'\n",
    "embeddings_path = parent_dir + os.sep + 'struct_model' + os.sep + 'embeddings.pkl'\n",
    "embeddings = model_utils.load_embeddings(embeddings_path)\n",
    "\n",
    "print_latent_plot(embeddings, latent_recon_path, 's', [106, 32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = 10\n",
    "ndims = opt.nRef\n",
    "\n",
    "nclasses = 10\n",
    "\n",
    "# z = enc(dp.get_images([0], 'train'))\n",
    "\n",
    "\n",
    "\n",
    "latent_grid_path = figure_dir + os.sep + 'grid_ref.png'\n",
    "image_out = print_latent_grid(dec_ref, 'ref', latent_grid_path, gpu_ids[0], std=std, colors=[[1,0,1], [0,1,1]], ndims = ndims, nclasses = nclasses)\n",
    "\n",
    "scipy.misc.imsave(latent_grid_path, image_out)\n",
    "\n",
    "image_out_ref = print_latent_grid(dec_ref, 'ref', latent_grid_path, gpu_ids[0], std=0, colors=[[1,0,1], [0,1,1]], ndims = ndims, nclasses = nclasses)\n",
    "\n",
    "for i in range(0, dp.get_n_classes()):\n",
    "    print('Printing ' + str(i) + os.sep + str(dp.get_n_classes()))\n",
    "#     latent_grid_path = figure_dir + os.sep + 'grid_struct_' + dp.label_names[i] + '.png'\n",
    "#     image_out = print_latent_grid(dec, i, latent_grid_path, gpu_ids[0], std=std, colors=[[1,0,1], [1,1,0], [0,1,1]], ndims = ndims, nclasses = nclasses)\n",
    "#     scipy.misc.imsave(latent_grid_path, image_out)\n",
    "    \n",
    "    latent_grid_path = figure_dir + os.sep + 'grid_struct_' + dp.label_names[i] + '_struct_only.png'\n",
    "    image_out = print_latent_grid(dec, i, latent_grid_path, gpu_ids[0], std=std, colors=[[0,0,0], [1,1,0], [0,0,0]], ndims = ndims, nclasses = nclasses)\n",
    "    scipy.misc.imsave(latent_grid_path, image_out)\n",
    "    \n",
    "    image_out = image_out + image_out_ref\n",
    "#     image_out[:,:,2] = image_out_ref[:,:,1]\n",
    "    \n",
    "    latent_grid_path = figure_dir + os.sep + 'grid_struct_' + dp.label_names[i] + '.png'\n",
    "    scipy.misc.imsave(latent_grid_path, image_out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = enc(Variable(dp.get_images([0], 'train')).cuda(0))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(np.where(dp.data['test']['inds']==9049))\n",
    "\n",
    "\n",
    "# print(np.where(dp.data['test']['inds']==8824))\n",
    "\n",
    "# print(np.where(dp.data['test']['inds']==9238))\n",
    "\n",
    "# print(np.where(dp.data['test']['inds']==9538))\n",
    "\n",
    "# print(np.where(dp.data['test']['inds']==9695))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = figure_dir + os.sep + 'tmp.png'\n",
    "colors=[[1,0,1], [1,1,0], [0,1,1]]\n",
    "\n",
    "images = Variable(dp.get_images([1], 'train')).cuda(gpu_ids[0])\n",
    "z = enc(images)\n",
    "z[1].data[0].fill_(0)\n",
    "img_out = dec(z)\n",
    "img_out = img_out.data.cpu()\n",
    "\n",
    "\n",
    "scipy.misc.imsave(save_path, tensor2img(img_out, colors))\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,128,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.get_n_dat('train')+dp.get_n_dat('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
