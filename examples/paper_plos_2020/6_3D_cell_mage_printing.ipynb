{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined reference and target images for image making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import integrated_cell\n",
    "from integrated_cell import model_utils, utils\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw \n",
    "\n",
    "from integrated_cell.utils.plots import tensor2im, imshow\n",
    "\n",
    "gpu_ids = [3]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(ID) for ID in gpu_ids])\n",
    "if len(gpu_ids) == 1:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "    \n",
    "model_dir = '/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_3D_avg_inten/2019-11-27-22:27:04'\n",
    "parent_dir = '/allen/aics/modeling/gregj/results/integrated_cell/'\n",
    "suffix = '_94544'    \n",
    "\n",
    "networks, dp_ref, args_ref = utils.load_network_from_dir(model_dir, parent_dir, suffix=suffix)\n",
    "\n",
    "ref_enc = networks['enc']\n",
    "ref_dec = networks['dec']\n",
    "\n",
    "parent_dir = '/allen/aics/modeling/gregj/results/integrated_cell/'\n",
    "model_dir = \"/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_3D_avg_inten/2019-10-22-15:24:09/\"\n",
    "suffix = '_93300'\n",
    "\n",
    "networks, dp_target, args_target = utils.load_network_from_dir(model_dir, parent_dir, suffix=suffix)\n",
    "    \n",
    "target_enc = networks['enc']\n",
    "target_dec = networks['dec']\n",
    "\n",
    "\n",
    "results_dir = '{}/results/ref_target_images/'.format(parent_dir)\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "print(\"Results dir: {}\".format(results_dir))\n",
    "\n",
    "save_dir = results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aicsimageio.writers import OmeTiffWriter\n",
    "\n",
    "def im_write(im, path):\n",
    "    im = im.cpu().detach().numpy().transpose(3,0,1,2)\n",
    "    \n",
    "    with OmeTiffWriter(path, overwrite_file=True) as writer:\n",
    "        writer.save(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrated_cell.networks.ref_target_autoencoder import Autoencoder\n",
    "\n",
    "\n",
    "mode = 'test'\n",
    "dp = dp_target\n",
    "u_classes, class_inds = np.unique(dp.get_classes(np.arange(0, dp.get_n_dat(mode)), mode), return_inverse=True)\n",
    "u_class_names = dp.label_names[u_classes]\n",
    "\n",
    "ae = Autoencoder(ref_enc, ref_dec, target_enc, target_dec)\n",
    "ae.train(False)\n",
    "ae = ae.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target, labels, ref = dp.get_sample(mode)\n",
    "label_onehot = utils.index_to_onehot(labels, len(u_classes)).cuda()\n",
    "target = target.cuda()\n",
    "ref = ref.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    target_hat, ref_hat = ae(target, ref, label_onehot)\n",
    "\n",
    "im = torch.cat([ref[:,[0]], target, ref[:,[1]]], 1)\n",
    "im_hat = torch.cat([ref_hat[:,[0]], target_hat, ref_hat[:,[1]]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Real and Autoencoded Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import integrated_cell.utils.plots as plots\n",
    "import tqdm\n",
    "\n",
    "ae_dir = \"./images/ae/\"\n",
    "if not os.path.exists(ae_dir):\n",
    "    os.makedirs(ae_dir)        \n",
    "        \n",
    "c = 0\n",
    "for i in tqdm.tqdm(range(10)):\n",
    "        \n",
    "    target, labels, ref = dp.get_sample(mode)\n",
    "    label_onehot = utils.index_to_onehot(labels, len(u_classes)).cuda()\n",
    "    target = target.cuda()\n",
    "    ref = ref.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        target_hat, ref_hat = ae(target, ref, label_onehot)\n",
    "\n",
    "    im = torch.cat([ref[:,[0]], target, ref[:,[1]]], 1)\n",
    "    im_hat = torch.cat([ref_hat[:,[0]], target_hat, ref_hat[:,[1]]], 1)\n",
    "\n",
    "    for i, [im_, im_hat_, structure_type] in enumerate(zip(im, im_hat, u_class_names[labels])):\n",
    "        im_write(im_, \"{}/{}_im{}_real.tiff\".format(ae_dir, structure_type, c))\n",
    "        im_write(im_hat_, \"{}/{}_im{}_ae.tiff\".format(ae_dir, structure_type, c))    \n",
    "        \n",
    "        c+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures_to_gen = [\"Mitochondria\", 'Nuclear envelope', 'Tight junctions']\n",
    "\n",
    "structure_ids_to_gen = np.stack([np.where(u_class_names == structure)[0] for structure in structures_to_gen])\n",
    "\n",
    "structure_to_gen_ids = [np.where(class_inds == structure_id)[0] for structure_id in structure_ids_to_gen]\n",
    "    \n",
    "#i chose these\n",
    "structure_to_gen_inds = [1, 0, 0]\n",
    "\n",
    "im_ids = [structure_to_gen[ind] for structure_to_gen, ind in zip(structure_to_gen_ids, structure_to_gen_inds)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros([9, len(u_classes)]).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imsave as imsave\n",
    "\n",
    "gen_dir = \"./images/gen/\"\n",
    "if not os.path.exists(gen_dir):\n",
    "    os.makedirs(gen_dir)   \n",
    "    \n",
    "n_structures = len(structures_to_gen)\n",
    "n_imgs_per_structure = 3\n",
    "\n",
    "n_cols = int(n_structures*n_imgs_per_structure)\n",
    "\n",
    "target, label, ref = dp.get_sample(mode, im_ids)\n",
    "label_onehot = utils.index_to_onehot(label, len(u_classes)).cuda()\n",
    "\n",
    "target = target.cuda()\n",
    "ref = ref.cuda()\n",
    "\n",
    "im = torch.cat([ref[:,[0]], target, ref[:,[1]]], 1)\n",
    "\n",
    "reals = list()\n",
    "for i in range(n_structures):\n",
    "    real = plots.tensor2im(im[[i]])\n",
    "    imsave(\"{}/real_{}.png\".format(gen_dir, structures_to_gen[i]), real)\n",
    "    \n",
    "    im_tmp = im[[i]]\n",
    "    im_tmp[:, [0,2]] = 0\n",
    "    real_no_ref = plots.tensor2im(im_tmp)\n",
    "    \n",
    "    imsave(\"{}/real_{}_no_ref.png\".format(gen_dir, structures_to_gen[i]), real_no_ref)\n",
    "    \n",
    "    \n",
    "    reals.append(plots.tensor2im(ref[[i]]))\n",
    "    \n",
    "imsave(\"{}/real_ref.png\".format(gen_dir), np.hstack(reals))\n",
    "    \n",
    "\n",
    "#generate 9 cell and nuc images by passing in only labels into the AE\n",
    "labels_onehot_dummy = torch.zeros([n_cols, len(u_classes)]).float().cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, ref_gen = ae(target=None, ref=None, labels = labels_onehot_dummy)\n",
    "\n",
    "gen_ref = np.hstack([plots.tensor2im(ref_gen[[i]]) for i in range(ref_gen.shape[0])])    \n",
    "\n",
    "imsave(\"{}/gen_ref.png\".format(gen_dir), gen_ref)\n",
    "    \n",
    "plt.figure(figsize=[20,20])\n",
    "plt.imshow(gen_ref)\n",
    "    \n",
    "labels_gen = torch.cat([label_onehot[[i]].repeat([n_imgs_per_structure,1]) for i in range(n_structures)],0)\n",
    "\n",
    "for i in range(n_structures):\n",
    "    ref_tmp = ref[[i]].repeat([n_cols, 1, 1, 1, 1])\n",
    "    \n",
    "    target_gen, _ = ae(target=None, ref=ref_tmp, labels = labels_gen)\n",
    "    \n",
    "    gen_imgs = np.hstack([plots.tensor2im(target_gen[[i]], color_transform=[[1,1,0]]) for i in range(target_gen.shape[0])])\n",
    "    \n",
    "    imsave(\"{}/gen_{}.png\".format(gen_dir, structures_to_gen[i]), gen_imgs)\n",
    "    \n",
    "    plt.figure(figsize=[20,20])\n",
    "    plt.imshow(gen_imgs)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "#generate 3 of each structure for the above reference images\n",
    "# for i in range(n_structures):\n",
    "    \n",
    "#     labels_onehot = torch.zeros([int(n_structures*n_imgs_per_structure), len(u_classes)]).float().cuda()\n",
    "    \n",
    "#     for j in range(n_imgs_per_structure):\n",
    "# for row in labels_onehot_dummy\n",
    "\n",
    "# for i in range(im.shape[0]):\n",
    "#     plots.imshow(im[[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u_label in np.unique(dp_ref.labels):\n",
    "    n_labels = np.sum(dp_ref.labels == u_label)\n",
    "    label_name = dp_ref.label_names[u_label]\n",
    "    print(f\"{label_name}: {n_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_integrated_cell]",
   "language": "python",
   "name": "conda-env-pytorch_integrated_cell-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
