{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure how this is different from other freature projection notebooks - grj 01/02/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import integrated_cell\n",
    "from integrated_cell import model_utils, utils\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "model_dir = '/allen/aics/modeling/gregj/results/integrated_cell//test_cbvae_avg_inten/2019-09-09-09:46:26/'\n",
    "parent_dir = '/allen/aics/modeling/gregj/results/integrated_cell/'\n",
    "suffix = '_174160'\n",
    "\n",
    "\n",
    "networks, dp, args = utils.load_network_from_dir(model_dir, parent_dir, suffix = suffix)\n",
    "    \n",
    "enc = networks['enc']\n",
    "dec = networks['dec']\n",
    "\n",
    "enc.train(False)\n",
    "dec.train(False)\n",
    "\n",
    "dp.data['test']['CellId'] = dp.csv_data['CellId'].values[dp.data['test']['inds']]\n",
    "dp.data['train']['CellId'] = dp.csv_data['CellId'].values[dp.data['train']['inds']]\n",
    "\n",
    "\n",
    "results_dir = '{}/results/kl_demo{}/'.format(model_dir, suffix)\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "print(\"Results dir: {}\".format(results_dir))\n",
    "\n",
    "dp.image_parent = '/allen/aics/modeling/gregj/results/ipp/scp_19_04_10/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aicsfeature.kitchen_sink\n",
    "from skimage.measure import label\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "import tqdm\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "\n",
    "def im2feats(im, extra_features = [\"io_intensity\", \"bright_spots\", \"intensity\", \"skeleton\", \"texture\"]):\n",
    "    im_cell, im_nuc, im_structures, im_structures_seg, seg_cell, seg_nuc = im_process(im)\n",
    "\n",
    "    feats_out = aicsfeature.kitchen_sink.kitchen_sink(im_cell = im_cell, im_nuc = im_nuc, im_structures = im_structures, seg_cell = seg_cell, seg_nuc = seg_nuc, extra_features = extra_features)\n",
    "    feats_out_seg = aicsfeature.kitchen_sink.kitchen_sink(im_cell = im_cell, im_nuc = im_nuc, im_structures = im_structures_seg, seg_cell = seg_cell, seg_nuc = seg_nuc, extra_features = extra_features)\n",
    "\n",
    "    return feats_out, feats_out_seg\n",
    "    \n",
    "def im_process(im):\n",
    "    seg_nuc = binary_fill_holes(find_main_obj(im[0][[2]] > 1E-2))\n",
    "    seg_cell = binary_fill_holes(find_main_obj(im[0][[0]] > 1E-2))\n",
    "    seg_cell[seg_nuc] = 1\n",
    " \n",
    "    im_nuc = (im[0][[2]]*(255)).astype('uint16') * seg_nuc    \n",
    "    im_cell = (im[0][[0]]*(255)).astype('uint16') * seg_cell\n",
    "    \n",
    "    im_structures = [(i[[1]]*(255)).astype('uint16') * seg_cell for i in im]\n",
    "    \n",
    "    im_structures_seg = list()\n",
    "    \n",
    "    for i, im_structure in enumerate(im_structures):\n",
    "        im_blur = gaussian(im_structure, 1)\n",
    "\n",
    "        im_pix = im_structure[im_cell>0]\n",
    "        if np.all(im_pix==0):\n",
    "            im_structures_seg.append(im_structure)\n",
    "            continue\n",
    "        \n",
    "        im_structures_seg.append(im_structure * (im_blur > threshold_otsu(im_blur[im_cell>0])))\n",
    "    \n",
    "    return im_cell, im_nuc, im_structures, im_structures_seg, seg_cell, seg_nuc\n",
    "    \n",
    "def find_main_obj(im_seg):\n",
    "    im_label = label(im_seg)\n",
    "    \n",
    "    obj_index = -1\n",
    "    max_cell_obj_size = -1\n",
    "    for i in range(1, np.max(im_label)+1):\n",
    "        obj_size = np.sum(im_label == i)\n",
    "        if obj_size > max_cell_obj_size:\n",
    "            max_cell_obj_size = obj_size\n",
    "            obj_index = i\n",
    "        \n",
    "    main_obj = im_label == obj_index\n",
    "    \n",
    "    return main_obj\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dir = '{}/results/features/test/'.format(parent_dir)\n",
    "if not os.path.exists(features_dir):\n",
    "    os.makedirs(features_dir)\n",
    "\n",
    "ndat = dp.get_n_dat('test')\n",
    "    \n",
    "save_real_feat_paths = ['{}/feat_{}.pkl'.format(features_dir, i) for i in range(ndat)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def save_real_feats(inputs, mode='test'):\n",
    "    \n",
    "    save_path, i = inputs\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        return\n",
    "    \n",
    "    print('.', end='')\n",
    "    \n",
    "    im, classes, ref = dp.get_sample(mode, [i])\n",
    "    im = im.numpy()\n",
    "    ch_name = dp.label_names[classes[0]]\n",
    "    \n",
    "    ch_names = np.concatenate([['Membrane', ch_name, 'DNA']])\n",
    "    \n",
    "    feats = im2feats(im)\n",
    "    \n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump([feats, ch_names], f)\n",
    "    \n",
    "    return\n",
    "    \n",
    "#open a multi-processing pool\n",
    "pool = mp.Pool()\n",
    "\n",
    "rows_real = [[save_path, i] for save_path, i in zip(save_real_feat_paths, range(ndat))]\n",
    "results = pool.imap_unordered(save_real_feats, rows_real)\n",
    "\n",
    "# Don't forget to close the pool\n",
    "pool.close()    \n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load the features\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "feats_membrane = list()\n",
    "feats_dna = list()\n",
    "feats_structure = list()\n",
    "\n",
    "for i, save_path in enumerate(save_real_feat_paths):\n",
    "    if not os.path.exists(save_path):\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        with open(save_path, 'rb') as f:\n",
    "            feats_raw, channel_names = pickle.load(f)\n",
    "    except:\n",
    "        print('could not load {}'.format(save_path))\n",
    "\n",
    "    f1 = pd.concat([pd.concat(fs) for fs in feats_raw[1][2:3]], axis=1)\n",
    "    f2 = pd.concat([pd.concat(fs) for fs in feats_raw[0][2:3]], axis=1)\n",
    "\n",
    "    c_out = {}\n",
    "    for c in f2.columns:\n",
    "        c_out[c] = c[0:3] + '_seg' + c[3:] \n",
    "\n",
    "    f2 = f2.rename(columns=c_out)\n",
    "\n",
    "    feats_struct = pd.concat([f1,f2], axis=1)\n",
    "       \n",
    "    feats = {}\n",
    "    feats[\"DNA\"] = feats_raw[0][0]\n",
    "    feats[\"Membrane\"] = feats_raw[0][1]\n",
    "    feats[channel_names[1]] = feats_struct\n",
    "    \n",
    "    for channel in channel_names:\n",
    "        feats[channel]['index'] = i\n",
    "        feats[channel]['structure'] = channel\n",
    "        \n",
    "        if channel == \"Membrane\":\n",
    "            feats_membrane.append(feats[channel])\n",
    "        elif channel == \"DNA\":\n",
    "            feats_dna.append(feats[channel])\n",
    "        else:\n",
    "            feats_structure.append(feats[channel])\n",
    "\n",
    "feats_membrane = pd.concat(feats_membrane)\n",
    "feats_structure = pd.concat(feats_structure)\n",
    "feats_dna = pd.concat(feats_dna)\n",
    "\n",
    "\n",
    "keep_inds = feats_structure['index'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([feats_membrane, feats_dna, feats_structure], axis=1).to_csv('{}/feats_test.csv'.format(results_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "embeddings_path = '{}/embeddings.pth'.format(results_dir)\n",
    "# losses_path = '{}/losses.pth'.format(results_dir)\n",
    "# klds_path = '{}/klds.pth'.format(results_dir)\n",
    "dimension_variation_path = '{}/dimension_variation.pth'.format(results_dir)\n",
    "\n",
    "if not os.path.exists(embeddings_path):\n",
    "    embeddings = get_latent_embeddings(enc, dec, dp)\n",
    "    torch.save(embeddings, embeddings_path)\n",
    "\n",
    "else:\n",
    "    embeddings = torch.load(embeddings_path)\n",
    "\n",
    "save_klds_path = \"{}/klds.pkl\".format(results_dir)\n",
    "\n",
    "#from elbo_demo.ipynb\n",
    "with open(save_klds_path, 'rb') as f:\n",
    "    klds_ref, ref_sorted_inds, klds_struct, struct_sorted_inds = pickle.load(f)\n",
    "    \n",
    "#sort embeddings by KLD\n",
    "embeddings_ref = embeddings['test']['ref']['mu'][:, ref_sorted_inds]\n",
    "embeddings_struct = embeddings['test']['struct']['mu'][:, struct_sorted_inds]\n",
    "\n",
    "#use embeddings for which we have features\n",
    "ref_keep_cols = klds_ref[ref_sorted_inds] > 0.05\n",
    "struct_keep_cols = klds_struct[struct_sorted_inds] > 0.05\n",
    "\n",
    "embeddings_ref = embeddings_ref[keep_inds]\n",
    "embeddings_ref = embeddings_ref.numpy()[:, ref_keep_cols]\n",
    "\n",
    "embeddings_struct = embeddings_struct[keep_inds]\n",
    "embeddings_struct = embeddings_struct.numpy()[:, struct_keep_cols]\n",
    "\n",
    "#at this point features and embeddings should be in cooresponding matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import decomposition\n",
    "from sklearn import cross_decomposition\n",
    "\n",
    "f_memb = feats_membrane.drop(columns=['index', 'structure'])\n",
    "f_dna = feats_dna.drop(columns=['index', 'structure'])\n",
    "\n",
    "feats = pd.concat([f_memb, f_dna], axis=1)\n",
    "feats[np.isnan(feats)] = 0\n",
    "\n",
    "#zscore\n",
    "feats_z = feats.apply(scipy.stats.zscore)\n",
    "#drop the nan columns\n",
    "feats_z = feats_z.drop(columns = feats_z.columns[np.all(np.isnan(feats_z),0)])\n",
    "\n",
    "# feats['mem_to_dna_main_area_total'] = feats['memb_main_area_total']/feats['dna_main_area_total']\n",
    "# feats['mem_to_dna_perimeter_total'] = feats['memb_main_perimeter_total']/feats['dna_main_perimeter_total']\n",
    "\n",
    "# model_save_path = '{}/feats_model_lasso.pkl'.format(results_dir)\n",
    "\n",
    "# if not os.path.exists(model_save_path):\n",
    "    \n",
    "#     model = linear_model.MultiTaskLassoCV()\n",
    "#     model.fit(feats_z, scipy.stats.zscore(embeddings_ref))\n",
    "    \n",
    "#     with open(model_save_path, \"wb\") as f:\n",
    "#         pickle.dump([model, feats_z], f)\n",
    "        \n",
    "# else:\n",
    "#     with open(model_save_path, 'rb') as f:\n",
    "#         model, feats_z = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_z.columns\n",
    "\n",
    "cell_feats = ['cell_volume',\n",
    "                'cell_surface_area',\n",
    "                'cell_shape_1st_axis_length',\n",
    "                'cell_shape_2nd_axis_length',\n",
    "                'cell_shape_sphericity',\n",
    "                'cell_intensity_mean',\n",
    "                'cell_intensity_median',\n",
    "                'cell_intensity_sum',\n",
    "                'cell_intensity_mode',\n",
    "                'cell_intensity_max',\n",
    "                'cell_intensity_std',\n",
    "                'cell_intensity_entropy',\n",
    "                'cell_skeleton_voxels_number',\n",
    "                'cell_skeleton_nodes_number',\n",
    "                'cell_skeleton_degree_mean',\n",
    "                'cell_skeleton_edges_number',\n",
    "                'cell_skeleton_deg0_prop',\n",
    "                'cell_skeleton_deg1_prop',\n",
    "                'cell_skeleton_deg3_prop',\n",
    "                'cell_skeleton_deg4p_prop']\n",
    "\n",
    "dna_feats = ['dna' + f[4:] for f in cell_feats]\n",
    "\n",
    "feats_z = feats_z[cell_feats + dna_feats]\n",
    "\n",
    "model_save_path = '{}/feats_model_lasso_short_features.pkl'.format(results_dir)\n",
    "\n",
    "# if not os.path.exists(model_save_path):\n",
    "    \n",
    "#     model = linear_model.MultiTaskLassoCV()\n",
    "#     model.fit(feats_z, embeddings_ref)\n",
    "\n",
    "#     with open(model_save_path, \"wb\") as f:\n",
    "#         pickle.dump([model, feats_z], f)\n",
    "        \n",
    "# else:\n",
    "#     with open(model_save_path, 'rb') as f:\n",
    "#         model, feats_z = pickle.load(f)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.MultiTaskElasticNetCV()\n",
    "model.fit(embeddings_ref, feats_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the columns to make them pretty\n",
    "\n",
    "\n",
    "coef = model.coef_.T\n",
    "\n",
    "renamed_columns = {}\n",
    "\n",
    "for c_in in feats_z.columns:\n",
    "    \n",
    "    c = c_in\n",
    "    \n",
    "    if c[0:4] == 'cell':\n",
    "        c = 'Membrane' + c[4:]\n",
    "        \n",
    "    if c[0:3] == 'dna':\n",
    "        c = 'DNA' + c[3:]        \n",
    "        \n",
    "        \n",
    "    c = c.replace('volume', 'area')\n",
    "    c = c.replace('surface_area', 'perimeter') \n",
    "    c = c.replace('shape_', '')\n",
    "    c = c.replace('1st_axis_length', 'major axis length')\n",
    "    c = c.replace('2nd_axis_length', 'minor axis length')    \n",
    "    \n",
    "    \n",
    "    c = c.replace('_', ' ')\n",
    "   \n",
    "    \n",
    "    \n",
    "    renamed_columns[c_in] = c\n",
    "    \n",
    "feats_z = feats_z.rename(columns = renamed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(coef)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = feats_z.columns[6]\n",
    "# c = c.replace('1st_axis_length', 'length')\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feats_z.shape)\n",
    "print(model.coef_.shape)\n",
    "np.sort(model.coef_[:, np.where(feats_z.columns == 'DNA area')[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "embedding_dims_to_plot = [0,1]\n",
    "\n",
    "coeff_scale = 7.5\n",
    "text_offset = 0.1\n",
    "\n",
    "\n",
    "n_top_coeffs = 10\n",
    "\n",
    "\n",
    "\n",
    "coeff_norm = np.linalg.norm(coef[embedding_dims_to_plot, :], axis = 0)\n",
    "coeff_norm_argsorted = np.argsort(coeff_norm)[::-1]\n",
    "\n",
    "print_coeff = np.zeros(len(coeff_norm))\n",
    "print_coeff[coeff_norm_argsorted[0:n_top_coeffs]] = 1\n",
    "\n",
    "plt.figure(figsize = [20,20])\n",
    "plt.scatter(embeddings_ref[:,embedding_dims_to_plot[0]], embeddings_ref[:,embedding_dims_to_plot[1]], s = 5)\n",
    "\n",
    "for i, f in enumerate(feats_z.columns):\n",
    "    \n",
    "    x_coeff = coef[embedding_dims_to_plot[0], i] * coeff_scale\n",
    "    y_coeff = coef[embedding_dims_to_plot[1], i] * coeff_scale\n",
    "    \n",
    "    plt.arrow(0, 0, x_coeff, y_coeff, head_width = 0.1, color='k', alpha = 0.5)\n",
    "    \n",
    "    if print_coeff[i]:\n",
    "        plt.text(x_coeff+text_offset+0.005, y_coeff-0.005 + text_offset, f, alpha = 1, color = 'w')\n",
    "        plt.text(x_coeff+ text_offset, y_coeff + text_offset, f, alpha = 1)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrated_cell.utils.plots import scatter_im\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "train_or_test = 'test'\n",
    "\n",
    "def get_image(train_or_test, im_id, channels_to_show = [1,1,1]):\n",
    "\n",
    "    x, _ , _ = dp.get_sample(train_or_test, [im_id])\n",
    "\n",
    "    im_out = model_utils.tensor2img(x)\n",
    "    \n",
    "    for i, ch in enumerate(channels_to_show):\n",
    "        if not ch:\n",
    "            im_out[:,:,i] = 0\n",
    "    \n",
    "    \n",
    "    #do the alpha layer\n",
    "    alpha = np.expand_dims(np.any(im_out > 0,2).astype(im_out.dtype), 2)\n",
    "\n",
    "    im_final = np.concatenate([im_out, alpha], 2)\n",
    "    \n",
    "    color_transform = np.array([[1, 1, 0, 0], [0, 1, 1, 0], [1, 0, 1, 0], [0,0,0,1]])\n",
    "    \n",
    "    #fix this\n",
    "    im_reshape = im_final.reshape([160*96, 4]).T\n",
    "    \n",
    "    im_recolored = np.matmul(color_transform, im_reshape).T \n",
    "#     im_recolored[im_recolored[:,3]>0] = 255\n",
    "    \n",
    "    im_out = im_recolored.reshape([160,96, 4]) / 1.25\n",
    "    \n",
    "    im_out[im_out > 1] = 1\n",
    "\n",
    "    return im_out\n",
    "\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "def myfunc(i):\n",
    "    im = get_image(train_or_test, keep_inds[i], channels_to_show = [1,0,1])\n",
    "    return im\n",
    "\n",
    "\n",
    "coeff_scale = 7.5\n",
    "text_offset = 0.05\n",
    "\n",
    "n_top_coeffs = 10\n",
    "\n",
    "\n",
    "figsize = [40, 40]\n",
    "dims_to_plot = [0, 1]\n",
    "\n",
    "coeff_norm = np.linalg.norm(coef[dims_to_plot, :], axis = 0)\n",
    "coeff_norm_argsorted = np.argsort(coeff_norm)[::-1]\n",
    "\n",
    "print_coeff = np.zeros(len(coeff_norm))\n",
    "print_coeff[coeff_norm_argsorted[0:n_top_coeffs]] = 1\n",
    "\n",
    "X = embeddings_ref\n",
    "\n",
    "plot_dims = [[0, 1], [2,3], [4,5]]\n",
    "\n",
    "# plot_dims = [[2,3]]\n",
    "\n",
    "for dims_to_plot in plot_dims:\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    scatter_im(X, myfunc, dims_to_plot = dims_to_plot, zoom = 0.01* figsize[0], inset=False, inset_width_and_height=0.17, inset_scatter_size = 50)\n",
    "\n",
    "    for i, f in enumerate(feats_z.columns):\n",
    "        \n",
    "        x_coeff = coef[dims_to_plot[0], i] * coeff_scale\n",
    "        y_coeff = coef[dims_to_plot[1], i] * coeff_scale\n",
    "\n",
    "        if print_coeff[i]:\n",
    "            plt.arrow(0, 0, x_coeff, y_coeff, width = 0.03, head_width = 0.06, color='w', zorder=10000, alpha = 0.5)\n",
    "            plt.text(x_coeff + text_offset + 0.005, y_coeff + text_offset - 0.01, s = f, fontsize=24, color = 'k', zorder=50000)\n",
    "            plt.text(x_coeff + text_offset, y_coeff + text_offset, s = f, fontsize=24, color = 'w', zorder=60000)\n",
    "\n",
    "\n",
    "    plt.savefig('{}/shape_space_with_vector_{}_{}.png'.format(results_dir, dims_to_plot[0], dims_to_plot[1]), bbox_inches='tight', dpi=90)\n",
    "    # matplotlib.image.imsave('{}/vector_shape_space.png'.format(results_dir))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_names = [\n",
    "    'obj_area_total',\n",
    "#     'main_convex_area_total',\n",
    "    \"obj_perimeter_total\",\n",
    "    'obj_equivalent_diameter_mean',\n",
    "#     'main_major_axis_length_mean',\n",
    "#     'main_minor_axis_length_mean',\n",
    "#     'cos_main_orientation_mean',\n",
    "#     'sin_main_orientation_mean',\n",
    "    \"obj_mean_intensity_std\",\n",
    "    \"obj_num_objs\",\n",
    "    \"main_perim_to_area\",\n",
    "    \"main_aspect_ratio\",\n",
    "    \n",
    "    ]\n",
    "\n",
    "f_struct = feats_structure[feature_names]\n",
    "rename_dict = {}\n",
    "for c in f_struct.columns:\n",
    "    rename_dict[c] = 'struct_' + c\n",
    "f_struct = f_struct.rename(columns = rename_dict)\n",
    "\n",
    "feats = f_struct\n",
    "\n",
    "model = linear_model.MultiTaskElasticNetCV()\n",
    "model.fit(scipy.stats.zscore(embeddings_struct), feats.apply(scipy.stats.zscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "def myfunc(i):\n",
    "    im = get_image(train_or_test, keep_inds[i], channels_to_show = [1,1,1])\n",
    "    return im\n",
    "\n",
    "\n",
    "coeff_scale = 5\n",
    "dims_to_plot = [0,1]\n",
    "\n",
    "X = embeddings_struct\n",
    "\n",
    "plt.figure(figsize=(40,40))\n",
    "scatter_im(X, myfunc, dims_to_plot = dims_to_plot, zoom = 0.5, inset=False, inset_width_and_height=0.17, inset_scatter_size = 50)\n",
    "\n",
    "\n",
    "for i, f in enumerate(feats.columns):\n",
    "    \n",
    "    x_coeff = model.coef_[i, dims_to_plot[0]] * coeff_scale\n",
    "    y_coeff = model.coef_[i, dims_to_plot[1]] * coeff_scale\n",
    "    \n",
    "    plt.arrow(0, 0, x_coeff, y_coeff, head_width = 0.05, color='w', zorder=10000)\n",
    "    plt.text(x_coeff + text_offset, y_coeff + text_offset, f, zorder=10000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embeddings_struct[:,0], embeddings_struct[:, 1])\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_integrated_cell]",
   "language": "python",
   "name": "conda-env-pytorch_integrated_cell-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
