{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D model selection!!\n",
    "\n",
    "Report the validation-set ELBO at every epoch, and pick the best. Do this for the reference and target models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from integrated_cell import model_utils, utils\n",
    "import os\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "import glob\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "from integrated_cell.metrics.embeddings_target import get_latent_embeddings as get_latent_embeddings_target\n",
    "from integrated_cell.metrics.embeddings_reference import get_latent_embeddings as get_latent_embeddings_ref\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "class RenamingUnpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'integrated_cell.SimpleLogger':\n",
    "            module = 'integrated_cell.simplelogger'\n",
    "        return super().find_class(module, name)\n",
    "\n",
    "def get_embeddings_for_model(suffix, model_dir, parent_dir, save_path, use_current_results):\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        if use_current_results:\n",
    "            return None\n",
    "            \n",
    "        networks, dp, args = utils.load_network_from_dir(model_dir, parent_dir, suffix = suffix)\n",
    "\n",
    "        recon_loss = utils.load_losses(args)['crit_recon']\n",
    "\n",
    "        enc = networks['enc']\n",
    "        dec = networks['dec']\n",
    "\n",
    "        enc.train(False)\n",
    "        dec.train(False)\n",
    "\n",
    "        if model == \"ref\":\n",
    "            embeddings = get_latent_embeddings_ref(enc, dec, dp, modes=[\"validate\"], recon_loss = recon_loss, batch_size = 32)\n",
    "        elif model == \"target\":\n",
    "            embeddings = get_latent_embeddings_target(enc, dec, dp, modes=[\"validate\"], recon_loss = recon_loss, batch_size = 32)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        torch.save(embeddings, save_path)\n",
    "    else:\n",
    "        embeddings = torch.load(save_path)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def embeddings2elbo(embeddings):\n",
    "\n",
    "    recon_per_point = torch.mean(embeddings['validate'][model]['recon'], 1)\n",
    "    kld_per_point =  embeddings['validate'][model]['kld']\n",
    "    \n",
    "    elbo_per_point = -(recon_per_point + kld_per_point)\n",
    "    \n",
    "    return elbo_per_point, recon_per_point, kld_per_point\n",
    "\n",
    "\n",
    "def get_embeddings_for_dir(model_dir, parent_dir, use_current_results=False):\n",
    "    model_paths = np.array(natsorted(glob.glob('{}/ref_model/enc_*'.format(model_dir))))\n",
    "    \n",
    "    #evenly sample 25 points along the training path\n",
    "    inds = np.linspace(0, len(model_paths)-1, 25).astype('int')\n",
    "    \n",
    "    model_paths = model_paths[inds]\n",
    "    \n",
    "    suffixes = [model_path.split('/enc')[1].split('.pth')[0] for model_path in model_paths]\n",
    "    \n",
    "    results_dir = '{}/results'.format(model_dir)\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    \n",
    "    embeddings_list = list()\n",
    "    \n",
    "    logger_file = '{0}/ref_model/logger_tmp.pkl'.format(model_dir)\n",
    "    \n",
    "    if not os.path.exists(logger_file):\n",
    "        return\n",
    "    \n",
    "    with open( logger_file, \"rb\" ) as fp:\n",
    "        logger = RenamingUnpickler(fp).load()\n",
    "\n",
    "    args_file = \"{}/args.json\".format(model_dir)\n",
    "    with open(args_file, \"r\") as f:\n",
    "        args = json.load(f)\n",
    "    \n",
    "    model_summaries = list()\n",
    "    \n",
    "    for suffix in suffixes:\n",
    "        \n",
    "        model_summary_path = \"{}/ref_model/embeddings_validate{}_summary.pth\".format(model_dir, suffix)\n",
    "        \n",
    "        if os.path.exists(model_summary_path):\n",
    "            with open(model_summary_path, \"rb\") as f:\n",
    "                model_summary = pickle.load(f)\n",
    "        else:\n",
    "            embeddings_path = \"{}/ref_model/embeddings_validate{}.pth\".format(model_dir, suffix)\n",
    "\n",
    "            embeddings = get_embeddings_for_model(suffix, model_dir, parent_dir, embeddings_path, use_current_results)\n",
    "\n",
    "            if embeddings is None: continue\n",
    "\n",
    "            opt = json.load(open( '{0}/args.json'.format(model_dir), \"rb\" ))\n",
    "\n",
    "            iteration = int(suffix[1:])-1\n",
    "            iteration_index = np.where(np.array(logger.log['iter']) == iteration)[0]\n",
    "\n",
    "            if len(iteration_index) == 0:\n",
    "                continue\n",
    "\n",
    "            if 'beta' in opt['kwargs_model']:\n",
    "                embeddings['beta'] = opt['kwargs_model']['beta']\n",
    "            else:\n",
    "                embeddings['beta'] = 1\n",
    "\n",
    "            embeddings['elbo'], embeddings['recon'], embeddings['kld'] = embeddings2elbo(embeddings)\n",
    "\n",
    "            model_summary = {\"iteration\": iteration,\n",
    "                    \"epoch\": np.array(logger.log['epoch'])[iteration_index],\n",
    "                    \"elbo\": np.mean(embeddings['elbo'].numpy()),\n",
    "                    \"recons\": np.mean(embeddings['recon'].numpy()),\n",
    "                    \"klds\": np.mean(embeddings['kld'].numpy()),\n",
    "                    \"model_dir\": model_dir,\n",
    "                    \"label\": model_dir.split('/')[-2],\n",
    "                    \"suffix\": suffix,\n",
    "                    \"args\": args}\n",
    "\n",
    "            with open(model_summary_path, \"wb\") as f:\n",
    "                pickle.dump(model_summary, f)\n",
    "\n",
    "        model_summaries.append(model_summary)\n",
    "            \n",
    "    return model_summaries\n",
    "\n",
    "\n",
    "gpu_ids = [5]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(ID) for ID in gpu_ids])\n",
    "if len(gpu_ids) == 1:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parent_dir = \"/allen/aics/modeling/gregj/results/integrated_cell/\"\n",
    "\n",
    "model_parent = '{}/test_cbvae_avg_inten'.format(parent_dir)\n",
    "\n",
    "#target dirs\n",
    "model_dirs = [\"/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_3D_avg_inten/2019-10-22-15:24:09/\",\n",
    "             \"/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_3D_avg_inten/2019-10-31-21:48:56/\",\n",
    "             ]\n",
    "model = \"target\"\n",
    "\n",
    "\n",
    "#reference dirs\n",
    "model_dirs = [\"/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_3D_avg_inten/2019-11-27-22:27:04\",\n",
    "              \"/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_3D_avg_inten/2019-11-27-22:23:27\",\n",
    "             ]\n",
    "model = \"ref\"\n",
    "\n",
    "data_list = list()\n",
    "for i, model_dir in enumerate(model_dirs):\n",
    "    print(model_dir)\n",
    "    \n",
    "\n",
    "    model_summaries = get_embeddings_for_dir(model_dir, parent_dir, use_current_results = False)\n",
    "\n",
    "    if model_summaries is None:\n",
    "        continue\n",
    "    \n",
    "    iteration = np.array([model_summary['iteration'] for model_summary in model_summaries])\n",
    "    epoch = np.array([model_summary['epoch'] for model_summary in model_summaries])\n",
    "    elbo = np.array([model_summary['elbo'] for model_summary in model_summaries])\n",
    "    recons = np.array([model_summary['recons'] for model_summary in model_summaries])\n",
    "    klds = np.array([model_summary['klds'] for model_summary in model_summaries])\n",
    "    args = [model_summary['args'] for model_summary in model_summaries]\n",
    "    suffix = [model_summary['suffix'] for model_summary in model_summaries]\n",
    "    \n",
    "    if len(elbo) == 0:\n",
    "        continue\n",
    "        \n",
    "    if 'beta' in args[0]['kwargs_model']:\n",
    "        beta = args[0]['kwargs_model']['beta']\n",
    "    else:\n",
    "        beta = 1\n",
    "        \n",
    "#     beta = args[0]['kwargs_model']['beta']\n",
    "        \n",
    "    max_ind = np.argmax( - (recons + beta*klds))\n",
    "    epoch_num = epoch[max_ind]\n",
    "    \n",
    "    best_ind = int(max_ind)\n",
    "    best_elbo = elbo[max_ind]\n",
    "    \n",
    "    label = model_dir.split('/')[-2]\n",
    "    \n",
    "    model_summary = {\"iteration\": iteration,\n",
    "                    \"epoch\": epoch,\n",
    "                    \"elbo\": elbo,\n",
    "                    \"recons\": recons,\n",
    "                    \"klds\": klds,\n",
    "                    \"model_dir\": model_dir,\n",
    "                    \"label\": label,\n",
    "                    \"suffix\": suffix,\n",
    "                    \"args\": args,\n",
    "                    \"best_ind\": best_ind,\n",
    "                    \"best_elbo\": best_elbo,\n",
    "                    \"beta\": beta}\n",
    "    \n",
    "\n",
    "    data_list.append(model_summary)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir.split('/')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '{}/results'.format(model_parent)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCEPTION SCORES\n",
    "\n",
    "import tqdm \n",
    "import matplotlib\n",
    "\n",
    "from integrated_cell.external.pytorch_fid.inception import InceptionV3\n",
    "import integrated_cell.external.pytorch_fid.fid_score as fid_score\n",
    "from integrated_cell.metrics.precision_recall import precision_recall\n",
    "import torch\n",
    "\n",
    "from skimage.external.tifffile import imsave\n",
    "\n",
    "ks = list(range(1,11))\n",
    "\n",
    "cuda = True\n",
    "\n",
    "dims = 2048\n",
    "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]\n",
    "model = InceptionV3([block_idx])\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "#inception score stuff\n",
    "inception_dir = '{}/results/inception/'.format(model_parent)\n",
    "\n",
    "#Sample a generated and real images into their own class folders\n",
    "modes = ['train','test','validate']\n",
    "\n",
    "im_paths_real = {}\n",
    "im_scores_real = {}\n",
    "im_paths_gen = {}\n",
    "\n",
    "class_list = list()\n",
    "path_list = list()\n",
    "mode_list = list()\n",
    "\n",
    "_, dp, _ = utils.load_network_from_dir(data_list[0]['model_dir'], parent_dir)\n",
    "dp.image_parent = '/allen/aics/modeling/gregj/results/ipp/scp_19_04_10/'\n",
    "\n",
    "# ######\n",
    "# ### Now the generated stuff\n",
    "# ######\n",
    "\n",
    "class_list = np.array(class_list)\n",
    "path_list = np.array(path_list)\n",
    "mode_list = np.array(mode_list)\n",
    "\n",
    "class_list_gen = class_list[mode_list == 'validate']\n",
    "\n",
    "im_paths_gen = {}\n",
    "im_scores_gen = {}\n",
    "\n",
    "#sample n_train images and stick them into directories\n",
    "for i, data in enumerate(data_list):    \n",
    "\n",
    "    model_ind = int(data['best_ind'])\n",
    "    \n",
    "    if len(data['suffix']) == 0:\n",
    "        continue\n",
    "        \n",
    "    #Make sure we get the hightest-ELBO model\n",
    "        \n",
    "    suffix = data['suffix'][model_ind]\n",
    "    model_dir = data['model_dir']\n",
    "    model_short = data['model_dir'].split('/')[-2]\n",
    "\n",
    "    im_paths_gen[i] = {}\n",
    "    im_scores_gen[i] = {}\n",
    "    \n",
    "    im_scores_gen[i]['model_dir'] = data['model_dir']\n",
    "    im_scores_gen[i]['label'] = data['label']\n",
    "    im_scores_gen[i]['suffix'] = data['suffix'][model_ind]    \n",
    "    im_scores_gen[i]['elbo'] = data['elbo'][model_ind]\n",
    "    im_scores_gen[i]['recon'] = data['recons'][model_ind]\n",
    "    im_scores_gen[i]['kld'] = data['klds'][model_ind]\n",
    "    im_scores_gen[i]['epoch'] = data['epoch'][model_ind]\n",
    "    im_scores_gen[i]['im_path'] = '{}/ref_model/progress_{}.png'.format(model_dir, int(data['elbo'][model_ind]))\n",
    "    im_scores_gen[i]['args'] = data['args'][model_ind]\n",
    "    im_scores_gen[i]['beta'] = data['beta']\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i in im_scores_gen:\n",
    "    #log specific model architechure choices\n",
    "    \n",
    "    color = 'k'\n",
    "    im_scores_gen[i]['noise_enc'] = 0\n",
    "    if ('noise_std' in im_scores_gen[i]['args']['kwargs_enc']) and (im_scores_gen[i]['args']['kwargs_enc']['noise_std'] > 0):\n",
    "        noise_std = im_scores_gen[i]['args']['kwargs_enc']['noise_std']\n",
    "        \n",
    "        im_scores_gen[i]['noise_enc'] = noise_std\n",
    "        \n",
    "        color = 'g'\n",
    "        if noise_std == 0.2:\n",
    "            color = 'r'\n",
    "\n",
    "    marker = '^'\n",
    "    \n",
    "    if 'proj' in im_scores_gen[i]['args']['network_name']:\n",
    "        im_scores_gen[i]['ref_proj'] = 0\n",
    "    else:\n",
    "        im_scores_gen[i]['ref_proj'] = 1\n",
    "        marker = 's'\n",
    "    \n",
    "    if 'resid' in im_scores_gen[i]['args']['network_name']:\n",
    "        im_scores_gen[i]['resid'] = 0\n",
    "    else:\n",
    "        im_scores_gen[i]['resid'] = 1\n",
    "        marker = 'p'\n",
    "        \n",
    "    if ('proj_z' in im_scores_gen[i]['args']['kwargs_dec']) and im_scores_gen[i]['args']['kwargs_dec']['proj_z']:\n",
    "        im_scores_gen[i]['z_skip'] = 1\n",
    "        marker = 'h'\n",
    "    else:\n",
    "        im_scores_gen[i]['z_skip'] = 0\n",
    "\n",
    "    if ('proj_z_ref_to_target' in im_scores_gen[i]['args']['kwargs_dec']) and im_scores_gen[i]['args']['kwargs_dec']['proj_z_ref_to_target']:\n",
    "        im_scores_gen[i]['z_skip_to_target'] = 1\n",
    "        marker = '*'\n",
    "    else:\n",
    "        im_scores_gen[i]['z_skip_to_target'] = 0\n",
    "        \n",
    "    if im_scores_gen[i]['args']['model_type'] == 'ae':\n",
    "        im_scores_gen[i]['gan'] = 0\n",
    "    else:\n",
    "        im_scores_gen[i]['gan'] = 1\n",
    "        marker = '$G$'\n",
    "        \n",
    "    if \"masked_channels\" in im_scores_gen[i]['args']['kwargs_dp']:\n",
    "        im_scores_gen[i]['masked_channels'] = im_scores_gen[i]['args']['kwargs_dp']['masked_channels']\n",
    "    else:\n",
    "        im_scores_gen[i]['masked_channels'] = -1\n",
    "\n",
    "#     im_scores_gen[i]['beta'] = im_scores_gen[i]['args']['kwargs_model']['beta']\n",
    "    im_scores_gen[i]['marker'] = marker\n",
    "    im_scores_gen[i]['color'] = color\n",
    "\n",
    "\n",
    "\n",
    "for i in im_scores_gen:\n",
    "    im_scores_gen[i]['model_arch_str'] = 'resid:{}, ref proj:{}, z-self:{}, z-target:{}, GAN:{}, noise:{}, beta:{}'.format(\n",
    "        im_scores_gen[i]['resid'],\n",
    "        im_scores_gen[i]['ref_proj'],\n",
    "        im_scores_gen[i]['z_skip'],\n",
    "        im_scores_gen[i]['z_skip_to_target'],\n",
    "        im_scores_gen[i]['gan'],\n",
    "        im_scores_gen[i]['noise_enc'],\n",
    "        im_scores_gen[i]['beta']\n",
    "    )\n",
    "    \n",
    "df_master = pd.DataFrame.from_dict([im_scores_gen[i] for i in im_scores_gen])    \n",
    "\n",
    "for s in df_master['model_arch_str']: print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "letter_x = -0.15\n",
    "letter_y = 1.05\n",
    "\n",
    "df = df_master[(df_master['beta'] == 1) & (df_master['masked_channels'] == -1)]\n",
    "\n",
    "# markers = ['^', 's', 'p', 'h', '*', '$G$']*2\n",
    "# colors = [[0, 0, 0]]*6 + [[1, 0, 0]]*6\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "# plt.subplot(2,2,1)\n",
    "\n",
    "for i, [r, d, label, marker, color, beta] in enumerate(zip(df['kld'], df['recon'], df['model_arch_str'], df['marker'], df['color'], df['beta'])):\n",
    "    \n",
    "    plt.scatter(r, d, label=label, marker = marker, color = color, linewidth=0, s = 100)\n",
    "    \n",
    "xlim = plt.xlim()\n",
    "ylim = plt.ylim()    \n",
    "    \n",
    "elbo = np.min(-df['elbo'])\n",
    "plt.plot([0, elbo], [elbo, 0], '--', c='gray')\n",
    "\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "    \n",
    "plt.xlabel('KL(q(z|x)|p(z)))')\n",
    "plt.ylabel(r'$- \\mathbb{E}_{q(z|x)}[logp(x|z)]$')    \n",
    "plt.legend(bbox_to_anchor=(1.05, 0.5), loc='center left', ncol=1, frameon=False)\n",
    "\n",
    "plt.gca().text(letter_x, letter_y, 'a)', transform=plt.gca().transAxes, size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "letter_x = -0.15\n",
    "letter_y = 1.05\n",
    "\n",
    "df = df_master[(df_master['resid'] == 1) & (df_master['masked_channels'] == -1) & (df_master['ref_proj'] == 1) & (df_master['z_skip'] == 0) & (df_master['z_skip_to_target'] == 0)]\n",
    "\n",
    "# markers = ['^', 's', 'p', 'h', '*', '$G$']*2\n",
    "# colors = [[0, 0, 0]]*6 + [[1, 0, 0]]*6\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "\n",
    "for i, [r, d, label, marker, color, beta] in enumerate(zip(df['kld'], df['recon'], df['model_arch_str'], df['marker'], df['color'], df['beta'])):\n",
    "    \n",
    "    plt.scatter(r, d, label=label, marker = '$'+str(beta)+'$', color = 'w', linewidth=0, s = 100)\n",
    "    plt.text(r, d, str(beta))\n",
    "    \n",
    "xlim = plt.xlim()\n",
    "ylim = plt.ylim()    \n",
    "    \n",
    "elbo = np.min(-df['elbo'])\n",
    "plt.plot([0, elbo], [elbo, 0], '--', c='gray')\n",
    "\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "    \n",
    "plt.xlabel('KL(q(z|x)|p(z)))')\n",
    "plt.ylabel(r'$- \\mathbb{E}_{q(z|x)}[logp(x|z)]$')    \n",
    "# plt.legend(bbox_to_anchor=(1.05, 0.5), loc='center left', ncol=1, frameon=False)\n",
    "\n",
    "# plt.gca().text(letter_x, letter_y, 'a)', transform=plt.gca().transAxes, size=20)\n",
    "\n",
    "plt.savefig('{}/model_selection_beta.png'.format(save_dir), bbox_inches='tight', dpi=90)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data_list: print(d['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from IPython.core.display import display\n",
    "import scipy.misc as misc\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "arrow_offset = 20\n",
    "\n",
    "plt.figure()\n",
    "for i, data in enumerate(data_list):\n",
    "    if len(data['elbo']) == 0:\n",
    "        continue\n",
    "    \n",
    "    if data['beta'] != 1:\n",
    "        continue\n",
    "    \n",
    "    p = plt.plot(data['iteration'], data['elbo'], label=data['label'])\n",
    "    ind = data['best_ind']\n",
    "\n",
    "#     ind = best_ind[i]\n",
    "    plt.scatter(data['iteration'][ind], data['elbo'][ind]+arrow_offset, s = 100, marker=r'$\\downarrow$', color = p[0].get_color())\n",
    "    \n",
    "    plt.text(data['iteration'][ind], data['elbo'][ind]+arrow_offset, label[11::])\n",
    "    \n",
    "    \n",
    "ylim = list(plt.ylim())\n",
    "ylim[1] = -100\n",
    "ylim[0] = -1000\n",
    "plt.ylim(ylim)\n",
    "plt.ylabel(r'$E_{(q|z)}[log P(X|z)] - D[Q(z|X)||P(z)]$')\n",
    "# plt.ylabel(r'$E_{(q|z)}[log P(X|z)] - \\beta D[Q(z|X)||P(z)]$')\n",
    "plt.xlabel(r'epoch') \n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "rate = list()\n",
    "distortion = list()\n",
    "labels = list()\n",
    "for i, data in enumerate(data_list):        \n",
    "    ind = int(data['best_ind'])\n",
    "    \n",
    "    if ind == -1:\n",
    "        continue\n",
    "    \n",
    "    labels.append(data['label'])\n",
    "    rate.append(data['klds'][ind])\n",
    "    distortion.append(data['recons'][ind])\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "for d, r, l in zip(distortion, rate, labels):\n",
    "    plt.scatter(r, d, label = l)\n",
    "    \n",
    "#     if l[11::] == \"10:23:11\":\n",
    "    plt.text(r,d,l[11::])\n",
    "\n",
    "\n",
    "xlim = list(plt.xlim())\n",
    "ylim = list(plt.ylim())\n",
    "\n",
    "xlim[0] = 0\n",
    "ylim[0] = 0\n",
    "\n",
    "# lim_max = np.max(np.hstack([xlim, ylim]))\n",
    "\n",
    "xlim[1] = 750\n",
    "# ylim[1] = lim_max\n",
    "\n",
    "plt.xlim(xlim)\n",
    "\n",
    "best_elbo = np.array([d['best_elbo'] for d in data_list])\n",
    "\n",
    "plt.plot([0, np.min(-best_elbo)], [np.min(-best_elbo), 0], '--', c='gray')\n",
    "\n",
    "plt.xlabel('rate (KLD)')\n",
    "plt.ylabel('distortion (MSE)')\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n",
    "plt.show()    \n",
    "\n",
    "#display the example images\n",
    "\n",
    "for i, data in enumerate(data_list):\n",
    "    if len(data['elbo']) == 0:\n",
    "        continue\n",
    "    \n",
    "    epoch_num = data['epoch'][data['best_ind']]\n",
    "    \n",
    "    im_out_path = '{}/ref_model/progress_{}.png'.format(data['model_dir'], int(epoch_num))\n",
    "    \n",
    "    print(data['model_dir'])\n",
    "    \n",
    "    \n",
    "    im_progress = misc.imread(im_out_path)\n",
    "    display(PIL.Image.fromarray(im_progress))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = 'asdfasdfasdf'\n",
    "\n",
    "for i, data in enumerate(data_list):\n",
    "    if data['model_dir'] == \"/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae/2019-07-19-09:27:15/\":\n",
    "        best_model = i\n",
    "        break\n",
    "\n",
    "best_model = np.argmax(best_elbo)\n",
    "\n",
    "for data in data_list:\n",
    "# data = data_list[best_model]\n",
    "\n",
    "\n",
    "    ind = int(data['best_ind'])  \n",
    "    save_dir = data['model_dir']\n",
    "\n",
    "    print(\"model_dir = '{}'\".format(data['model_dir']))\n",
    "    print(\"parent_dir = '{}'\".format(parent_dir))\n",
    "    print(\"suffix = '{}'\".format(data['suffix'][ind]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list[0]['args'][0]['kwargs_model']['beta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_integrated_cell]",
   "language": "python",
   "name": "conda-env-pytorch_integrated_cell-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
