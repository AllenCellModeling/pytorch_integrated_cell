{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D model feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display a summary of the 2D models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import features_lib as flib\n",
    "from integrated_cell import model_utils, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.width = 200\n",
    "pd.options.display.max_colwidth = None\n",
    "\n",
    "# Read df_master, a summary of the 25 2D models used in trained 1_model_compare_2D.py\n",
    "strCSVFullFilename_2DModels = '/allen/aics/modeling/caleb/data/df_master.csv'\n",
    "print(strCSVFullFilename_2DModels)\n",
    "\n",
    "dfCSV_2DModels = pd.read_csv(strCSVFullFilename_2DModels)\n",
    "print(dfCSV_2DModels[['beta', 'intensity_norm', 'suffix', 'model_dir']].sort_values(['beta', 'intensity_norm'], ascending = [True, True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the script parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 cells with save_imgs (all seg methods) = 1 hr\n",
    "# 20 cells with save_imgs (1 seg method) = 12 mins\n",
    "# 100 cells, no save_imgs, 3 betas = 7 mins\n",
    "# 100 cells, no save_imgs, 4 betas = 9 mins\n",
    "\n",
    "# Parent directory of where the extracted features will be saved\n",
    "feats_parent_dir = '/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/results/feats_caleb/'\n",
    "\n",
    "intNumCells = 5  # Set to < 0 to select the entire test set\n",
    "\n",
    "# methods = {'gt_zero', otsu', 'local_gaussian', 'local_mean', 'local_median', 'li', 'mean', 'all'}\n",
    "seg_method_real = 'gt_zero'    # Should be gt_zero for real cells\n",
    "seg_method_gen = 'local_mean'  # Should be local_mean for generated cells\n",
    "\n",
    "# Whether to mask the intensity images before feature extraction\n",
    "# TODO: Test whether this makes a difference for the generated cells\n",
    "mask_intensity_features_real = True\n",
    "mask_intensity_features_gen = True\n",
    "\n",
    "save_imgs = False       # Whether to save the binary masks\n",
    "figsize_hist = (16, 2)  # Large = (30, 4), small = (16, 2)\n",
    "\n",
    "gpu_ids = [5]  # A list of available GPUs\n",
    "\n",
    "# A list of 2D models to use\n",
    "# TODO: Allow the user to specify these models by listing intensity_norm and beta, and\n",
    "#       get the model paths from dfCSV_2DModels above\n",
    "model_dirs = [\n",
    "    '/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_298/',  # norm = 0, beta = 0.010\n",
    "    '/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_299/',  # norm = 1, beta = 0.010\n",
    "    \n",
    "    '/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_312/',  # norm = 0, beta = 0.296\n",
    "    '/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_313/',  # norm = 1, beta = 0.296\n",
    "    \n",
    "    #'/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_329/',  # norm = 1, beta = 0.623\n",
    "    \n",
    "    '/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_330/',  # norm = 0, beta = 0.663\n",
    "    '/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_331/',  # norm = 1, beta = 0.663\n",
    "    \n",
    "    # All generated cells look the same since beta is too high, not a good model to use\n",
    "    #'/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_378/',  # norm = 0, beta = 0.990\n",
    "    #'/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_379/',  # norm = 1, beta = 0.990\n",
    "]\n",
    "\n",
    "strEmbeddingsParentPath = '/allen/aics/modeling/caleb/data/'\n",
    "\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (not flib.fnIsBatchMode()):\n",
    "    # Automatically reload modules before code execution\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not flib.fnIsBatchMode()):\n",
    "    # Set plotting style\n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a data structure of the loaded models' properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpu_ids = [5]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(ID) for ID in gpu_ids])\n",
    "if len(gpu_ids) == 1:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "parent_dir = \"/allen/aics/modeling/gregj/results/integrated_cell/\"\n",
    "\n",
    "model_parent = '{}/test_cbvae_beta_ref'.format(parent_dir)\n",
    "\n",
    "#model_dirs = glob.glob('/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_*/')\n",
    "\n",
    "# model_dirs = [\n",
    "#     '/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_298/', \n",
    "#     '/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_299/', \n",
    "    \n",
    "#     '/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_312/', \n",
    "#     '/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_313/', \n",
    "    \n",
    "#     #'/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_329/', \n",
    "    \n",
    "#     '/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_330/', \n",
    "#     '/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_331/', \n",
    "    \n",
    "#     # All generated cells look the same since beta is too high, not a good model to use\n",
    "#     #'/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_378/', \n",
    "#     #'/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_379/', \n",
    "# ]\n",
    "\n",
    "        \n",
    "save_dir = '{}/results'.format(model_parent)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "results_dir = save_dir\n",
    "    \n",
    "    \n",
    "\n",
    "datStart = flib.fnNow()\n",
    "print(f'Started on {flib.fnGetDatetime(datStart)}')\n",
    "print()\n",
    "\n",
    "data_list = list()\n",
    "for i, model_dir in enumerate(model_dirs):\n",
    "    print(model_dir)\n",
    "    \n",
    "    # do model selection based on validation data\n",
    "    model_summaries = flib.get_embeddings_for_dir(model_dir, parent_dir, use_current_results = False, mode='validate')\n",
    "\n",
    "    if model_summaries is None:\n",
    "        continue\n",
    "        \n",
    "    # find the best model    \n",
    "    elbo = np.array([model_summary['elbo'] for model_summary in model_summaries])\n",
    "    suffix = [model_summary['suffix'] for model_summary in model_summaries] \n",
    "    \n",
    "    if len(elbo) == 0:\n",
    "        continue\n",
    "    \n",
    "    max_ind = np.argmax(elbo)\n",
    "    best_elbo = elbo[max_ind]\n",
    "    best_suffix = suffix[max_ind]\n",
    "    \n",
    "    best_ind = int(max_ind)\n",
    "    \n",
    "    # get results for test data\n",
    "    model_summaries = flib.get_embeddings_for_dir(model_dir, parent_dir, use_current_results = False, mode = \"test\", suffixes=[best_suffix])\n",
    "    \n",
    "    iteration = np.array([model_summary['iteration'] for model_summary in model_summaries])\n",
    "    epoch = np.array([model_summary['epoch'] for model_summary in model_summaries])\n",
    "    elbo = np.array([model_summary['elbo'] for model_summary in model_summaries])\n",
    "    recons = np.array([model_summary['recons'] for model_summary in model_summaries])\n",
    "    klds = np.array([model_summary['klds'] for model_summary in model_summaries])\n",
    "    args = [model_summary['args'] for model_summary in model_summaries]\n",
    "    suffix = [model_summary['suffix'] for model_summary in model_summaries]    \n",
    "    klds_per_dim = np.hstack([model_summary['klds_per_dim'] for model_summary in model_summaries])\n",
    "    \n",
    "    beta = args[0]['kwargs_model']['alpha']\n",
    "    \n",
    "    label = model_dir.split('/')[-2]\n",
    "    \n",
    "    model_summary = {\"iteration\": iteration,\n",
    "                    \"epoch\": epoch,\n",
    "                    \"elbo\": elbo,\n",
    "                    \"recons\": recons,\n",
    "                    \"klds\": klds,\n",
    "                    \"klds_per_dim\": klds_per_dim,\n",
    "                    \"model_dir\": model_dir,\n",
    "                    \"label\": label,\n",
    "                    \"suffix\": suffix,\n",
    "                    \"args\": args,\n",
    "                    \"best_elbo\": best_elbo,\n",
    "                    \"beta\": beta}\n",
    "    \n",
    "\n",
    "    data_list.append(model_summary)\n",
    "\n",
    "datEnd = flib.fnNow()\n",
    "print()\n",
    "print(f'Ended on {flib.fnGetDatetime(datEnd)}')\n",
    "\n",
    "datDuration = datEnd - datStart\n",
    "print(f'datDuration = {datDuration}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some information about the loaded models\n",
    "print(f'Num. models = {len(data_list)}, {type(data_list[0])}')\n",
    "\n",
    "lstBeta = []\n",
    "\n",
    "for dctModel in data_list:\n",
    "    print(f\"suffix = {dctModel['suffix']}: beta = {dctModel['beta']}\")\n",
    "    lstBeta.append(dctModel['beta'])\n",
    "    \n",
    "print(f'Sorted betas = {np.sort(lstBeta)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize the data structure into something slightly more manageable \n",
    "\n",
    "import tqdm \n",
    "import matplotlib\n",
    "\n",
    "import torch\n",
    "\n",
    "from skimage.external.tifffile import imsave\n",
    "\n",
    "ks = list(range(1,11))\n",
    "\n",
    "cuda = True\n",
    "\n",
    "# dims = 2048\n",
    "# block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]\n",
    "# model = InceptionV3([block_idx])\n",
    "# if cuda:\n",
    "#     model.cuda()\n",
    "\n",
    "#inception score stuff\n",
    "# inception_dir = '{}/results/inception/'.format(model_parent)\n",
    "\n",
    "#Sample a generated and real images into their own class folders\n",
    "modes = ['train','test','validate']\n",
    "\n",
    "im_paths_real = {}\n",
    "im_scores_real = {}\n",
    "im_paths_gen = {}\n",
    "\n",
    "class_list = list()\n",
    "path_list = list()\n",
    "mode_list = list()\n",
    "\n",
    "_, dp, _ = utils.load_network_from_dir(data_list[0]['model_dir'], parent_dir)\n",
    "dp.image_parent = '/allen/aics/modeling/gregj/results/ipp/scp_19_04_10/'\n",
    "\n",
    "class_list = np.array(class_list)\n",
    "path_list = np.array(path_list)\n",
    "mode_list = np.array(mode_list)\n",
    "\n",
    "class_list_gen = class_list[mode_list == 'validate']\n",
    "\n",
    "im_paths_gen = {}\n",
    "im_scores_gen = {}\n",
    "\n",
    "#sample n_train images and stick them into directories\n",
    "for i, data in enumerate(data_list):    \n",
    "\n",
    "    model_ind = 0\n",
    "    \n",
    "    if len(data['suffix']) == 0:\n",
    "        continue\n",
    "        \n",
    "    #Make sure we get the hightest-ELBO model\n",
    "        \n",
    "    suffix = data['suffix'][model_ind]\n",
    "    model_dir = data['model_dir']\n",
    "    model_short = data['model_dir'].split('/')[-2]\n",
    "\n",
    "    im_paths_gen[i] = {}\n",
    "    im_scores_gen[i] = {}\n",
    "    \n",
    "    im_scores_gen[i]['model_dir'] = data['model_dir']\n",
    "    im_scores_gen[i]['label'] = data['label']\n",
    "    im_scores_gen[i]['suffix'] = data['suffix'][model_ind]    \n",
    "    im_scores_gen[i]['elbo'] = data['elbo'][model_ind]\n",
    "    im_scores_gen[i]['recon'] = data['recons'][model_ind]\n",
    "    im_scores_gen[i]['kld'] = data['klds'][model_ind]\n",
    "    im_scores_gen[i]['klds_per_dim'] = data['klds_per_dim'][model_ind]    \n",
    "    im_scores_gen[i]['epoch'] = data['epoch'][model_ind]\n",
    "    im_scores_gen[i]['im_path'] = '{}/ref_model/progress_{}.png'.format(model_dir, int(data['elbo'][model_ind]))\n",
    "    im_scores_gen[i]['args'] = data['args'][model_ind]\n",
    "    im_scores_gen[i]['beta'] = data['beta']\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug: print(f'Num. models = {len(im_scores_gen)}\\n{im_scores_gen[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i in im_scores_gen:\n",
    "    #log specific model architechure choices\n",
    "    \n",
    "    color = 'k'\n",
    "    \n",
    "    if im_scores_gen[i]['args']['dataProvider'] == 'RefDataProvider':\n",
    "        im_scores_gen[i]['intensity_norm'] = 0\n",
    "    elif im_scores_gen[i]['args']['dataProvider'] == 'RescaledIntensityRefDataProvider':\n",
    "        im_scores_gen[i]['intensity_norm'] = 1\n",
    "    else:\n",
    "        raise error\n",
    "        \n",
    "    if im_scores_gen[i]['args']['dataProvider'] == 'RescaledIntensityRefDataProvider':\n",
    "        marker = 'p'\n",
    "    else:\n",
    "        marker = '^'\n",
    "        \n",
    "#     im_scores_gen[i]['beta'] = im_scores_gen[i]['args']['kwargs_model']['beta']\n",
    "    im_scores_gen[i]['marker'] = marker\n",
    "    im_scores_gen[i]['color'] = color\n",
    "\n",
    "\n",
    "\n",
    "for i in im_scores_gen:\n",
    "    beta = im_scores_gen[i]['beta']\n",
    "    im_scores_gen[i]['model_arch_str'] = rf\"$ \\beta $ = {beta}\"\n",
    "    \n",
    "df_master = pd.DataFrame.from_dict([im_scores_gen[i] for i in im_scores_gen])    \n",
    "df_master = df_master.sort_values('beta')\n",
    "\n",
    "\n",
    "# for s in df_master['model_arch_str']: print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some information about the loaded models in a dataframe\n",
    "df_master[['beta', 'intensity_norm', 'suffix', 'model_dir']].sort_values(['beta', 'intensity_norm'])\n",
    "#df_master.to_csv('~/df_master.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do feature calculation for some subset of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# All = (30, 4), single = (10, 4)\n",
    "figsize_cells_real = (30, 4) if seg_method_real == 'all' else (10, 4)\n",
    "figsize_cells_gen = (30, 4) if seg_method_gen == 'all' else (10, 4)\n",
    "\n",
    "datStart = flib.fnNow()\n",
    "print(f'Started on {flib.fnGetDatetime(datStart)}')\n",
    "print()\n",
    "\n",
    "#feats_parent_dir = \"{}/feats/\".format(results_dir)\n",
    "#feats_parent_dir = \"{}/feats_caleb/\".format(results_dir)\n",
    "print(f'feats_parent_dir = {feats_parent_dir}')\n",
    "\n",
    "all_feats_save_path = \"{}/all_feats.pkl\".format(feats_parent_dir)\n",
    "print(f'all_feats_save_path = {all_feats_save_path}')\n",
    "\n",
    "intensity_norms = np.unique(df_master['intensity_norm'])\n",
    "\n",
    "feature_path_dict = {}\n",
    "#there are 2 normalization methods\n",
    "for intensity_norm in intensity_norms:\n",
    "    print(f'  intensity_norm = {intensity_norm}')\n",
    "    \n",
    "    #get the dataframe for this normalization method\n",
    "    df_norm = df_master[df_master['intensity_norm'] == intensity_norm]\n",
    "    \n",
    "    #get the parent directory for saving this normalization method    \n",
    "    save_norm_parent = \"{}/norm_{}\".format(feats_parent_dir, intensity_norm)\n",
    "    print(f'  save_norm_parent = {save_norm_parent}')\n",
    "    if not os.path.exists(save_norm_parent):\n",
    "        os.makedirs(save_norm_parent)\n",
    "        \n",
    "    save_norm_feats = \"{}/feats_test\".format(save_norm_parent)\n",
    "    print(f'  save_norm_feats = {save_norm_feats}')\n",
    "    if not os.path.exists(save_norm_feats):\n",
    "        os.makedirs(save_norm_feats)\n",
    "        \n",
    "    #get a data provider for this normalization methods\n",
    "    networks, dp, args = utils.load_network_from_dir(df_norm['model_dir'].iloc[0], parent_dir, suffix=df_norm['suffix'].iloc[0])\n",
    "    \n",
    "    enc = networks['enc'].cuda()\n",
    "    \n",
    "    x = dp.get_sample()\n",
    "    print(f'  x.shape = {x.shape}')\n",
    "    \n",
    "    z_tmp = enc(x.cuda())[0]\n",
    "    z_tmp = z_tmp[[0]]\n",
    "    print(f'  z_tmp.shape = {z_tmp.shape}')\n",
    "    \n",
    "    n_latent = z_tmp.shape[1]\n",
    "    \n",
    "    if (intNumCells <= 0):\n",
    "        intNumCells = dp.get_n_dat('test')\n",
    "        \n",
    "    #cell_idx = range(dp.get_n_dat('test'))\n",
    "    cell_idx = range(intNumCells)\n",
    "    \n",
    "    #n_dat = dp.get_n_dat('test')\n",
    "    n_dat = len(cell_idx)\n",
    "    \n",
    "\n",
    "    #save_real_feats_paths = ['{}/feat_{}.pkl'.format(save_norm_feats, i) for i in range(n_dat)]\n",
    "    save_real_feats_paths = ['{}/feat_{}.pkl'.format(save_norm_feats, i) for i in cell_idx]\n",
    "    \n",
    "    # Loop through all the real images (test set) and save them\n",
    "    for i, save_real_feat_path in tqdm(enumerate(save_real_feats_paths)):\n",
    "        if not os.path.exists(save_real_feat_path):\n",
    "            print(f'    i = {i}, cell_idx = {cell_idx[i]}, save_real_feat_path = {save_real_feat_path}')\n",
    "            #im = dp.get_sample('test', [i])   \n",
    "            im = dp.get_sample('test', [cell_idx[i]])\n",
    "            flib.save_feats(\n",
    "                im, \n",
    "                save_real_feat_path, \n",
    "                seg_method=seg_method_real, \n",
    "                mask_intensity_features=mask_intensity_features_real, \n",
    "                save_imgs=save_imgs, \n",
    "                figsize_hist=figsize_hist, \n",
    "                figsize_cells=figsize_cells_real, \n",
    "                debug=debug\n",
    "            )\n",
    "\n",
    "    feature_path_dict[intensity_norm] = {}\n",
    "    feature_path_dict[intensity_norm]['real'] = flib.load_feats(save_real_feats_paths)\n",
    "    feature_path_dict[intensity_norm]['gen'] = {}\n",
    "    \n",
    "    # now loop through all the models under this normalization method, saving generated images and features\n",
    "    for i in range(df_norm.shape[0]):\n",
    "        print(f'    i_df_norm = {i}')\n",
    "        \n",
    "        # ***BUG?: I think we should be using df_norm below, and not df_master\n",
    "        #save_feats_dir = '{}/{}'.format(save_norm_parent, df_master['label'].iloc[i])\n",
    "        save_feats_dir = '{}/{}'.format(save_norm_parent, df_norm['label'].iloc[i])\n",
    "        print(f'    save_feats_dir = {save_feats_dir}')\n",
    "        \n",
    "        if not os.path.exists(save_feats_dir):\n",
    "            os.makedirs(save_feats_dir)\n",
    "        \n",
    "        #load the network\n",
    "        network_loaded = False\n",
    "        \n",
    "        # ***BUG?: Will this line always be using the network\n",
    "        #          loaded in the last loop except for the first\n",
    "        #          loop???\n",
    "        #dec = networks['dec'].cuda()\n",
    "        \n",
    "        strModelDir = df_norm['model_dir'].iloc[i]\n",
    "        strRefSuffix = df_norm['suffix'].iloc[i]\n",
    "        \n",
    "        beta = df_norm['beta'].iloc[i]\n",
    "        print(f'    beta = {beta}')\n",
    "        \n",
    "        gen_real_path = f'{save_feats_dir}/real'\n",
    "        gen_kld_path = f'{save_feats_dir}/kld'\n",
    "        gen_norm_path = f'{save_feats_dir}/norm'\n",
    "        \n",
    "        os.makedirs(gen_real_path, exist_ok=True)\n",
    "        os.makedirs(gen_kld_path, exist_ok=True)\n",
    "        os.makedirs(gen_norm_path, exist_ok=True)\n",
    "        \n",
    "        save_gen_feats_paths_real = ['{}/feat_{}.pkl'.format(gen_real_path, i) for i in range(n_dat)]\n",
    "        save_gen_feats_paths_kld = ['{}/feat_{}.pkl'.format(gen_kld_path, i) for i in range(n_dat)]\n",
    "        save_gen_feats_paths_norm = ['{}/feat_{}.pkl'.format(gen_norm_path, i) for i in range(n_dat)]\n",
    "        \n",
    "        save_gen_feats_paths_dct = {\n",
    "            'real': save_gen_feats_paths_real, \n",
    "            'rnd_kld': save_gen_feats_paths_kld, \n",
    "            'rnd_norm': save_gen_feats_paths_norm, \n",
    "        }\n",
    "        \n",
    "        # TODO:\n",
    "        #   - test embeddings should be loaded and available here, and then integrated with the feature tables\n",
    "        #   - z_tmps generated should be saved in save_feats_dir\n",
    "        #   - images should also be saved in save_feats here\n",
    "        \n",
    "        # (1) Real cell features\n",
    "        # (2) Gen cell features (from real cells) + latent space embeddings\n",
    "        # (3) Gen cell features (random from unit gaussian) + latent space embeddings\n",
    "        # (4) Gen cell features (ramdom from latent space dims) + latent space embeddings\n",
    "\n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        \n",
    "        strEmbeddingsFullFilename = flib.fnGenUnsortedEmbeddingsPath(strEmbeddingsParentPath, strModelDir, strRefSuffix)\n",
    "        dctUnsortedEmbeddings = flib.fnLoadUnsortedEmbeddings(strEmbeddingsFullFilename)\n",
    "        z_test = dctUnsortedEmbeddings['test'][cell_idx, :]\n",
    "        print(f'    z_test.shape = {z_test.shape}')\n",
    "        \n",
    "        z_rnd_kld = flib.fnGenRandomZ(strEmbeddingsParentPath, strModelDir, strRefSuffix, argBatchSize=n_dat)\n",
    "        print(f'    z_rnd_kld.shape = {z_rnd_kld.shape}')\n",
    "        \n",
    "        z_rnd_norm = z_tmp[0, :].repeat(n_dat, 1)\n",
    "        z_rnd_norm.normal_()\n",
    "        print(f'    z_rnd_norm.shape = {z_rnd_norm.shape}')\n",
    "        \n",
    "        # Save embeddings (test set or random) to embeddings_z_test/rnd_kld/rnd_norm.pkl\n",
    "        with open(f'{gen_real_path}/embeddings.pkl', \"wb\") as f:\n",
    "            pickle.dump(z_test, f)\n",
    "        print(f'    Saving embeddings (real) to {gen_real_path}/embeddings.pkl')\n",
    "        \n",
    "        with open(f'{gen_kld_path}/embeddings.pkl', \"wb\") as f:\n",
    "            pickle.dump(z_rnd_kld, f)\n",
    "        print(f'    Saving embeddings (rnd_kld) to {gen_kld_path}/embeddings.pkl')\n",
    "        \n",
    "        with open(f'{gen_norm_path}/embeddings.pkl', \"wb\") as f:\n",
    "            pickle.dump(z_rnd_norm, f)\n",
    "        print(f'    Saving embeddings (rnd_norm) to {gen_norm_path}/embeddings.pkl')\n",
    "        \n",
    "        feature_path_dict[intensity_norm]['gen'][beta] = {}\n",
    "        \n",
    "        for key in save_gen_feats_paths_dct.keys():\n",
    "            \n",
    "            save_gen_feats_paths = save_gen_feats_paths_dct[key]\n",
    "            \n",
    "            if (key == 'real'):\n",
    "                z_tmp = z_test\n",
    "                \n",
    "            elif (key == 'rnd_kld'):\n",
    "                z_tmp = z_rnd_kld\n",
    "                \n",
    "            else:\n",
    "                z_tmp = z_rnd_norm\n",
    "            \n",
    "            for j, save_path in tqdm(enumerate(save_gen_feats_paths)):\n",
    "\n",
    "                if not os.path.exists(save_path):\n",
    "                    print(f'      j = {j}, save_path = {save_path}')\n",
    "\n",
    "                    if not network_loaded:\n",
    "                        networks, dp, args = utils.load_network_from_dir(df_norm['model_dir'].iloc[i], parent_dir, suffix=df_norm['suffix'].iloc[i])\n",
    "                        dec = networks['dec'].cuda()  # ***BUG?: How come we load the network without assigning the enc or dec even though we use it in the next few lines?\n",
    "                        network_loaded = True\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        # Randomly sample from a normal distribution (default mean = 0, stdev = 1)\n",
    "                        # Does this make sense given that the latent space is not necessarily a unit\n",
    "                        # Gaussian distribution?\n",
    "                        #im = dec(z_tmp.normal_())\n",
    "                        im = dec(z_tmp[j, :][np.newaxis, :].cuda())\n",
    "                        print(f'      z_tmp.shape = {z_tmp.shape}\\nim.shape = {im.shape}')\n",
    "\n",
    "                    flib.save_feats(\n",
    "                        im, \n",
    "                        save_path, \n",
    "                        seg_method=seg_method_gen, \n",
    "                        mask_intensity_features=mask_intensity_features_gen, \n",
    "                        save_imgs=save_imgs, \n",
    "                        figsize_hist=figsize_hist, \n",
    "                        figsize_cells=figsize_cells_gen, \n",
    "                        debug=debug\n",
    "                    )\n",
    "\n",
    "            #beta = df_norm['beta'].iloc[i]\n",
    "            #print(f'    beta = {beta}')\n",
    "\n",
    "            #feature_path_dict[intensity_norm]['gen'][beta][key] = load_feats(save_gen_feats_paths)\n",
    "            \n",
    "            feature_path_dict[intensity_norm]['gen'][beta][key] = {}\n",
    "            feature_path_dict[intensity_norm]['gen'][beta][key]['embeddings'] = z_tmp.cpu().detach().numpy()\n",
    "            feature_path_dict[intensity_norm]['gen'][beta][key]['features'] = flib.load_feats(save_gen_feats_paths)\n",
    "            \n",
    "with open(all_feats_save_path, \"wb\") as f:\n",
    "    pickle.dump(feature_path_dict, f)\n",
    "\n",
    "datEnd = flib.fnNow()\n",
    "print()\n",
    "print(f'Ended on {flib.fnGetDatetime(datEnd)}')\n",
    "\n",
    "datDuration = datEnd - datStart\n",
    "print(f'datDuration = {datDuration}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
