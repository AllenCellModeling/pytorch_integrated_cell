{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D model compare\n",
    "\n",
    "Because our model is an implementation of the variational autoencoder, there exists a trade off between a compact representation of the cell in the low dimensional embedding space (i.e. the number of dimensions needed to describe an image $\\zRef$ and $\\zTarget$), a low $KL(q(z|x)|p(z)))$, and faithful reconstruction of the original image from the decoded low dimensional embedding, a high $\\mathbb{E}_{q(z|x)}[\\log p(x|z)]$.\n",
    "The relative emphasis of one term versus the other has consequences for the model and for its applications.\n",
    "For example, one might desire a less-complex data embedding to facilitate the statistical exploration and interpretation of the latent space, while in other circumstances it might be preferable for a more-complex embedding that enables the comparative analysis of high-fidelity generated images.\n",
    "\n",
    "To demonstrate how our model performs as a function of this relationship, we adopt a modified variational objective that allows us to tune the relative weights of these two terms.\n",
    "\n",
    "$ELBO(x) = (1-\\beta) \\mathbb{E}_{q(z|x)}[\\log p(x|z)] - \\beta KL(q(z|x)|p(z)))$\n",
    "\n",
    "We trained 25 models of cell and nuclear shape ($\\modelRef$) with $\\beta$ values evenly spaced between 0 and 1 using 2D maximum-intensity-projected images of cell and nuclear shape.\n",
    "Using the test data, i.e.\\ data not used in the training phase, we record the average of the two terms of ELBO for each of the 25 models and plot the two as a function of $\\beta$ in figure \\ref{fig:3}a.\n",
    "Sampling from the cell and nuclear shape representation, we show generated images across a range of $\\beta$ in figure \\ref{fig:3}b.\n",
    "We note that compared to observed cell and nuclear shapes, generated images close to $\\beta \\rightarrow 0$ retain more detail and perhaps more diversity than images at $\\beta \\rightarrow 1$, although this comes at a trade off of increased representation dimensionality (figure \\ref{fig:3_supp}).\n",
    "\n",
    "First load each model, and get embeddings and ELBO values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_313/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_303/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_378/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_306/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_331/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_329/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_298/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_317/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_341/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_343/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_332/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_302/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_326/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_301/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_319/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_315/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_377/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_321/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_310/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_314/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_342/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_322/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_323/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_320/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_299/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_304/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_340/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_333/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_327/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_307/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_308/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_309/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_330/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_334/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_311/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_379/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_300/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_324/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_338/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_328/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_305/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_325/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_337/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_339/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_316/\n",
      "/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_318/\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "\n",
    "from integrated_cell import model_utils, utils\n",
    "from integrated_cell.metrics.embeddings_reference import get_latent_embeddings\n",
    "from integrated_cell.models.bvae import kl_divergence\n",
    "\n",
    "\n",
    "def dim_klds(mus, sigmas):\n",
    "    kl_dims = list()\n",
    "    for mu, sigma in zip(mus, sigmas):\n",
    "        _, kl_dim, _ = kl_divergence(mu.unsqueeze(0), sigma.unsqueeze(0))\n",
    "        \n",
    "        kl_dims.append(kl_dim)\n",
    "    \n",
    "    return np.vstack(np.vstack(kl_dims))    \n",
    "    \n",
    "    \n",
    "def get_embeddings_for_model(suffix, model_dir, parent_dir, save_path, use_current_results, mode = \"validate\"):\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        if use_current_results:\n",
    "            return None\n",
    "            \n",
    "        networks, dp, args = utils.load_network_from_dir(model_dir, parent_dir, suffix = suffix)\n",
    "\n",
    "        recon_loss = utils.load_losses(args)['crit_recon']\n",
    "\n",
    "        enc = networks['enc']\n",
    "        dec = networks['dec']\n",
    "\n",
    "        enc.train(False)\n",
    "        dec.train(False)\n",
    "\n",
    "        embeddings = get_latent_embeddings(enc, dec, dp, modes=[mode], recon_loss = recon_loss, batch_size = 32)\n",
    "\n",
    "        torch.save(embeddings, save_path)\n",
    "    else:\n",
    "        embeddings = torch.load(save_path)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def embeddings2elbo(embeddings, alpha=0.5, mode = \"validate\"):\n",
    "\n",
    "    recon_per_point = torch.mean(embeddings[mode]['ref']['recon'], 1)\n",
    "    kld_per_point =  embeddings[mode]['ref']['kld']\n",
    "    \n",
    "    elbo_per_point = -2*((1-alpha)*recon_per_point + alpha*kld_per_point)\n",
    "    \n",
    "    return elbo_per_point, recon_per_point, kld_per_point\n",
    "\n",
    "\n",
    "def get_embeddings_for_dir(model_dir, parent_dir, use_current_results=False, suffixes = None, mode = 'validate'):\n",
    "    model_paths = np.array(natsorted(glob.glob('{}/ref_model/enc_*'.format(model_dir))))\n",
    "    \n",
    "    inds = np.linspace(0, len(model_paths)-1).astype('int')\n",
    "    \n",
    "    model_paths = model_paths[inds]\n",
    "    \n",
    "    if suffixes is None:\n",
    "        suffixes = [model_path.split('/enc')[1].split('.pth')[0] for model_path in model_paths]\n",
    "    \n",
    "    results_dir = '{}/results'.format(model_dir)\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    \n",
    "    embeddings_list = list()\n",
    "    \n",
    "    logger_file = '{0}/ref_model/logger_tmp.pkl'.format(model_dir)\n",
    "    \n",
    "    if not os.path.exists(logger_file):\n",
    "        return\n",
    "    \n",
    "    with open( logger_file, \"rb\" ) as fp:\n",
    "        logger = pickle.load(fp)\n",
    "\n",
    "    args_file = \"{}/args.json\".format(model_dir)\n",
    "    with open(args_file, \"r\") as f:\n",
    "        args = json.load(f)\n",
    "    \n",
    "    model_summaries = list()\n",
    "    \n",
    "    for suffix in suffixes:\n",
    "        \n",
    "        model_summary_path = \"{}/ref_model/embeddings_{}{}_summary.pth\".format(model_dir, mode, suffix)\n",
    "        \n",
    "#         if os.path.exists(model_summary_path):\n",
    "#             with open(model_summary_path, \"rb\") as f:\n",
    "#                 model_summary = pickle.load(f)\n",
    "#         else:\n",
    "        embeddings_path = \"{}/ref_model/embeddings_{}{}.pth\".format(model_dir, mode, suffix)\n",
    "    \n",
    "        embeddings = get_embeddings_for_model(suffix, model_dir, parent_dir, embeddings_path, use_current_results, mode = mode)\n",
    "\n",
    "        if embeddings is None: continue\n",
    "\n",
    "        opt = json.load(open( '{0}/args.json'.format(model_dir), \"rb\" ))\n",
    "\n",
    "        iteration = int(suffix[1:])-1\n",
    "        iteration_index = np.where(np.array(logger.log['iter']) == iteration)[0]\n",
    "\n",
    "        if len(iteration_index) == 0:\n",
    "            continue\n",
    "\n",
    "\n",
    "        embeddings['beta'] = opt['kwargs_model']['alpha']\n",
    "        embeddings['elbo'], embeddings['recon'], embeddings['kld'] = embeddings2elbo(embeddings, embeddings['beta'], mode = mode)\n",
    "\n",
    "        klds_per_dim = dim_klds(embeddings[mode]['ref']['mu'], embeddings[mode]['ref']['sigma'])\n",
    "\n",
    "        model_summary = {\"iteration\": iteration,\n",
    "                \"epoch\": np.array(logger.log['epoch'])[iteration_index],\n",
    "                \"elbo\": np.mean(embeddings['elbo'].numpy()),\n",
    "                \"recons\": np.mean(embeddings['recon'].numpy()),\n",
    "                \"klds\": np.mean(embeddings['kld'].numpy()),\n",
    "                \"klds_per_dim\": np.mean(klds_per_dim, 0),\n",
    "                \"model_dir\": model_dir,\n",
    "                \"label\": model_dir.split('/')[-2],\n",
    "                \"suffix\": suffix,\n",
    "                \"args\": args}\n",
    "\n",
    "        with open(model_summary_path, \"wb\") as f:\n",
    "            pickle.dump(model_summary, f)\n",
    "\n",
    "        model_summaries.append(model_summary)\n",
    "            \n",
    "    return model_summaries\n",
    "\n",
    "\n",
    "gpu_ids = [5]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(ID) for ID in gpu_ids])\n",
    "if len(gpu_ids) == 1:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "parent_dir = \"/allen/aics/modeling/gregj/results/integrated_cell/\"\n",
    "\n",
    "model_parent = '{}/test_cbvae_beta_ref'.format(parent_dir)\n",
    "\n",
    "model_dirs = glob.glob('/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae_beta_ref/job_*/')\n",
    "\n",
    "        \n",
    "save_dir = '{}/results'.format(model_parent)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "results_dir = save_dir\n",
    "    \n",
    "    \n",
    "\n",
    "data_list = list()\n",
    "for i, model_dir in enumerate(model_dirs):\n",
    "    print(model_dir)\n",
    "    \n",
    "    # do model selection based on validation data\n",
    "    model_summaries = get_embeddings_for_dir(model_dir, parent_dir, use_current_results = False, mode='validate')\n",
    "\n",
    "    if model_summaries is None:\n",
    "        continue\n",
    "        \n",
    "    # find the best model    \n",
    "    elbo = np.array([model_summary['elbo'] for model_summary in model_summaries])\n",
    "    suffix = [model_summary['suffix'] for model_summary in model_summaries] \n",
    "    \n",
    "    if len(elbo) == 0:\n",
    "        continue\n",
    "    \n",
    "    max_ind = np.argmax(elbo)\n",
    "    best_elbo = elbo[max_ind]\n",
    "    best_suffix = suffix[max_ind]\n",
    "    \n",
    "    best_ind = int(max_ind)\n",
    "    \n",
    "    # get results for test data\n",
    "    model_summaries = get_embeddings_for_dir(model_dir, parent_dir, use_current_results = False, mode = \"test\", suffixes=[best_suffix])\n",
    "    \n",
    "    iteration = np.array([model_summary['iteration'] for model_summary in model_summaries])\n",
    "    epoch = np.array([model_summary['epoch'] for model_summary in model_summaries])\n",
    "    elbo = np.array([model_summary['elbo'] for model_summary in model_summaries])\n",
    "    recons = np.array([model_summary['recons'] for model_summary in model_summaries])\n",
    "    klds = np.array([model_summary['klds'] for model_summary in model_summaries])\n",
    "    args = [model_summary['args'] for model_summary in model_summaries]\n",
    "    suffix = [model_summary['suffix'] for model_summary in model_summaries]    \n",
    "    klds_per_dim = np.hstack([model_summary['klds_per_dim'] for model_summary in model_summaries])\n",
    "    \n",
    "    beta = args[0]['kwargs_model']['alpha']\n",
    "    \n",
    "    label = model_dir.split('/')[-2]\n",
    "    \n",
    "    model_summary = {\"iteration\": iteration,\n",
    "                    \"epoch\": epoch,\n",
    "                    \"elbo\": elbo,\n",
    "                    \"recons\": recons,\n",
    "                    \"klds\": klds,\n",
    "                    \"klds_per_dim\": klds_per_dim,\n",
    "                    \"model_dir\": model_dir,\n",
    "                    \"label\": label,\n",
    "                    \"suffix\": suffix,\n",
    "                    \"args\": args,\n",
    "                    \"best_elbo\": best_elbo,\n",
    "                    \"beta\": beta}\n",
    "    \n",
    "\n",
    "    data_list.append(model_summary)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize the data structure into something slightly more manageable \n",
    "\n",
    "import tqdm \n",
    "import matplotlib\n",
    "\n",
    "import torch\n",
    "\n",
    "from skimage.external.tifffile import imsave\n",
    "\n",
    "ks = list(range(1,11))\n",
    "\n",
    "cuda = True\n",
    "\n",
    "# dims = 2048\n",
    "# block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]\n",
    "# model = InceptionV3([block_idx])\n",
    "# if cuda:\n",
    "#     model.cuda()\n",
    "\n",
    "#inception score stuff\n",
    "# inception_dir = '{}/results/inception/'.format(model_parent)\n",
    "\n",
    "#Sample a generated and real images into their own class folders\n",
    "modes = ['train','test','validate']\n",
    "\n",
    "im_paths_real = {}\n",
    "im_scores_real = {}\n",
    "im_paths_gen = {}\n",
    "\n",
    "class_list = list()\n",
    "path_list = list()\n",
    "mode_list = list()\n",
    "\n",
    "_, dp, _ = utils.load_network_from_dir(data_list[0]['model_dir'], parent_dir)\n",
    "dp.image_parent = '/allen/aics/modeling/gregj/results/ipp/scp_19_04_10/'\n",
    "\n",
    "class_list = np.array(class_list)\n",
    "path_list = np.array(path_list)\n",
    "mode_list = np.array(mode_list)\n",
    "\n",
    "class_list_gen = class_list[mode_list == 'validate']\n",
    "\n",
    "im_paths_gen = {}\n",
    "im_scores_gen = {}\n",
    "\n",
    "#sample n_train images and stick them into directories\n",
    "for i, data in enumerate(data_list):    \n",
    "\n",
    "    model_ind = 0\n",
    "    \n",
    "    if len(data['suffix']) == 0:\n",
    "        continue\n",
    "        \n",
    "    #Make sure we get the hightest-ELBO model\n",
    "        \n",
    "    suffix = data['suffix'][model_ind]\n",
    "    model_dir = data['model_dir']\n",
    "    model_short = data['model_dir'].split('/')[-2]\n",
    "\n",
    "    im_paths_gen[i] = {}\n",
    "    im_scores_gen[i] = {}\n",
    "    \n",
    "    im_scores_gen[i]['model_dir'] = data['model_dir']\n",
    "    im_scores_gen[i]['label'] = data['label']\n",
    "    im_scores_gen[i]['suffix'] = data['suffix'][model_ind]    \n",
    "    im_scores_gen[i]['elbo'] = data['elbo'][model_ind]\n",
    "    im_scores_gen[i]['recon'] = data['recons'][model_ind]\n",
    "    im_scores_gen[i]['kld'] = data['klds'][model_ind]\n",
    "    im_scores_gen[i]['klds_per_dim'] = data['klds_per_dim'][model_ind]    \n",
    "    im_scores_gen[i]['epoch'] = data['epoch'][model_ind]\n",
    "    im_scores_gen[i]['im_path'] = '{}/ref_model/progress_{}.png'.format(model_dir, int(data['elbo'][model_ind]))\n",
    "    im_scores_gen[i]['args'] = data['args'][model_ind]\n",
    "    im_scores_gen[i]['beta'] = data['beta']\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i in im_scores_gen:\n",
    "    #log specific model architechure choices\n",
    "    \n",
    "    color = 'k'\n",
    "    \n",
    "    if im_scores_gen[i]['args']['dataProvider'] == 'RefDataProvider':\n",
    "        im_scores_gen[i]['intensity_norm'] = 0\n",
    "    elif im_scores_gen[i]['args']['dataProvider'] == 'RescaledIntensityRefDataProvider':\n",
    "        im_scores_gen[i]['intensity_norm'] = 1\n",
    "    else:\n",
    "        raise error\n",
    "        \n",
    "    if im_scores_gen[i]['args']['dataProvider'] == 'RescaledIntensityRefDataProvider':\n",
    "        marker = 'p'\n",
    "    else:\n",
    "        marker = '^'\n",
    "        \n",
    "#     im_scores_gen[i]['beta'] = im_scores_gen[i]['args']['kwargs_model']['beta']\n",
    "    im_scores_gen[i]['marker'] = marker\n",
    "    im_scores_gen[i]['color'] = color\n",
    "\n",
    "\n",
    "\n",
    "for i in im_scores_gen:\n",
    "    beta = im_scores_gen[i]['beta']\n",
    "    im_scores_gen[i]['model_arch_str'] = rf\"$ \\beta $ = {beta}\"\n",
    "    \n",
    "df_master = pd.DataFrame.from_dict([im_scores_gen[i] for i in im_scores_gen])    \n",
    "df_master = df_master.sort_values('beta')\n",
    "\n",
    "\n",
    "# for s in df_master['model_arch_str']: print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot models as a function of $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "letter_x = -0.15\n",
    "letter_y = 1.05\n",
    "\n",
    "# df = df_master[(df_master['beta'] == 1) & (df_master['masked_channels'] == -1)]\n",
    "\n",
    "df = df_master \n",
    "# markers = ['^', 's', 'p', 'h', '*', '$G$']*2\n",
    "# colors = [[0, 0, 0]]*6 + [[1, 0, 0]]*6\n",
    "\n",
    "colors = np.arange(df.shape[0])\n",
    "\n",
    "colors = cm.viridis(df['beta'])\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "# plt.subplot(2,2,1)\n",
    "\n",
    "for i, [r, d, label, marker, color, beta] in enumerate(zip(df['kld'], df['recon'], df['model_arch_str'], df['marker'], colors, df['beta'])):\n",
    "    if marker == 'p': \n",
    "        label = None\n",
    "        continue\n",
    "        \n",
    "    ax = plt.scatter(r, d, label=label, marker = marker, color = color, linewidth=0, s = 100)\n",
    "    \n",
    "elbo = np.min(df['recon']+df['kld'])\n",
    "plt.plot([0, elbo], [elbo, 0], '--', c='gray')\n",
    "\n",
    "plt.xlabel('KL Divergence: KL(q(z|x)|p(z)))')\n",
    "plt.ylabel(r'Reconstruction Loss: $- \\mathbb{E}_{q(z|x)}[logp(x|z)]$')   \n",
    "\n",
    "# plt.colorbar(ax)\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.5), loc='center left', ncol=1, frameon=False)\n",
    "\n",
    "plt.ylim([40, 175])\n",
    "plt.xlim([-3, 160])\n",
    "\n",
    "plt.gca().text(letter_x, letter_y, 'a)', transform=plt.gca().transAxes, size=20)\n",
    "\n",
    "# plt.axis('equal')    \n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "letter_x = -0.15\n",
    "letter_y = 1.05\n",
    "\n",
    "df = df_master\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "\n",
    "for i, [r, d, label, marker, color, beta] in enumerate(zip(df['kld'], df['recon'], df['model_arch_str'], df['marker'], df['color'], df['beta'])):\n",
    "    \n",
    "    plt.scatter(r, d, label=label, marker = '$'+str(beta)+'$', color = 'w', linewidth=0, s = 100)\n",
    "    plt.text(r, d, str(beta))\n",
    "    \n",
    "xlim = plt.xlim()\n",
    "ylim = plt.ylim()    \n",
    "    \n",
    "elbo = np.min(df['recon']+df['kld'])\n",
    "plt.plot([0, elbo], [elbo, 0], '--', c='gray')\n",
    "\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "    \n",
    "plt.xlabel('KL Divergence: KL(q(z|x)|p(z)))')\n",
    "plt.ylabel(r'Reconstruction Loss: $- \\mathbb{E}_{q(z|x)}[logp(x|z)]$')    \n",
    "\n",
    "plt.savefig('{}/model_selection_beta.png'.format(save_dir), bbox_inches='tight', dpi=90)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot models as a function of $\\beta$ but prettier this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "letter_x = -0.15\n",
    "letter_y = 1.05\n",
    "\n",
    "# df = df_master[(df_master['beta'] == 1) & (df_master['masked_channels'] == -1)]\n",
    "\n",
    "df = df_master.iloc[np.array(df_master['intensity_norm'] == 0)] \n",
    "# markers = ['^', 's', 'p', 'h', '*', '$G$']*2\n",
    "# colors = [[0, 0, 0]]*6 + [[1, 0, 0]]*6\n",
    "\n",
    "colors = np.arange(df.shape[0])\n",
    "\n",
    "colors = cm.viridis(df['beta'])\n",
    "\n",
    "plt.figure(figsize=[10,5.5])\n",
    "# plt.subplot(2,2,1)\n",
    "\n",
    "# for i, [r, d, label, marker, color, beta] in enumerate(zip(df['kld'], df['recon'], df['model_arch_str'], df['marker'], colors, df['beta'])):\n",
    "#     if marker == 'p': \n",
    "#         label = None\n",
    "#         continue\n",
    "        \n",
    "ax = plt.scatter(df['kld'], df['recon'], c = df['beta'], linewidth=0, s = 100, cmap='viridis')\n",
    "    \n",
    "elbo = np.min(df['recon']+df['kld'])\n",
    "plt.plot([0, elbo], [elbo, 0], '--', c='gray')\n",
    "\n",
    "plt.xlabel('KL Divergence: KL(q(z|x)|p(z)))')\n",
    "plt.ylabel(r'Reconstruction Loss: $- \\mathbb{E}_{q(z|x)}[logp(x|z)]$')   \n",
    "\n",
    "cb = plt.colorbar(ax, aspect=100, orientation=\"horizontal\", pad=0.125)\n",
    "cb.set_label(rf'$ \\beta $')\n",
    "# plt.legend(bbox_to_anchor=(1.05, 0.5), loc='center left', ncol=1, frameon=False)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.axis('tight')\n",
    "\n",
    "# plt.ylim([-3, 175])\n",
    "# plt.xlim([-3, 420])\n",
    "\n",
    "# plt.gca().text(letter_x, letter_y, 'a)', transform=plt.gca().transAxes, size=20)\n",
    "\n",
    "# plt.axis('equal')    \n",
    "\n",
    "plt.savefig('{}/model_selection_beta_clean.png'.format(results_dir), bbox_inches='tight', dpi=90)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out the best-on-validation set models for each $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = 'asdfasdfasdf'\n",
    "\n",
    "for i, data in enumerate(data_list):\n",
    "    if data['model_dir'] == \"/allen/aics/modeling/gregj/results/integrated_cell/test_cbvae/2019-07-19-09:27:15/\":\n",
    "        best_model = i\n",
    "        break\n",
    "\n",
    "best_model = np.argmax(best_elbo)\n",
    "\n",
    "for data in data_list:\n",
    "# data = data_list[best_model]\n",
    "\n",
    "\n",
    "    ind = 0\n",
    "    save_dir = data['model_dir']\n",
    "\n",
    "    print(\"model_dir = '{}'\".format(data['model_dir']))\n",
    "    print(\"parent_dir = '{}'\".format(parent_dir))\n",
    "    print(\"suffix = '{}'\".format(data['suffix'][ind]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do feature calculation for some subset of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "import importlib as imp\n",
    "import integrated_cell.utils.features\n",
    "imp.reload(integrated_cell.utils)\n",
    "imp.reload(integrated_cell.utils.features)\n",
    "\n",
    "from integrated_cell.utils.features import im2feats\n",
    "from aicsfeature.extractor.common import get_shape_features, get_intensity_features, get_skeleton_features\n",
    "\n",
    "def save_feats(im, save_path):\n",
    "    \n",
    "    assert im.shape[0] == 1 \n",
    "    \n",
    "    im_tmp = im[0].cpu().numpy()\n",
    "\n",
    "    im_tmp = np.expand_dims(im_tmp, 3)\n",
    "\n",
    "    im_struct = np.copy(im_tmp)\n",
    "    \n",
    "    for i in range(im_struct.shape[0]):\n",
    "        im_struct[i] = (im_struct[i] / np.max(im_struct[i]))*255\n",
    "        \n",
    "    im_struct = im_struct.astype('uint8')\n",
    "    \n",
    "    feats = {}\n",
    "    \n",
    "    feats['dna_shape'] = get_shape_features(seg=im_struct[1]>0)\n",
    "    feats['dna_inten'] = get_intensity_features(img=im_struct[1])\n",
    "    feats['dna_skeleton'] = get_skeleton_features(seg=im_struct[1])\n",
    "\n",
    "    feats['cell_shape'] = get_shape_features(seg=im_struct[0]>0)\n",
    "    feats['cell_inten'] = get_intensity_features(img=im_struct[0])\n",
    "    feats['cell_skeleton'] = get_skeleton_features(seg=im_struct[0])\n",
    "#     feats = im2feats(im_struct[0], im_struct[1], im_struct, extra_features=[\"io_intensity\", \"bright_spots\", \"intensity\", \"skeleton\"])\n",
    "    \n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump(feats, f)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def load_feats(save_paths):\n",
    "    feats = list()\n",
    "    for save_path in save_paths:\n",
    "        with open(save_path, 'rb') as f:\n",
    "            feat_tmp = pickle.load(f)\n",
    "            \n",
    "        feat = {}\n",
    "        for i in feat_tmp:\n",
    "            for j in feat_tmp[i]:\n",
    "                feat[\"{}_{}\".format(i,j)] = feat_tmp[i][j]            \n",
    "            \n",
    "        feats.append(feat)\n",
    "\n",
    "    feats = pd.DataFrame.from_dict(feats)\n",
    "        \n",
    "    return feats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "feats_parent_dir = \"{}/feats/\".format(results_dir)\n",
    "\n",
    "all_feats_save_path = \"{}/all_feats.pkl\".format(feats_parent_dir)\n",
    "\n",
    "intensity_norms = np.unique(df_master['intensity_norm'])\n",
    "\n",
    "feature_path_dict = {}\n",
    "#there are 2 normalization methods\n",
    "for intensity_norm in intensity_norms:\n",
    "    \n",
    "    #get the dataframe for this normalization method\n",
    "    df_norm = df_master[df_master['intensity_norm'] == intensity_norm]\n",
    "    \n",
    "    #get the parent directory for saving this normalization method    \n",
    "    save_norm_parent = \"{}/norm_{}\".format(feats_parent_dir, intensity_norm)\n",
    "    if not os.path.exists(save_norm_parent):\n",
    "        os.makedirs(save_norm_parent)\n",
    "        \n",
    "    save_norm_feats = \"{}/feats_test\".format(save_norm_parent)\n",
    "    if not os.path.exists(save_norm_feats):\n",
    "        os.makedirs(save_norm_feats)\n",
    "        \n",
    "    #get a data provider for this normalization methods\n",
    "    networks, dp, args = utils.load_network_from_dir(df_norm['model_dir'].iloc[0], parent_dir, suffix=df_norm['suffix'].iloc[0])\n",
    "    \n",
    "    enc = networks['enc'].cuda()\n",
    "    \n",
    "    x = dp.get_sample()\n",
    "    \n",
    "    z_tmp = enc(x.cuda())[0]\n",
    "    z_tmp = z_tmp[[0]]\n",
    "    n_latent = z_tmp.shape[1]\n",
    "    n_dat = dp.get_n_dat('test')\n",
    "    \n",
    "\n",
    "    \n",
    "    save_real_feats_paths = ['{}/feat_{}.pkl'.format(save_norm_feats, i) for i in range(n_dat)]\n",
    "    \n",
    "    #loop through all images and save them\n",
    "    for i, save_real_feat_path in tqdm(enumerate(save_real_feats_paths)):\n",
    "        if not os.path.exists(save_real_feat_path):\n",
    "            im = dp.get_sample('test', [i])   \n",
    "            save_feats(im, save_real_feat_path)\n",
    "\n",
    "    feature_path_dict[intensity_norm] = {}\n",
    "    feature_path_dict[intensity_norm]['real'] = load_feats(save_real_feats_paths)\n",
    "    feature_path_dict[intensity_norm]['gen'] = {}\n",
    "    \n",
    "    # now loop through all the models under this normalization method, saving generated images and features\n",
    "    for i in range(df_norm.shape[0]):\n",
    "        \n",
    "        save_feats_dir = '{}/{}'.format(save_norm_parent, df_master['label'].iloc[i])\n",
    "        \n",
    "        if not os.path.exists(save_feats_dir):\n",
    "            os.makedirs(save_feats_dir)\n",
    "        \n",
    "        #load the network\n",
    "        network_loaded = False\n",
    "        \n",
    "        dec = networks['dec'].cuda()\n",
    "        \n",
    "        save_gen_feats_paths = ['{}/feat_{}.pkl'.format(save_feats_dir, i) for i in range(n_dat)]\n",
    "        \n",
    "        for j, save_path in tqdm(enumerate(save_gen_feats_paths)):\n",
    "            \n",
    "            if not os.path.exists(save_path):\n",
    "\n",
    "                if not network_loaded:\n",
    "                    networks, dp, args = utils.load_network_from_dir(df_norm['model_dir'].iloc[i], parent_dir, suffix=df_norm['suffix'].iloc[i])\n",
    "                    network_loaded = True\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    im = dec(z_tmp.normal_())      \n",
    "\n",
    "                save_feats(im, save_path)\n",
    "\n",
    "        beta = df_norm['beta'].iloc[i]\n",
    "        feature_path_dict[intensity_norm]['gen'][beta] = load_feats(save_gen_feats_paths)\n",
    "        \n",
    "        \n",
    "with open(all_feats_save_path, \"wb\") as f:\n",
    "    pickle.dump(feature_path_dict, f)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_path_dict[intensity_norm]['real'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print precision/recall manifold stats across betas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrated_cell.metrics.precision_recall import precision_recall\n",
    "\n",
    "# colors = cm.Paired(np.arange(len(prs))/len(prs))\n",
    "\n",
    "k = 3\n",
    "\n",
    "n = len(feature_path_dict[intensity_norm]['gen'])\n",
    "colors = cm.Paired(np.arange(n)/n)\n",
    "\n",
    "for intensity_norm in intensity_norms:\n",
    "    \n",
    "    f1 = torch.Tensor(feature_path_dict[intensity_norm]['real'].values)\n",
    "\n",
    "    keep_cols = ~torch.all(f1[0] == f1, 0) * ~torch.all(np.isnan(f1)==1, 0)\n",
    "    \n",
    "#     print(keep_cols)\n",
    "#     print(feature_path_dict[intensity_norm]['real'].columns[keep_cols])\n",
    "    \n",
    "    f1 = f1[:,keep_cols] \n",
    "    \n",
    "    keep_rows = ~torch.any(np.isnan(f1)== 1, 1)\n",
    "    f1 = f1[keep_rows]\n",
    "    \n",
    "    mu = torch.mean(f1, 0)\n",
    "    std = torch.std(f1, 0)\n",
    "\n",
    "    f1 = (f1 - mu) / std\n",
    "\n",
    "    prs = {}\n",
    "    for beta in feature_path_dict[intensity_norm]['gen']:\n",
    "        f2 = torch.Tensor(feature_path_dict[intensity_norm]['gen'][beta].values)\n",
    "        f2 = f2[:,keep_cols]\n",
    "        \n",
    "        keep_rows = ~torch.any(np.isnan(f2)== 1, 1)\n",
    "        f2 = f2[keep_rows]\n",
    "        \n",
    "        f2 = (f2 - mu) / std\n",
    "\n",
    "        prs[beta] = precision_recall(f1, f2, k = [k])\n",
    "\n",
    "\n",
    "\n",
    "    betas = [beta for beta in prs]\n",
    "    precisions = [prs[beta][k]['precision'] for beta in prs]\n",
    "    recalls = [prs[beta][k]['recall'] for beta in prs]\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('intensity normalization = {}'.format(intensity_norm))\n",
    "    plt.plot(betas, precisions, label = 'precision')\n",
    "    plt.plot(betas, recalls, label = 'recall')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.xlabel('beta')\n",
    "    plt.ylabel('{}-NN Manifold precision & recall'.format(k))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print example images for each beta\n",
    "Rows from top to bottom are:  \n",
    "training input  \n",
    "training output  \n",
    "test input  \n",
    "test output  \n",
    "sampled images  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import imageio\n",
    "\n",
    "for intensity_norm in intensity_norms:\n",
    "    df_tmp = df_master[df_master['intensity_norm'] == intensity_norm]\n",
    "    df_tmp = df_tmp.iloc[np.argsort(df_tmp['beta'])]\n",
    "    \n",
    "    for i in range(df_tmp.shape[0]):\n",
    "        \n",
    "        im_out_path = '{}/ref_model/progress_{}.png'.format(df_tmp.iloc[i]['model_dir'], int(df_tmp.iloc[i]['epoch'][0]))\n",
    "    \n",
    "        print('Beta: {}, Intensity Norm: {}'.format(df_tmp.iloc[i]['beta'], intensity_norm))\n",
    "    \n",
    "        im_progress = imageio.imread(im_out_path)\n",
    "        display(PIL.Image.fromarray(im_progress))\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print off real versus generated feature distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(all_feats_save_path, \"rb\") as f:\n",
    "    feature_dict = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats_save_path = '/allen/aics/modeling/gregj/results/integrated_cell//test_cbvae_beta_ref/results/feats//all_feats.pkl'\n",
    "\n",
    "intensity_norms = ['unnormalized', 'normalized']\n",
    "\n",
    "with open(all_feats_save_path, \"rb\") as f:\n",
    "    feature_dict = pickle.load(f) \n",
    "\n",
    "for i, intensity_norm in enumerate(intensity_norms):\n",
    "    \n",
    "    #features for a specified intensity norm\n",
    "    feature_dict[i]\n",
    "    \n",
    "    #each sub-dict has real and gen features\n",
    "    real_feats = feature_dict[i]['real']\n",
    "    \n",
    "    feature_dict[i]['gen']\n",
    "    \n",
    "    #then gen feature dict has features for many betas\n",
    "    betas = [k for k in feature_dict[i]['gen']]\n",
    "    \n",
    "#     print(betas[0])\n",
    "    \n",
    "    features_for_the_first_beta = feature_dict[i]['gen'][betas[0]]\n",
    "    \n",
    "#     print(features_for_the_first_beta)\n",
    "    \n",
    "    #the real columns and the generated columns (for each beta) are the same\n",
    "    for columnReal, columnGen in zip(real_feats.columns, features_for_the_first_beta):\n",
    "        assert columnReal == columnGen\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from scipy.stats import gaussian_kde\n",
    "from matplotlib import cm\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "intensity_norm_meth = 0\n",
    "\n",
    "features = feature_dict[intensity_norm_meth]\n",
    "\n",
    "cols_to_plot = [\n",
    "    \"cell_shape_volume\",\n",
    "    \"cell_shape_surface_area\",\n",
    "    'cell_inten_intensity_mean',    \n",
    "    \"dna_shape_volume\",\n",
    "#     \"dna_shape_surface_area\",\n",
    "    'dna_inten_intensity_std'\n",
    "\n",
    "\n",
    "#     'cell_inten_intensity_median',\n",
    "#     'cell_inten_intensity_std',\n",
    "#     'dna_inten_intensity_mean',\n",
    "#     'dna_inten_intensity_median',\n",
    "    \n",
    "]\n",
    "\n",
    "n_feats = len(cols_to_plot)\n",
    "n_betas_to_plot = 5\n",
    "color_real = 'r'\n",
    "colors_betas = cm.viridis(np.linspace(0, 1, n_betas_to_plot))\n",
    "\n",
    "betas = np.array([k for k in features['gen']])\n",
    "\n",
    "betas_to_plot = betas[np.linspace(0, len(betas)-1, n_betas_to_plot).astype(int)]\n",
    "\n",
    "print(betas_to_plot)\n",
    "\n",
    "points_to_eval_kde = np.linspace(-3,10,100)\n",
    "\n",
    "plt.figure(figsize=[10, 6])\n",
    "\n",
    "for i, col in enumerate(cols_to_plot):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.title(col.replace('_', ' ').replace('surface area', 'perimeter').replace('volume', 'area').replace(' inten ', ' ').replace('dna ', 'DNA '))\n",
    "    \n",
    "    feats_real = features['real'][col].values.reshape(-1,1)\n",
    "    \n",
    "    scalar = preprocessing.StandardScaler()\n",
    "    scalar.fit(feats_real)\n",
    "\n",
    "    feats_real = scalar.transform(feats_real).flatten()\n",
    "    \n",
    "    density_real = gaussian_kde(feats_real).evaluate(points_to_eval_kde)\n",
    "\n",
    "    plt.plot(points_to_eval_kde, density_real, label='observed (z-scored)', color = color_real, zorder=1E10)\n",
    "    plt.fill_between(points_to_eval_kde, density_real, alpha = 0.1, color = color_real, zorder=1E10)\n",
    "    \n",
    "    if i == 0:\n",
    "        plt.ylabel('relative distribution')\n",
    "    \n",
    "    for j, beta_to_plot in enumerate(betas_to_plot):\n",
    "        feats_gen = features['gen'][beta_to_plot][col].values.reshape(-1,1)\n",
    "        \n",
    "        feats_gen = scalar.transform(feats_gen).flatten()\n",
    "        density = gaussian_kde(feats_gen).evaluate(points_to_eval_kde)\n",
    "        \n",
    "        plt.plot(points_to_eval_kde, density, label=rf'$ \\beta $ = {beta_to_plot}', color = colors_betas[j])\n",
    "        plt.fill_between(points_to_eval_kde, density, alpha = 0.1, color = colors_betas[j])\n",
    "\n",
    "\n",
    "    plt.yticks([])\n",
    "        \n",
    "#     if i == (len(cols_to_plot) - 1):\n",
    "#         plt.legend(bbox_to_anchor=(1.05, .95), frameon=False)\n",
    "    \n",
    "plt.subplot(2, 3, i+2)    \n",
    "\n",
    "legend_elements = [Line2D([0], [0], color=color_real, lw=4, label='observed (z-scored)')] + [Line2D([0], [0], color=colors_betas[j], lw=4, label=rf'$ \\beta $ = {beta_to_plot}') for j, beta_to_plot in  enumerate(betas_to_plot)]\n",
    "plt.gca().legend(handles=legend_elements, loc='center', frameon=False)\n",
    "plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('{}/features_and_betas.png'.format(results_dir), bbox_inches='tight', dpi=90)\n",
    "plt.show()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print off generated images for the models at different $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "from integrated_cell.utils.plots import tensor2im\n",
    "\n",
    "df = df_master.iloc[np.array(df_master['intensity_norm'] == 0)] \n",
    "\n",
    "gen_dir = f\"{results_dir}/gen\"\n",
    "if not os.path.exists(gen_dir):\n",
    "    os.makedirs(gen_dir)\n",
    "\n",
    "n_imgs_to_gen = 10    \n",
    "    \n",
    "im_dict = {}\n",
    "    \n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    row = df.iloc[i]\n",
    "    \n",
    "    beta = row['beta']\n",
    "    label = row['label']\n",
    "    \n",
    "    gen_img_dir = f\"{gen_dir}/{label}\"\n",
    "    if not os.path.exists(gen_img_dir):\n",
    "        os.makedirs(gen_img_dir)\n",
    "#     else:\n",
    "#         continue\n",
    "    \n",
    "    networks, dp, args = utils.load_network_from_dir(row['model_dir'], parent_dir, suffix = row['suffix'])\n",
    "    \n",
    "    sample = torch.zeros([n_imgs_to_gen, args['kwargs_dec']['n_latent_dim']]).normal_().cuda()\n",
    "    dec = networks['dec'].cuda()\n",
    "    \n",
    "    x_gen = dec.forward(sample)\n",
    "    \n",
    "    im_dict[beta] = {}\n",
    "    for j in range(n_imgs_to_gen):\n",
    "        im = tensor2im(x_gen[[j]])\n",
    "        \n",
    "        im_dict[beta][j] = im\n",
    "        scipy.misc.imsave(f'{gen_dir}/im_{j}.png', im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_imgs_per_beta = 4\n",
    "n_betas_to_plot = 11\n",
    "\n",
    "betas_to_plot = betas[np.linspace(0, len(betas)-1, n_betas_to_plot).astype(int)]\n",
    "\n",
    "print(betas_to_plot)\n",
    "\n",
    "beta_cols = list()\n",
    "for beta in betas_to_plot:\n",
    "    beta_col = list()\n",
    "    for i in range(n_imgs_per_beta):\n",
    "        beta_col.append(im_dict[beta][i])\n",
    "        \n",
    "    beta_cols.append(np.vstack(beta_col))\n",
    "    \n",
    "im_out = np.hstack(beta_cols)\n",
    "\n",
    "scipy.misc.imsave(f'{results_dir}/im_generated.png', im_out)\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(im_out)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sampled_to_plot = n_betas_to_plot - 1\n",
    "\n",
    "ims = dp.get_sample('test', list(range(n_sampled_to_plot)))\n",
    "\n",
    "\n",
    "\n",
    "im_real = np.hstack([tensor2im(ims[[i]]/torch.max(ims[[i]])) for i in range(n_sampled_to_plot)])\n",
    "\n",
    "scipy.misc.imsave(f'{results_dir}/im_sampled.png', im_real)\n",
    "\n",
    "plt.imshow(im_real)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "scipy.misc.imsave(f'{results_dir}/im_sampled.png', im_real)\n",
    "\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ritvik_pytorch_integrated_cell_workshop2021]",
   "language": "python",
   "name": "conda-env-ritvik_pytorch_integrated_cell_workshop2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}